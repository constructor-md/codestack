---
title: 简介
draft: false
weight: 1
---

# 简介
Kafka是一种分布式流事件处理平台  
最初由LinkedIn开发，现在是Apache基金会的一部分  
核心功能包括：消息队列、流处理和数据集成  
具备高吞吐量、低延迟、可扩展和高容错性  

## 主要应用场景  
1. 消息队列  
用作高吞吐量的消息系统，将消息从一个系统传递到另一个系统
2. 日志收集  
集中收起日志数据，然后通过Kafka传递到是实时监控系统或存储系统
3. 流计算  
处理实时数据流，将数据传递给实时计算系统，如Apache Strom或 Apache Flink
4. 事件溯源  
记录时间发生的历史，以便稍后进行数据回溯或重新处理
5. Metrics收集和监控  
收集来自不同服务的监控指标，统一存储和处理


Kafka设计理念与传统消息队列（如RabbitMQ）有所不同。  
Kafka更侧重于处理大规模数据流、支持高吞吐量和持久化存储。通常用于处理日志、监控数据等大规模数据流  
传统消息队列更多侧重于短生命周期的消息传递和任务调度。通常用于任务队列、队列服务等场景  

Kafka能在大数据生态系统中占据一席之地，归功于其独特设计和多个技术特点  
1. Kafka采用分区（Partition）和副本（Replica）的策略。每个主题（Topic）可以分成多个分区，每个分区可以有多个副本，即使某些节点出现故障，仍然可以保证数据的高可用和持久性。使得Kafka能够轻松应对大量数据的并发写入和读取
2. Kafka的高吞吐量和低延迟主要得益于其高效的IO模型。Kafka将数据写入操作进行顺序追加，避免磁盘的随机读写，极大提高了写入性能。此外Kafka采用了零拷贝（Zero-Copy）的技术，可以大幅提升数据传输效率，从而降低延迟  
在流处理方面，Kafka有强大的流处理API--Kafka Streams。这个API允许开发者使用简单的编程莫辛纳甘创建复杂的流处理应用，而不必依赖外部独立的流处理框架。  
另外，Kafka Connect是Kafka用来进行数据继承的工具。它提供了各种各样的连接器（Connectors），可以轻松的将数据从外部系统导入Kafka，或者将Kafka中的数据导出到外部系统  

## 基本架构组成
Kafka基本架构主要包括：Producer、Consumer、Broker 和 Zookeeper
1. Producer  
消息生产者，将数据发布到Kafka特定Topic上。客户端可以指定消费者发送的主题数据的分区和副本策略
2. Consumer  
消息消费者，从Kafka的Topic中读取数据。消费者可以属于某个消费者组（Consumer Group），消费者组内的消费者，每个只会消费一个主题的一个消息，不会重复消费，可以让多个消费者平衡复杂读取数据
3. Broker  
消息代理，也就是Kafka集群的服务节点。负责消息的存储和管理，集群可以包含一个或多个Broker，负责接收、存储、发送数据
4. Zookeeper（有废弃Zookeeper的版本）  
协调器，用于Kafka的愤怒不是协调和管理任务，比如存储Broker的元数据信息、分区列表、Leader等。Zookeeper来确保Kafka集群的高可用性和一致性