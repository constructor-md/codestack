[{"id":0,"href":"/codestack/docs/javaee/spring/","title":"Spring","section":"JavaEE","content":"\rSpring\r#\r"},{"id":1,"href":"/codestack/docs/deploy/ubuntu/","title":"Ubuntu","section":"部署","content":"\rUbuntu\r#\r采用版本：24.01\n安装过程：全部 Done\n非Root用户上传文件\r#\r# 赋予指定用户组用户在某个文件夹及其子文件夹上传文件的权限\rsudo chown -R quanta:quanta /DATA 时区设置\r#\r# 查看当前时区\rtimedatectl\r# 查看东八区全称\rtimedatectl list-timezones | grep Shanghai\r# 设置时区\rsudo timedatectl set-timezone Asia/Shanghai host设置\r#\r便于多主机内网互相访问\nsudo vim /etc/hosts\r# 补充相关机器的ip 主机名\r192.168.1.11 dataserver1\r192.168.1.12 dataserver2\r192.168.1.13 dataserver3 OpenSSH安装\r#\rsudo apt update \u0026amp;\u0026amp; sudo apt upgrade\rsudo apt install openssh-server\rservice ssh status\r# 随后可以本机SSH使用安装过程设置的账户密码登录服务器 修改监听端口\r#\rsudo vi /etc/ssh/sshd_config\r# 内容\rPort 2222 修改后要重启\n重启\r#\r# Ubuntu22版本之前：\rsudo systemctl restart sshd\r# Ubuntu22版本之后：\rsudo systemctl daemon-reload\rsudo systemctl restart ssh.socket Docker安装(指定版本)\r#\rapt依赖安装\r#\rsudo apt-get install apt-transport-https ca-certificates curl gnupg-agent software-properties-common 添加阿里云docker GPG密钥\r#\rcurl -fsSL http://mirrors.aliyun.com/docker-ce/linux/ubuntu/gpg | sudo apt-key add - 添加阿里云镜像源\r#\rsudo add-apt-repository \u0026#34;deb [arch=amd64] http://mirrors.aliyun.com/docker-ce/linux/ubuntu $(lsb_release -cs) stable\u0026#34;\r#更新\rsudo apt-get update 查看有哪些可安装版本\r#\rsudo apt-cache madison docker-ce\r# 列出版本\rsudo apt-cache madison docker-ce | awk \u0026#39;{ print $3 }\u0026#39; 第二列是版本号，第三列是存储库的名称\n版本号提取： 第二列的第一行字符串为 5:19.03.93-0ubuntu-bionic ，那么版本号为 5:19.03.93-0ubuntu-bionic，版本号字符串必须写全第二列的整个字符串\n安装最新版\r#\rsudo apt-get install -y docker-ce 安装指定版本\r#\rsudo apt-get install -y docker-ce=5:27.3.1-1~ubuntu.24.04~noble 安装检查(版本查看)\r#\rsudo docker --version 修改镜像源\r#\rsudo vim /etc/docker/daemon.json\r{\r\u0026#34;registry-mirrors\u0026#34;: [\r\u0026#34;https://docker.m.daocloud.io\u0026#34;\r]\r} 修改后要重启docker\nsudo systemctl daemon-reload\t#重启daemon进程\rsudo systemctl restart docker\t#重启docker 检查修改成功\nsudo docker info 限制容器日志大小\r#\r不限制会直接打到磁盘爆满\nsudo vim /etc/docker/daemon.json\r{\r\u0026#34;registry-mirrors\u0026#34;: [\u0026#34;https://docker.m.daocloud.io\u0026#34;],\r\u0026#34;log-driver\u0026#34;:\u0026#34;json-file\u0026#34;,\r\u0026#34;log-opts\u0026#34;: {\u0026#34;max-size\u0026#34;:\u0026#34;10k\u0026#34;, \u0026#34;max-file\u0026#34;:\u0026#34;3\u0026#34;}\r}\r# 重启docker\rsudo systemctl daemon-reload\rsudo systemctl restart docker Hello World\r#\rsudo docker pull hello-world\rsudo docker run hello-world 命令启停\r#\rsudo systemctl start docker\rsudo systemctl stop docker 自动唤醒\r#\r默认会开启自动唤醒，stop docker进程时会显示：\nStopping \u0026#39;docker.service\u0026#39;, but its triggering units are still active:\rdocker.socket docker被访问时会被自动启动\n一般不会想关闭，如果要关闭：\nsudo systemctl stop docker.socket 开启自启\r#\rsudo systemctl enable docker Curl安装\r#\rsudo apt install curl DockerCompose安装（指定版本）\r#\r与Docker的版本适配关系 https://docs.docker.com/compose/releases/release-notes/\n指定版本安装\r#\rdocker装的是27.3.1 对应compose版本是2.30.x\n使用2.30.1\nsudo curl -L \u0026#34;https://github.com/docker/compose/releases/download/v2.30.1/docker-compose-linux-x86_64\u0026#34; -o /usr/local/bin/docker-compose 或者自行下载上传后执行：\n# 下载：到github docker compose上找所需版本包\rhttps://github.com/docker/compose/releases/download/v2.30.1/docker-compose-linux-x86_64\rhttps://github.com/docker/compose/releases\r# 上传后转移目录\rsudo cp docker-compose-linux-x86_64 /usr/local/bin/docker-compose 添加Docker Compose执行权限\r#\rsudo chmod +x /usr/local/bin/docker-compose 安装检查\r#\rdocker-compose --version Docker卸载\r#\r完全卸载Docker及安装时自动安装的所有包\r#\rsudo apt-get autoremove docker docker-ce docker-engine docker.io containerd runc 删除没有删除的相关插件\r#\rsudo apt-get autoremove docker-ce-* 删除docker的相关配置\u0026amp;目录\r#\rsudo rm -rf /etc/systemd/system/docker.service.d\rsudo rm -rf /var/lib/docker 确认docker卸载完毕（查看版本）\r#\rsudo docker --version 如果还有，可能存在snap版本的，删除\nsudo snap remove --purge docker 删除Docker相关文件\r#\rwhereis docker\rsudo rm -rf /usr/bin/docker 防火墙UFW控制\r#\r查看防火墙状态\r#\rsudo ufw status 查看防火墙状态 包括默认规则\r#\rsudo ufw status verbose 设置默认拒绝入站流量\r#\rsudo ufw default deny incoming 设置默认允许出站流量\r#\rsudo ufw default allow outgoing 防火墙启停\r#\rsudo ufw enable\rsudo ufw disable 允许/禁用端口\r#\rsudo ufw allow 2222/tcp\rsudo ufw deny 22/tcp 删除规则\r#\rsudo ufw delete allow 6379/tcp 防火墙开机自启\r#\rsudo systemctl status ufw ifconfig使用安装\r#\rsudo apt install net-tools 扩容磁盘（分区扩展+提升逻辑卷大小和根目录空间）\r#\r# 操作之前先停止各个docker容器等程序\rsudo docker-compose stop container_name\r# 持续重启的容器可能无法接收停止命令 使用down强制停止\rsudo docker-compose down container_name\r# 进入 fdisk 程序\rsudo fdisk /dev/sda\r# 输入 d 表示要删除分区\rCommand (m for help): d\r# 输入 3 表示要删除的是 /dev/sda3\rPartition number (1-3, default 3): 3\r# 显示已删除\rPartition 3 has been deleted.\r# 输入 n 表示创建新分区\rCommand (m for help): n\r# 直接回车表示选择分区号为默认3\rPartition number (3-128, default 3): # 直接回车默认起始扇区\rFirst sector (4198400-1430257630, default 4198400): # 直接回车默认结束扇区为使用所有剩余空间\rLast sector, +/-sectors or +/-size{K,M,G,T,P} (4198400-1430257630, default 1430255615): Created a new partition 3 of type \u0026#39;Linux filesystem\u0026#39; and of size 680 GiB.\rPartition #3 contains a LVM2_member signature.\r# yes 表示删除原本的GPT/MBR签名 会导致分区信息丢失\r# no 表示保留旧签名 只是对磁盘进行小调整 比如扩展\rDo you want to remove the signature? [Y]es/[N]o: n\r# w 保存修改\rCommand (m for help): w\rThe partition table has been altered.\rSyncing disks.\r# 重新加载分区表\rsudo partprobe\r# 扩展 LVM物理卷\rsudo pvresize /dev/sda3\r# 扩展逻辑卷\rsudo lvextend -l +100%FREE /dev/mapper/ubuntu--vg-ubuntu--lv\r# 调整文件系统大小\rsudo resize2fs /dev/mapper/ubuntu--vg-ubuntu--lv\r# 查看当前的文件占用情况\rsudo fdisk -l\rDisk /dev/sda: 682 GiB, 732291923968 bytes, 1430257664 sectors\rDisk model: Virtual disk Units: sectors of 1 * 512 = 512 bytes\rSector size (logical/physical): 512 bytes / 512 bytes\rI/O size (minimum/optimal): 512 bytes / 512 bytes\rDisklabel type: gpt\rDisk identifier: 0493D914-0713-4A60-93B8-B83236128F4C\rDevice Start End Sectors Size Type\r/dev/sda1 2048 4095 2048 1M BIOS boot\r/dev/sda2 4096 4198399 4194304 2G Linux filesystem\r/dev/sda3 4198400 1430255615 1426057216 680G Linux filesystem\rDisk /dev/mapper/ubuntu--vg-ubuntu--lv: 680 GiB, 730140246016 bytes, 1426055168 sectors\rUnits: sectors of 1 * 512 = 512 bytes\rSector size (logical/physical): 512 bytes / 512 bytes\rI/O size (minimum/optimal): 512 bytes / 512 bytes\r# 已经给/dev/sda3和/dev/mapper/ubuntu--vg-ubuntu--lv扩展到了680G\rdf -h\rFilesystem Size Used Avail Use% Mounted on\rtmpfs 1.2G 114M 1.1G 10% /run\r/dev/mapper/ubuntu--vg-ubuntu--lv 669G 11G 631G 2% /\rtmpfs 5.9G 0 5.9G 0% /dev/shm\rtmpfs 5.0M 0 5.0M 0% /run/lock\r/dev/sda2 2.0G 95M 1.7G 6% /boot\rtmpfs 1.2G 12K 1.2G 1% /run/user/1000\r# 根目录可用空间已经扩展到了669G 切换用户和修改密码\r#\r# 切换用户\rsu user\r# 修改密码\rpasswd user\r# 修改root用户密码\rsudo passwd root 固定本机内网IP 禁用DHCP\r#\r# 编辑netplan配置文件\rsudo vim /etc/netplan/50-cloud-init.yaml\r# 内容如下 注释了原本的配置\r# This file is generated from information provided by the datasource. Changes\r# to it will not persist across an instance reboot. To disable cloud-init\u0026#39;s\r# network configuration capabilities, write a file\r# /etc/cloud/cloud.cfg.d/99-disable-network-config.cfg with the following:\r# network: {config: disabled}\r#network:\r# ethernets:\r# ens192:\r# dhcp4: true\r# version: 2\rnetwork:\rethernets:\r# ens192名称和原始配置保持一致\rens192:\rdhcp4: false\raddresses: [192.168.1.11/24] # 需要的本机ip\rroutes:\r- to: default\rvia: 192.168.1.1 # 网关地址\rnameservers:\raddresses: [192.168.1.1] # DNS地址\rversion: 2\r# 使得配置生效\rsudo netplan apply "},{"id":2,"href":"/codestack/docs/javaee/mysql/tree-high/","title":"索引树高度计算","section":"MySQL","content":"\r索引树高度计算\r#\r基本原理\r#\rInnodb是索引组织表，每个页都包含一个PAGE_LEVEL，表示当前页在索引上的高度\n默认叶子节点高度为0，ROOT节点PAGE_LEVEL+1就是这棵索引高度\nPAGE_LEVEL在每个页的64位偏移位置，占用2字节\n找到ROOT页位置，知道单页大小，使用hexdump在指定表空间找到第PAGE_NO页的64位偏移量的后两个字节即可\n找到ROOT页信息\r#\rSELECT b.name, a.name, index_id, type, a.space, a.PAGE_NO FROM information_schema.INNODB_SYS_INDEXES a, information_schema.INNODB_SYS_TABLES b WHERE a.table_id = b.table_id AND a.space \u0026lt;\u0026gt; 0;\n结果： 其中（space、PAGE_NO）指向ROOT页\nspace是表空间，可以是系统表空间（如ibdata1文件）或独立表空间（如每个InnoDB表的.ibd文件）。表空间由多个区（extent）组成，每个区包含连续的页（page）\n也就是ROOT页是space的page_no页\n查看innodb_page_size\r#\rshow variables like \u0026#39;innodb_page_size\u0026#39; 结果： 也就是Innodb默认的页大小16KB\n找到ROOT的PAGE_LEVEL，得到索引高度\r#\r首先要找到表对应的ibd文件，也就是表空间文件\n所在位置是MySQL的数据目录下的数据库名文件夹下\n#查找MySQL数据目录\rshow variables like \u0026#39;datadir\u0026#39; 我的MySQL是用Docker起的，docker中没有安装hexdump命令，不过这个目录被挂载出来了，考虑在宿主机上分析其中的ibd文件\n但所在文件夹和文件权限限制了宿主机外用户访问文件夹和文件 修改权限需要到docker容器中修改该文件和对应文件夹权限\nchmod 755 path 原本权限为750，禁止其他用户读写文件夹\n修改后在宿主机进入文件夹中，找到所需文件，在文件夹执行命令\nhexdump -C -s 49216 -n 10 goods_info_100M.ibd 前两个字节是PAGE_LEVEL，所以这个索引树高度为3+1 = 4\n后面8个字节是index_id，32十六进制转10进制就是50，49216 = 16384*3 + 64，是ROOT页在PAGE_NO=3的索引树 总结\r#\r关键命令：\nhexdump -C -s [innodb_page_size*PAGE_NO + 64] -n 10 [ibd filename] "},{"id":3,"href":"/codestack/docs/basic/","title":"计算机基础","section":"Docs","content":"\r计算机基础\r#\r"},{"id":4,"href":"/codestack/docs/javaee/","title":"JavaEE","section":"Docs","content":"\rJavaEE\r#\r"},{"id":5,"href":"/codestack/docs/deploy/mysql/","title":"MySQL","section":"部署","content":"\rMySQL\r#\r安装版本：MySQL 8.0.20\n部署方式：一主二从\n运行方式：docker-compose\n各节点安装\r#\r创建MySQL目录\r#\r# 放置所有mysql相关文件 比如my.cnf\rsudo mkdir /DATA/mysql\r# 放置mysql数据文件 也作为mysql\rsudo mkdir /DATA/mysql/mysql 创建MySQL用户并设置权限\r#\r# 创建mysql用户 设置为不可登陆系统 并设置用户的主目录为/DATA/mysql/mysql\rsudo useradd -r -s /sbin/nologin -d /DATA/mysql/mysql mysql\r# 指定mysql用户的主目录为/DATA/mysql/mysql\rsudo usermod -d /DATA/mysql/mysql mysql\r# 递归地将/DATA/mysql/mysql目录及其所有子目录和文件的所有者和所属组设置为mysql用户和mysql组\rsudo chown -R mysql:mysql /DATA/mysql/mysql\r# 递归地将/DATA/mysql/mysql目录及其子目录设和文件的权限设置为755\r# 755：所有者有读写和执行权限，组用户和其他用户有读和执行权限\rsudo chmod -R 755 /DATA/mysql/mysql\r# 查找/etc/passwd文件中包含mysql的行 /etc/passwd是系统用户信息文件，包含所有用户的基本信息\rgrep mysql /etc/passwd 操作失误时的可选操作\n# 删除用户及其主目录 没有r不删除主目录\rsudo userdel -r mysql\r# 手动删除主目录\rsudo rm -rf /DATA/mysql\r# 检查 grep mysql /etc/passwd\r# 删除用户组\rsudo groupdel mysql\r# 检查用户组是否删除\rgrep mysql /etc/group docker-compose文件\r#\r# 创建docker-compose文件在/DATA下，或者追加在已有文件中\rvim docker-compose.yml docker-compose.yml\nversion: \u0026#39;3\u0026#39; # 使用docker-compose版本3\rservices: # 定义服务\rmysql8: # 定义一个名为mysql8的服务\rimage: mysql:8.0.20 # 使用MySQL 8.0.20镜像\rcontainer_name: mysql8 # 指定容器名称为mysql8\rrestart: always # 系统重启时自动重新启动\rcap_add:\r- SYS_NICE\rports: # 定义容器和主机之间的端口映射\r- \u0026#34;33060:3306\u0026#34; # 将容器的3306端口映射到主机的33060端口\renvironment: # 定义环境变量\rMYSQL_ROOT_PASSWORD: \u0026#34;password\u0026#34; # 设置root用户的密码\rvolumes: # 定义数据卷\r- /DATA/mysql/mysql:/var/lib/mysql # 挂载数据目录\r- /DATA/mysql/my.cnf:/etc/mysql/my.cnf # 挂载my.cnf\rhealthcheck:\rtest: [\u0026#34;CMD\u0026#34;, \u0026#34;mysqladmin\u0026#34; ,\u0026#34;ping\u0026#34;, \u0026#34;-h\u0026#34;, \u0026#34;localhost\u0026#34;, \u0026#34;-u\u0026#34;, \u0026#34;user\u0026#34;, \u0026#34;-ppassword\u0026#34;] # 设置容器健康检查命令\rinterval: 20s # 每隔20秒进行一次健康检查\rtimeout: 10s # 健康检查超时时间为10秒\rretries: 3 # 健康检查失败时重试次数为3次 服务器间文件复制\r#\r# scp [源文件路径] [目标服务器用户名]@[目标服务器IP]:[目标路径]\rscp -P [ssh port] /home/user/file.txt user@192.168.1.2:/home/user/\r# scp [源服务器用户名]@[源服务器IP]:[源文件路径] [目标路径]\rscp -P [ssh port] user@192.168.1.2:/home/user/file.txt /home/user/ 授权文件\nsudo chmod 777 /DATA/docker-compose.yml my.cnf文件\r#\rsudo vim /DATA/mysql/my.cnf my.cnf\n[mysqld]\r# 指定数据目录\rdatadir = /var/lib/mysql\r# 安全文件前缀\rsecure-file-priv = NULL\r# 不进行域名解析\rskip-name-resolve\r# 默认存储引擎\rdefault-storage-engine = InnoDB\r# 服务器监听的ip地址\rbind-address = 0.0.0.0\r# 服务器监听的端口号\rport = 3306\r# 连接配置\r# 最大连接数\rmax_connections = 2000\r# 单个用户最大连接数\rmax_user_connections = 1000 # 最大连接错误数\rmax_connect_errors = 4000 # 空闲连接的超时时间\rwait_timeout = 300 # 交互式连接的超时时间 数据库管理工具的连接 那些手动执行SQL的可能长时间空闲\rinteractive_timeout = 600 # 最大允许的数据包大小 避免一次查出太多数据打崩数据库\rmax_allowed_packet = 32M # 日志设置\r# 使用短格式记录日志\rlog-short-format = 1 # 启用慢查询日志\rslow_query_log # 慢查询的时间阈值 2s及以上的查询被作为慢查询记录\rlong_query_time = 2 [mysqldump]\rquick # 快速导出数据\rmax_allowed_packet = 16M # 最大允许的数据包大小\r[mysqlhotcopy]\rinteractive-timeout = 3600 # 交互式超时时间，超时时间设置为 1 小时 授权文件\n# 所有者读写，组成员和其他用户可读不可写，完全不可执行\rsudo chmod 644 /DATA/mysql/my.cnf docker compose运行镜像\r#\rsudo docker-compose up -d mysql8 docker compose停止镜像\r#\rsudo docker-compose stop mysql8 docker compose重启镜像\r#\rsudo docker-compose restart mysql8 日志查看\r#\rsudo docker logs mysql8 防火墙配置\r#\rsudo ufw allow 33060/tcp root用户限制为局域网访问\r#\r# 进入docker\rsudo docker exec -it mysql8 /bin/bash\r# 登录mysql\rmysql -u root -p your_password\r# 使用mysql数据库\ruse mysql;\r# 删除\u0026#39;root\u0026#39;@\u0026#39;%\u0026#39; 不删除\u0026#39;root\u0026#39;@\u0026#39;localhost\u0026#39; 保留本机访问权限\rDROP USER \u0026#39;root\u0026#39;@\u0026#39;%\u0026#39;;\r# 创建\u0026#39;root\u0026#39;@\u0026#39;192.168.1.*\u0026#39; 建立局域网访问权限\rCREATE USER \u0026#39;root\u0026#39;@\u0026#39;192.168.1.%\u0026#39; IDENTIFIED BY \u0026#39;bucunzaide2333\u0026#39;;\rGRANT ALL PRIVILEGES ON *.* TO \u0026#39;root\u0026#39;@\u0026#39;192.168.1.%\u0026#39; WITH GRANT OPTION;\rFLUSH PRIVILEGES; 主从配置\r#\r主节点配置\r#\rmy.cnf配置\r#\rsudo vim /DATA/mysql/my.cnf 要在[mysqld]部分添加\n# 主从配置 - 主节点\r# MySQL服务id 各节点不同\rserver_id = 1010\r# 开启二进制日志\rlog-bin = mysql-bin\r# 日志格式\rbinlog_format = ROW 重启MySQL服务\r#\r# 要在所需docker-compose.yml文件同文件夹下执行\rsudo docker-compose restart mysql8 检查server-id配置确保生效\r#\r# 连接数据库执行\rSHOW VARIABLES LIKE \u0026#39;server_id\u0026#39;; 创建复制用户并赋予权限\r#\rCREATE USER \u0026#39;repl\u0026#39;@\u0026#39;192.168.1.%\u0026#39; IDENTIFIED WITH mysql_native_password BY \u0026#39;repl_password\u0026#39;;\rGRANT REPLICATION SLAVE ON *.* TO \u0026#39;repl\u0026#39;@\u0026#39;192.168.1.%\u0026#39;;\rFLUSH PRIVILEGES; 查看主服务器的二进制日志信息并记录\r#\rSHOW master status\r# 记录File和Position值 从节点配置\r#\rmy.cnf配置\r#\rsudo vim /DATA/mysql/my.cnf 要在[mysqld]部分添加\n# 主从配置 - 从节点\r# MySQL服务标识id 每个节点不同 大于0\rserver_id = 1020\r# 从节点不建议开启二进制日志\r# 从节点设置为只读 然后在应用层做数据源切换 读写分离\r# 仅read-only， root用户还是可以建表，普通用户只读\r# 5.7.8后添加了super_read_only root用户也不可以执行读以外的操作\rsuper_read_only = 1 重启MySQL服务\r#\rsudo docker-compose restart mysql8 配置从服务器连接主服务器\r#\r登录从服务器的MySQL数据库执行\nCHANGE MASTER TO\rMASTER_HOST = \u0026#39;192.168.1.x\u0026#39;, # 主服务器的 IP 地址\rMASTER_PORT = \u0026#39;33060\u0026#39;, # 主服务器MySQL端口\rMASTER_USER = \u0026#39;repl\u0026#39;, # 复制用户的用户名\rMASTER_PASSWORD = \u0026#39;repl_password\u0026#39;, # 复制用户的密码\rMASTER_LOG_FILE = \u0026#39;mysql-bin.00000x\u0026#39;, # 主服务器的二进制日志文件名\rMASTER_LOG_POS = 1234; # 主服务器的二进制日志位置\r# CHANGE MASTER TO之后，有任何SQL执行都会导致MASTER_LOG_POS变化\r# 需要再次查看Master Status，停止复制修改后，再开始复制 MASTER_LOG_FILE 和 MASTER_LOG_POS 的值从主服务器的 SHOW MASTER STATUS; 命令中获取\n启动从服务器的复制进程\r#\rSTART SLAVE; 停止从服务器的复制进程\r#\rSTOP SLAVE; 检查从服务器的复制状态\r#\rSHOW SLAVE STATUS;\r# 确保Slave_IO_Running和Slave_SQL_Running都是Yes 验证主从复制\r#\r主服务器写数据，查看从服务器是否变更\n一些常见操作\r#\r配置时主节点常用命令\r#\rSHOW VARIABLES LIKE \u0026#39;server_id\u0026#39;;\rSHOW master status;\rSHOW GRANTS FOR \u0026#39;repl\u0026#39;@\u0026#39;192.168.1.%\u0026#39;;\rDROP USER \u0026#39;repl\u0026#39;@\u0026#39;192.168.1.%\u0026#39;\rCREATE USER \u0026#39;repl\u0026#39;@\u0026#39;192.168.1.%\u0026#39; IDENTIFIED WITH mysql_native_password BY \u0026#39;repl_password\u0026#39;;\rGRANT REPLICATION SLAVE ON *.* TO \u0026#39;repl\u0026#39;@\u0026#39;192.168.1.%\u0026#39;;\rFLUSH PRIVILEGES; 配置时从节点常用命令\r#\rSHOW VARIABLES LIKE \u0026#39;server_id\u0026#39;;\rCHANGE MASTER TO\rMASTER_HOST = \u0026#39;192.168.1.11\u0026#39;,\rMASTER_PORT = 33060,\rMASTER_USER = \u0026#39;repl\u0026#39;,\rMASTER_PASSWORD = \u0026#39;repl_password\u0026#39;,\rMASTER_LOG_FILE = \u0026#39;mysql-bin.000001\u0026#39;,\rMASTER_LOG_POS = 1739;\rSTOP SLAVE;\rSTART SLAVE;\rSHOW SLAVE STATUS; 登陆的是从节点，查找主节点IP\r#\rSHOW SLAVE STATUS;\r# Master_Host 和 Master_Port 二进制日志格式的区别\r#\rROW（5.7之后官方默认的选择）： 基于行的复制，记录的是每行的变化，可读性差，文件大，传输慢，但可以应对各种情况的影响 对于 INSERT 操作，记录插入的每一行数据 对于 UPDATE 操作，记录修改前和修改后的每一行数据 对于 DELETE 操作，记录被删除的每一行数据 绝对的数据一致性保证 STATEMENT：最初的MySQL主从复制模式，不推荐选择 记录的是SQL，文件小传输快 遇到非确定函数如NOW RAND UUID等，主从库执行的结果会不同 遇到存储过程和触发器可能无法正确复制 遇到用户自定义函数，可能会在主从库产生不同的效果 某些场景下 LAST_INSERT_ID()可能在主从库上值不一致 MIXED：混合模式，一些情况下可能有人选择 普通SQL记录为STATEMENT形式，有可读性 遇到非确定性函数等转换为ROW格式记录 复杂场景下如存储过程、触发器，可能会导致数据不一致 如果对数据一致性要求极高，且对日志大小和性能的影响可以接受，建议使用 ROW 格式。↑\n如果需要在性能和一致性之间取得平衡，且希望减少日志大小和管理复杂性，建议使用 MIXED 格式\n完全不要用STATEMENT格式\n一主多从和多主多从的配置区别\r#\r多主多从： 主节点之间互为主从，可能出现数据冲突需要在应用层避免，或者引入冲突解决机制（如conflict-resolution 插件） 从节点要设置每个主节点为主节点，为每个主节点单独配置复制通道，便于从多个主节点获取数据（多源复制）\n"},{"id":6,"href":"/codestack/docs/javaee/mysql/","title":"MySQL","section":"JavaEE","content":"\rMySQL\r#\r"},{"id":7,"href":"/codestack/docs/deploy/redis/","title":"Redis","section":"部署","content":"\rRedis\r#\r安装版本：7.0.4\n部署方式：一主二从三哨兵\n节点分配：每节点一个Redis-Server，一个Sentinel\n运行方式：docker-compose\n目录和用户权限\r#\r创建Redis和Sentinel目录\r#\r# 存放所有Redis相关文件\rsudo mkdir /DATA/redis\r# 存放Redis和Sentinel配置文件\rsudo mkdir /DATA/redis/config\r# 存放Sentinel配置和文件\rsudo mkdir /DATA/redis/config/sentinel\r# 存放挂载docker内运行Redis的数据目录\rsudo mkdir /DATA/redis/data 创建redis用户并设置工作目录\r#\r# 创建 redis 用户 设置为不可登陆系统 并设置用户的主目录为/DATA/redis/data\rsudo useradd -r -s /sbin/nologin -d /DATA/redis/data redis\r# 指定 redis 用户的主目录为/DATA/redis/data\rsudo usermod -d /DATA/redis/data redis\r# 递归地将/DATA/redis/data目录及其所有子目录和文件的所有者和所属组设置为redis用户和redis组\rsudo chown -R redis:redis /DATA/redis/data\r# 递归地将/DATA/redis/data目录及其子目录设和文件的权限设置为755\r# 755：所有者有读写和执行权限，组用户和其他用户有读和执行权限\rsudo chmod -R 755 /DATA/redis/data\r# 查找/etc/passwd文件中包含mysql的行 /etc/passwd是系统用户信息文件，包含所有用户的基本信息\rgrep redis /etc/passwd 主节点配置\r#\rredis.conf\r#\rsudo vim /DATA/redis/config/redis.conf\r# 监听端口\rport 63790\r# 访问密码\rrequirepass password\r# 数据库数量 使用cluster模式时只会有一个database即DB0\rdatabases 16\r# 绑定本机的网络接口（网卡） 绑定的是网卡的IP地址\r# 0.0.0.0 监听所有 默认127.0.0.1\rbind 0.0.0.0\r# 默认开启\r# 如果没有设置密码和且没有设置bind，只允许本机访问\rprotected-mode yes\r# 单位秒，timeout时间内客户端没有数据交互，关闭连接\rtimeout 60\r# 客户端同时连接的最大数量 默认10000\r# 达到最大值时关闭新连接并返回max number of clients reached\rmaxclients 1000\r# 内存管理 # 最大内存，推荐最大设置为6GB\r# 不要设置过大内存，防止执行RDB内存快照文件或者AOF重写时因为数据太大阻塞太长时间\rmaxmemory 2GB\r# 内存淘汰策略 默认noeviction\r# noeviction -\u0026gt; 不删除任何 key，内存满了直接返回报错\r# 默认情况下slave节点会忽略maxmemory配置，除非被提升为master\r# 只有master会执行内存淘汰策略，master删除key后会发送DEL指令给slave\rmaxmemory-policy noeviction\r# 过期key滞留在内存的比例 默认值为1 表示10%\r# 设置的越小，一次淘汰周期需要消耗的CPU更多 需要删除更多的过期数据\ractive-expire-effort 1\r# 持久化\r# AOF持久化开启\rappendonly yes\r# AOF 持久化模式，默认为 \u0026#34;always\u0026#34;。可以是 always、everysec 或 no\r# always：每个写操作都立即同步到磁盘，最费性能\r# everysec：每秒钟同步一次到磁盘，折中的选择\r# no：完全依赖操作系统的行为，可能会丢失数据，但性能最高\rappendfsync everysec\r# AOF-RDB混合持久化\r# 配置成yes必须先开启AOF AOF重写生成的文件将同时包含RDB和AOF格式内容\r# 推荐开启\raof-use-rdb-preamble yes\r# 性能监控\r# 慢查询日志 执行时间只是命令阶段的时间，不包括建立连接发送回复等\r# slow log 仅保存在内存中，效率很高\r# 执行时间大于多少微秒的查询进行记录 1s = 1,000,000微秒 默认10000\rslowlog-log-slower-than 10000\r# 最多保存多少条慢查询日志 slowlog本身是FIFO 默认128\rslowlog-max-len 128 sentinel.conf\r#\rsudo vim /DATA/redis/config/sentinel/sentinel.conf\r# 哨兵端口\rport 26379\r# 监控的redis主节点的ip port\r# master-name 自定义\r# quorum 多少个sentinel主观认为master失联，认为客观上master失联\r# sentinel monitor \u0026lt;master-name\u0026gt; \u0026lt;ip\u0026gt; \u0026lt;redis-port\u0026gt; \u0026lt;quorum\u0026gt;\rsentinel monitor mymaster 192.168.1.11 63790 2\r# redis实例的密码 主从的访问密码必须要一样\rsentinel auth-pass mymaster password\r# 指定多少毫秒之后主节点没有应答哨兵\r# 此时哨兵主观上认为主节点下线\r# 默认30秒\r# sentinel down-after-milliseconds \u0026lt;master-name\u0026gt; \u0026lt;milliseconds\u0026gt;\rsentinel down-after-milliseconds mymaster 30000\r# 设置故障转移时，从节点同步新主节点数据的并发数量\r# 值越小，对主节点的压力越小，但同步速度可能较慢\r# sentinel parallel-syncs \u0026lt;master-name\u0026gt; \u0026lt;numslaves\u0026gt;\rsentinel parallel-syncs mymaster 1\r# 设置故障转移的超时时间（单位：毫秒）\r# 如果故障转移在这个时间内没有完成，则认为失败\rsentinel failover-timeout mymaster 180000\r# 配置哨兵自身的ip 避免走自动检测给出其他哨兵访问不到的地址\rsentinel announce-ip 192.168.1.11\rsentinel announce-port 36379 docker-compose.yml\r#\rsudo vim /DATA/docker-compose.yml\rversion: \u0026#39;3\u0026#39; # 使用docker-compose版本3\rservices: # 定义服务\rredis7:\rimage: redis:7.0.4\rcontainer_name: redis7\ruser: \u0026#34;996:986\u0026#34;\rrestart: always\rports:\r- 63790:63790\renvironment:\rTZ: \u0026#34;Asia/Shanghai\u0026#34;\rvolumes:\r- /DATA/redis/config/redis.conf:/etc/redis/redis.conf\r- /DATA/redis/data:/data\rcommand: [\u0026#34;redis-server\u0026#34;, \u0026#34;/etc/redis/redis.conf\u0026#34;]\rsentinel:\rimage: redis:7.0.4\rcontainer_name: sentinel\rrestart: always\rports:\r- 36379:26379\rvolumes:\r- /DATA/redis/config/sentinel:/etc/redis/config/sentinel\renvironment:\rTZ: \u0026#34;Asia/Shanghai\u0026#34;\rcommand: [\u0026#34;redis-sentinel\u0026#34;, \u0026#34;/etc/redis/config/sentinel/sentinel.conf\u0026#34;] docker-compose.yml语法验证\r#\rdocker-compose config 子节点配置\r#\rredis.conf\r#\rsudo vim /DATA/redis/config/redis.conf\r# 监听端口 sentinel不知道外面映射啥端口，只好把内外端口设置一样\rport 63790\r# 访问密码\rrequirepass password\r# 数据库数量 使用cluster模式时只会有一个database即DB0\rdatabases 16\r# 绑定本机的网络接口（网卡） 绑定的是网卡的IP地址\r# 0.0.0.0 监听所有 默认127.0.0.1\rbind 0.0.0.0\r# 默认开启\r# 如果没有设置密码和且没有设置bind，只允许本机访问\rprotected-mode yes\r# 单位秒，timeout时间内客户端没有数据交互，关闭连接\rtimeout 60\r# 客户端同时连接的最大数量 默认10000\r# 达到最大值时关闭新连接并返回max number of clients reached\rmaxclients 1000\r# 内存管理 # 最大内存，推荐最大设置为6GB\r# 不要设置过大内存，防止执行RDB内存快照文件或者AOF重写时因为数据太大阻塞太长时间\rmaxmemory 2GB\r# 内存淘汰策略 默认noeviction\r# noeviction -\u0026gt; 不删除任何 key，内存满了直接返回报错\r# 默认情况下slave节点会忽略maxmemory配置，除非被提升为master\r# 只有master会执行内存淘汰策略，master删除key后会发送DEL指令给slave\rmaxmemory-policy noeviction\r# 过期key滞留在内存的比例 默认值为1 表示10%\r# 设置的越小，一次淘汰周期需要消耗的CPU更多 需要删除更多的过期数据\ractive-expire-effort 1\r# 持久化\r# AOF持久化开启\rappendonly yes\r# AOF 持久化模式，默认为 \u0026#34;always\u0026#34;。可以是 always、everysec 或 no\r# always：每个写操作都立即同步到磁盘，最费性能\r# everysec：每秒钟同步一次到磁盘，折中的选择\r# no：完全依赖操作系统的行为，可能会丢失数据，但性能最高\rappendfsync everysec\r# AOF-RDB混合持久化\r# 配置成yes必须先开启AOF AOF重写生成的文件将同时包含RDB和AOF格式内容\r# 推荐开启\raof-use-rdb-preamble yes\r# 性能监控\r# 慢查询日志 执行时间只是命令阶段的时间，不包括建立连接发送回复等\r# slow log 仅保存在内存中，效率很高\r# 执行时间大于多少微秒的查询进行记录 1s = 1,000,000微秒 默认10000\rslowlog-log-slower-than 10000\r# 最多保存多少条慢查询日志 slowlog本身是FIFO 默认128\rslowlog-max-len 128\r# 主从复制\r# replicaof \u0026lt;masterip\u0026gt; \u0026lt;masterport\u0026gt;将当前实例成为master的从节点\rreplicaof 192.168.1.11 63790\r# master节点的requiepass\rmasterauth bucunzaide82838161\r# 从节点只读，默认为yes，建议保留默认配置\rreplica-read-only yes\r# slave每10s Ping一次master\rrepl-ping-replica-period 10\r# slave与master之间的复制超时时间，默认60s\rrepl-timeout 60\r# slave优先级 哨兵使用 默认100\r# master节点挂掉，哨兵选择priority最小的slave节点作为新的master\rreplica-priority 100 sentinel.conf\r#\rsudo scp -P 2222 quanta@192.168.1.11:/DATA/redis/config/sentinel.conf /DATA/redis/config/sentinel.conf 修改配置sentinel ip\nsudo vim /DATA/redis/config/sentinel/sentinel.conf\r# 配置哨兵自身的ip 避免走自动检测给出其他哨兵访问不到的地址\rsentinel announce-ip 192.168.1.1x\rsentinel announce-port 36379 docker-compose.yml\r#\rsudo vim /DATA/docker-compose.yml\rversion: \u0026#39;3\u0026#39; # 使用docker-compose版本3\rservices: # 定义服务\rredis7:\rimage: redis:7.0.4\rcontainer_name: redis7\rrestart: always\rports:\r- 63811:6379\r# 指定时区，保证容器内时间正确\renvironment:\rTZ: \u0026#34;Asia/Shanghai\u0026#34;\rvolumes:\r# 映射配置文件和数据目录\r- /DATA/redis/redis-master.conf:/usr/local/etc/redis/redis.conf\r- ./data/redis-master:/data\r#sysctls:\r# net.core.somaxconn: \u0026#39;511\u0026#39;\rcommand: [\u0026#34;redis-server\u0026#34;, \u0026#34;/usr/local/etc/redis/redis.conf\u0026#34;]\rsentinel:\rimage: redis:7.0.4\rcontainer_name: redis-sentinel-1\rrestart: always\rports:\r- 26379:26379\rvolumes:\r- ./s1/:/usr/local/etc/redis/conf/\r# 指定时区，保证容器内时间正确\renvironment:\rTZ: \u0026#34;Asia/Shanghai\u0026#34;\r# sysctls:\r# net.core.somaxconn: \u0026#39;511\u0026#39;\rcommand: [\u0026#34;redis-sentinel\u0026#34;, \u0026#34;/usr/local/etc/redis/conf/redis-sentinel-1.conf\u0026#34;] docker-compose.yml语法验证\r#\rdocker-compose config 各节点启动\r#\rcd /DATA\rsudo docker-compose up -d redis7\rsudo docker-compose up -d sentinel\r# 停止容器\rsudo docker-compose stop redis7\rsudo docker-compose stop sentinel\r# 删除容器以清空容器的控制台日志\rsudo docker rm redis7\rsudo docker rm sentinel 打开防火墙端口\r#\r# 开放Redis端口给哨兵访问\rsudo ufw allow 63790/tcp\rsudo ufw deny 6379/tcp\r# 开放哨兵端口\rsudo ufw allow 36379/tcp\rsudo ufw deny 26379/tcp 验证哨兵\r#\r# 登录sentinel docker\rsudo docker exec -it sentinel /bin/bash\r# 登录sentinel\rredis-cli -p 26379\r# 查看信息\r# Sentinel部分 master行 显示了masterip:port slave数量 sentinel数量\rinfo\r# 看看哨兵认为目前有哪些主节点、从节点、哨兵节点\rSENTINEL MASTER mymaster\rSENTINEL SLAVES mymaster\rSENTINEL SENTINELS mymaster\r# 强制刷新主从信息\rSENTINEL RESET mymaster\r# sentinel会把一些信息在sentinel.conf里面记录下来\r# 包括选举次数 每次选举结果节点信息等\r# Sentinel重启时会根据sentinel.conf的记录\r# 将上次选举的结果作为主节点\r# 想要日志里面把选举次数、当前主节点清空，就要清理sentinel.conf 日志说明\r#\r1:X 17 Feb 2025 20:44:53.226 * Running mode=sentinel, port=26379.\r1:X 17 Feb 2025 20:44:53.228 * Sentinel new configuration saved on disk\r1:X 17 Feb 2025 20:44:53.228 # Sentinel ID is 6b8d5f11db078b21d5251456f5f7d5b4c117c3c9\r# 主节点监控\r1:X 17 Feb 2025 20:44:53.228 # +monitor master mymaster 192.168.1.11 63790 quorum 2\r# 从节点监控\r1:X 17 Feb 2025 20:45:03.273 * +slave slave 192.168.1.12:63790 192.168.1.12 63790 @ mymaster 192.168.1.11 63790\r1:X 17 Feb 2025 20:45:03.277 * Sentinel new configuration saved on disk\r# sentinel节点互相发现\r1:X 17 Feb 2025 20:45:03.617 * +sentinel sentinel cb3cce637d7611c93785059ebd3dd6c4a5a5d6ad 192.168.1.12 36379 @ mymaster 192.168.1.11 63790\r1:X 17 Feb 2025 20:45:03.620 * Sentinel new configuration saved on disk\r# sentinel节点互相发现\r1:X 17 Feb 2025 20:45:12.053 * +sentinel sentinel b4979ced54d276d73a9a16fb9ad1935e0e8a5e20 192.168.1.13 36379 @ mymaster 192.168.1.11 63790\r1:X 17 Feb 2025 20:45:12.056 * Sentinel new configuration saved on disk\r# 从节点监控\r1:X 17 Feb 2025 20:45:13.285 * +slave slave 192.168.1.13:63790 192.168.1.13 63790 @ mymaster 192.168.1.11 63790 验证主从\r#\r# 主从节点登录redis\rsudo docker exec -it redis7 /bin/bash\rredis-cli -p 63790 -a bucunzaide82838161\rinfo replication 故障转移测试\r#\r停机操作\r#\r# 停止主节点\rsudo docker-compose stop redis7\r# 查看sentinel日志\rsudo docker logs --tail 100 -f sentinel 日志说明\r#\r1:X 17 Feb 2025 20:45:13.290 * Sentinel new configuration saved on disk\r# 主观下线\r1:X 17 Feb 2025 21:06:53.259 # +sdown master mymaster 192.168.1.11 63790\r# 两个节点投票 客观下线\r1:X 17 Feb 2025 21:06:53.315 # +odown master mymaster 192.168.1.11 63790 #quorum 2/2\r# 第一次选举\r1:X 17 Feb 2025 21:06:53.315 # +new-epoch 1\r# 尝试对主节点故障转移\r1:X 17 Feb 2025 21:06:53.315 # +try-failover master mymaster 192.168.1.11 63790\r1:X 17 Feb 2025 21:06:53.318 * Sentinel new configuration saved on disk\r# 本哨兵投票\r1:X 17 Feb 2025 21:06:53.318 # +vote-for-leader 6b8d5f11db078b21d5251456f5f7d5b4c117c3c9 1\r# 其他哨兵投票\r1:X 17 Feb 2025 21:06:53.324 # b4979ced54d276d73a9a16fb9ad1935e0e8a5e20 voted for 6b8d5f11db078b21d5251456f5f7d5b4c117c3c9 1\r# 其他哨兵投票\r1:X 17 Feb 2025 21:06:53.325 # cb3cce637d7611c93785059ebd3dd6c4a5a5d6ad voted for 6b8d5f11db078b21d5251456f5f7d5b4c117c3c9 1\r# 为旧主节点的故障转移 选举领导者\r1:X 17 Feb 2025 21:06:53.385 # +elected-leader master mymaster 192.168.1.11 63790\r# 为旧主节点的故障转移 选择合适的从节点\r1:X 17 Feb 2025 21:06:53.385 # +failover-state-select-slave master mymaster 192.168.1.11 63790\r# 为旧主节点的故障转移 选择了合适的从节点13 从节点13属于旧主节点11\r1:X 17 Feb 2025 21:06:53.452 # +selected-slave slave 192.168.1.13:63790 192.168.1.13 63790 @ mymaster 192.168.1.11 63790\r# 向选中的节点发送slaveof no one命令，让它不再作为其他节点的从节点，为提升为主节点做准备\r1:X 17 Feb 2025 21:06:53.452 * +failover-state-send-slaveof-noone slave 192.168.1.13:63790 192.168.1.13 63790 @ mymaster 192.168.1.11 63790\r# 等待13节点完成提升为主节点的操作\r1:X 17 Feb 2025 21:06:53.508 * +failover-state-wait-promotion slave 192.168.1.13:63790 192.168.1.13 63790 @ mymaster 192.168.1.11 63790\r1:X 17 Feb 2025 21:06:54.305 * Sentinel new configuration saved on disk\r# 13成功提升为主节点 之前是11的从节点\r1:X 17 Feb 2025 21:06:54.305 # +promoted-slave slave 192.168.1.13:63790 192.168.1.13 63790 @ mymaster 192.168.1.11 63790\r# 进入故障转移的重新配置从节点阶段 原主节点是11\r1:X 17 Feb 2025 21:06:54.305 # +failover-state-reconf-slaves master mymaster 192.168.1.11 63790\r# 向原先11的从节点12 发送了重新配置的命令\r1:X 17 Feb 2025 21:06:54.369 * +slave-reconf-sent slave 192.168.1.12:63790 192.168.1.12 63790 @ mymaster 192.168.1.11 63790\r# 从节点12正在更新自己的配置指向新的主节点\r1:X 17 Feb 2025 21:06:54.517 * +slave-reconf-inprog slave 192.168.1.12:63790 192.168.1.12 63790 @ mymaster 192.168.1.11 63790\r# 从节点12完成了重新配置操作 指向了新的主节点\r1:X 17 Feb 2025 21:06:54.517 * +slave-reconf-done slave 192.168.1.12:63790 192.168.1.12 63790 @ mymaster 192.168.1.11 63790\r# 旧节点11的故障转移操作结束\r1:X 17 Feb 2025 21:06:54.583 # +failover-end master mymaster 192.168.1.11 63790\r# 记录主节点切换完毕 原主节点11切换为新主节点13\r1:X 17 Feb 2025 21:06:54.583 # +switch-master mymaster 192.168.1.11 63790 192.168.1.13 63790\r# 记录12为从节点\r1:X 17 Feb 2025 21:06:54.372 * +slave slave 192.168.1.12:63790 192.168.1.12 63790 @ mymaster 192.168.1.13 63790\r# 记录11变为从节点 虽然下线了\r1:X 17 Feb 2025 21:06:54.372 * +slave slave 192.168.1.11:63790 192.168.1.11 63790 @ mymaster 192.168.1.13 63790\r1:X 17 Feb 2025 21:06:54.378 * Sentinel new configuration saved on disk\r# 记录11节点主观下线 +是增加主观下线标记\r1:X 17 Feb 2025 21:07:24.410 # +sdown slave 192.168.1.11:63790 192.168.1.11 63790 @ mymaster 192.168.1.13 63790 故障恢复\r#\r# 重启旧主节点\rsudo docker-compose start redis7\r# 查看sentinel日志\rsudo docker logs --tail 100 -f sentinel 日志说明\r#\r# 移除11 的主观下线标记\r1:X 17 Feb 2025 21:45:58.909 # -sdown slave 192.168.1.11:63790 192.168.1.11 63790 @ mymaster 192.168.1.13 63790\r# 转换11为新主节点13的从节点\r1:X 17 Feb 2025 21:46:08.884 * +convert-to-slave slave 192.168.1.11:63790 192.168.1.11 63790 @ mymaster 192.168.1.13 63790 服务发现和故障转移过程（哨兵选举）\r#\r服务发现\nsentinel根据配置指定的master监控master并通信 master知道slave的信息 sentinel根据redis的sub/pub机制获取其他sentinel信息 故障转移\n主节点下线后，一段时间sentinel ping主节点不通，记录主节点主观下线，并通知其他sentinel 认为主节点主观下线的sentinel个数超过quorm个数，也就是半数以上，标记主节点客观下线，开启故障转移流程 各sentinel开始投票选择节点作为主节点，并选择一个sentinel协调故障转移流程 获得选票过半的节点被选中准备提升为主节点 sentinel向被选中节点发送提升主节点命令，并等待其完成转换 被选中节点提升为新主节点后，sentinel向其他节点发送转换新主节点的信息 其他节点完成转换后，集群主节点状态转换完毕 旧主节点被记录为新主节点的从节点 旧主节点上线后，sentinel告知他将自己转换为新主节点的从节点 "},{"id":8,"href":"/codestack/docs/deploy/elasticsearch/","title":"ElasticSearch","section":"部署","content":"\rElasticSearch\r#\r安装版本：8.15.0\n部署方式：三节点\n运行方式：docker-compose\nLinux系统设置\r#\r# 修改内核参数\r# 设置每个进程最多拥有的最大内存映射区域数量 默认65536对ES来说不足\recho \u0026#34;vm.max_map_count=262144\u0026#34; | sudo tee -a /etc/sysctl.conf\rsudo sysctl -p 创建目录\r#\rsudo mkdir /DATA/es /DATA/es/data /DATA/es/logs /DATA/es/plugins /DATA/es/config 权限设置\r#\rsudo chmod -R 777 /DATA/es/data /DATA/es/logs /DATA/es/plugins /DATA/es/config 各单节点启动获取官方配置\r#\rsudo vim /DATA/docker-compose.yml\rversion: \u0026#39;3\u0026#39;\rservices:\res:\rimage: docker.elastic.co/elasticsearch/elasticsearch:8.15.0\rcontainer_name: es\rrestart: always\renvironment:\r- \u0026#34;ES_JAVA_OPTS=-Xms4g -Xmx4g\u0026#34; # 宿主机最大内存的一半 再留点给其他应用\r- \u0026#34;ELASTIC_PASSWORD=bucunzaide2333\u0026#34;\r- \u0026#34;TZ=Asia/Shanghai\u0026#34;\rports:\r- \u0026#34;19200:19200\u0026#34;\r- \u0026#34;19300:19300\u0026#34;\rvolumes:\r- /DATA/es/data:/usr/share/elasticsearch/data\r- /DATA/es/logs:/usr/share/elasticsearch/logs\r- /etc/hosts:/etc/hosts\r- es_config:/usr/share/elasticsearch/config\r- /DATA/es/plugins:/usr/share/elasticsearch/plugins\rulimits:\r# mmap 映射内存不限制\rmemlock:\rsoft: -1 hard: -1\r# 文件描述符打开个数修改 nofile: soft: 65535 hard: 65535\r# 末尾添加 作用是不要让宿主机空目录覆盖\rvolumes:\res_config:\rdriver: local\rdriver_opts:\rtype: none\rdevice: /DATA/es/config\ro: bind #mmap 映射内存不限制\nES底层lucene底层使用mmap映射磁盘文件\nmemlock本意是限制内存映射的大小，默认为64KB，不够，修改为不用限制大小\n#文件描述符打开个数修改\nElasticsearch 需要打开大量的文件来处理索引数据、日志文件以及网络连接\n如果文件描述符的数量不足，导致“Too many open files” 和频繁的文件关闭和重新打开操作，从而降低性能\nElasticsearch 官方推荐将 nofile 的 soft 和 hard 值设置为 65535 或更高\nsoft （软限制）：是当前生效的限制值，用户可以动态调整，但不能超过 hard 限制。\nhard （硬限制）：是系统允许的最大值，用户无法超过这个限制\n# 启动 三个节点的es\rsudo docker-compose up -d es\r# 验证节点状态\rcurl --cacert /DATA/es/config/certs/http_ca.crt -u elastic:bucunzaide2333 https://localhost:19200/_cluster/health?pretty 生成和复制节点间传输层证书\r#\r# 进入一个节点的 docker\rsudo docker exec -it es /bin/bash\r./bin/elasticsearch-certutil ca\r# Please enter the desired output file [elastic-stack-ca.p12]:\r# 直接空格默认文件名和路径\r# Enter password for elastic-stack-ca.p12 :\r# 设置密码 2333\r# 用刚生成的CA证书生成节点证书\r# elastic-stack-ca.p12在/usr/share/elasticsearch 目录下 # 在这个目录执行，elastic-certificates.p12也生成在这个目录下\r./bin/elasticsearch-certutil cert --ca elastic-stack-ca.p12\r# Enter password for CA (elastic-stack-ca.p12) : # 输入CA证书的密码 密码 2333\r# Enter password for elastic-certificates.p12 :\r# 输入节点证书的密码，设置密码 2333\r# 生成的证书都移动到config/certs目录下\rmv elastic-certificates.p12 config/certs/\rmv elastic-stack-ca.p12 config/certs/\rexit\r# 各个节点都需要这两个文件 复制到各节点\rscp -P 2222 quanta@192.168.1.11:/DATA/es/config/certs/elastic-certificates.p12 /DATA/es/config/certs\rscp -P 2222 quanta@192.168.1.11:/DATA/es/config/certs/elastic-stack-ca.p12 /DATA/es/config/certs\r# 密码加入各节点的信任库 覆盖原本的设置y\r# 提示输入节点证书密码 2333\rsudo docker exec -it es /bin/bash\r./bin/elasticsearch-keystore add xpack.security.transport.ssl.keystore.secure_password\r./bin/elasticsearch-keystore add xpack.security.transport.ssl.truststore.secure_password\rexit\r# https证书保持各节点自己的 各类客户端访问不使用https\r# 检查https是否可以访问 curl访问-k跳过证书验证 浏览器https高级继续 （不认自签名证书）\rcurl -k --cacert /DATA/es/config/certs/http_ca.crt -u elastic:bucunzaide2333 https://localhost:19200/_cluster/health?pretty 修改各节点 elasticsearch.yml 文件\r#\rsudo vim /DATA/es/config/elasticsearch.yml\r# 集群名称 每个节点相同 根据他生成 cluster_uuid\r# cluster_uuid 相同的加入同一个集群，修改后只能删除data目录重来\rcluster.name: \u0026#34;es-cluster\u0026#34;\r# 节点名称 每个节点不同\rnode.name: \u0026#34;es-node1\u0026#34;\r# 节点主机名 在/etc/hosts换节点ip用\rnetwork.publish_host: dataserver1\rnetwork.host: 0.0.0.0\rtransport.port: 19300\rhttp.port: 19200\r#----------------------- BEGIN SECURITY AUTO CONFIGURATION -----------------------\r#\r# The following settings, TLS certificates, and keys have been automatically # generated to configure Elasticsearch security features on 28-02-2025 09:24:45\r#\r# --------------------------------------------------------------------------------\r# Enable security features\rxpack.security.enabled: true\rxpack.security.enrollment.enabled: true\r# Enable encryption for HTTP API client connections, such as Kibana, Logstash, and Agents\r# 关闭https访问\rxpack.security.http.ssl:\renabled: false\rkeystore.path: certs/http.p12\r# Enable encryption and mutual authentication between cluster nodes\rxpack.security.transport.ssl:\renabled: true\rverification_mode: certificate\rkeystore.path: certs/elastic-certificates.p12\rtruststore.path: certs/elastic-certificates.p12\r# Create a new cluster with the current node only\r# Additional nodes can still join the cluster later\rcluster.initial_master_nodes: [\u0026#34;es-node1\u0026#34;, \u0026#34;es-node2\u0026#34;, \u0026#34;es-node3\u0026#34;]\rdiscovery.seed_hosts: [\u0026#34;dataserver1\u0026#34;, \u0026#34;dataserver2\u0026#34;, \u0026#34;dataserver3\u0026#34;]\r#----------------------- END SECURITY AUTO CONFIGURATION -------------------------\r# 节点间复制并修改节点名和publish_host\rscp -P 2222 user@ip:/DATA/es/config/elasticsearch.yml /DATA/es/config/elasticsearch.yml\rsudo vim /DATA/es/config/elasticsearch.yml\r# 修改各节点防火墙\rsudo ufw allow 19200/tcp sudo ufw allow 19300/tcp\rsudo ufw delete allow 9200/tcp sudo ufw delete allow 9300/tcp\r# 重启各节点\rsudo docker-compose down es\r# 删除 data目录下的内容 因为修改了cluster_name\rsudo rm -rf /DATA/es/data/*\rsudo docker-compose up -d es 启动并验证\r#\rsudo docker-compose up -d es\r# 验证节点状态\rcurl -u elastic:bucunzaide2333 http://localhost:19200/_cluster/health?pretty\r{\r\u0026#34;cluster_name\u0026#34; : \u0026#34;docker-cluster\u0026#34;,\r# green ：所有主分片和副本分片都已分配，集群状态良好。\r# yellow ：所有主分片已分配，但部分副本分片未分配。\r# red ：部分主分片未分配，集群状态不佳\r\u0026#34;status\u0026#34; : \u0026#34;green\u0026#34;,\r# 本次查询是否超时\r\u0026#34;timed_out\u0026#34; : false,\r# 集群节点数量\r\u0026#34;number_of_nodes\u0026#34; : 3,\r# 集群数据节点数量\r\u0026#34;number_of_data_nodes\u0026#34; : 3,\r\u0026#34;active_primary_shards\u0026#34; : 0,\r\u0026#34;active_shards\u0026#34; : 0,\r\u0026#34;relocating_shards\u0026#34; : 0,\r\u0026#34;initializing_shards\u0026#34; : 0,\r\u0026#34;unassigned_shards\u0026#34; : 0,\r\u0026#34;delayed_unassigned_shards\u0026#34; : 0,\r\u0026#34;number_of_pending_tasks\u0026#34; : 0,\r\u0026#34;number_of_in_flight_fetch\u0026#34; : 0,\r\u0026#34;task_max_waiting_in_queue_millis\u0026#34; : 0,\r\u0026#34;active_shards_percent_as_number\u0026#34; : 100.0\r}\rcurl -u elastic:bucunzaide2333 http://localhost:19200/_cat/nodes?pretty\r192.168.1.13 13 71 2 0.07 0.31 0.22 cdfhilmrstw - es-node3\r192.168.1.12 14 71 2 0.24 0.38 0.26 cdfhilmrstw - es-node2\r192.168.1.11 18 53 2 0.07 0.30 0.22 cdfhilmrstw * es-node1 设置内置用户和密码\r#\rsudo docker exec -it es /bin/bash\r./bin/elasticsearch-reset-password -i -u kibana_system\r# 多节点验证是否可以登录\rcurl -u kibana_system:bucunzaide2333 http://localhost:19200/_cat/nodes?pretty 用户和密码单独索引在security 数据目录挂载出来的情况下可以在docker重启后沿用\n安装kibana(单节点)\r#\r目录和权限\r#\rsudo mkdir -p /DATA/kibana/config /DATA/kibana/data\rsudo chmod -R 777 /DATA/kibana/config /DATA/kibana/data 启动kibana\r#\rsudo vim /DATA/docker-compose.yml\rversion: \u0026#39;3\u0026#39;\rservices:\rkibana:\rimage: kibana:8.15.0\rcontainer_name: kibana\rrestart: always\renvironment:\r- \u0026#34;TZ=Asia/Shanghai\u0026#34;\rports:\r- \u0026#34;15601:15601\u0026#34;\rvolumes:\r- kibana_config:/usr/share/kibana/config\r- /DATA/kibana/data:/usr/share/kibana/data\r- /etc/hosts:/etc/hosts\rvolumes:\rkibana_config:\rdriver: local\rdriver_opts:\rtype: none\rdevice: /DATA/kibana/config\ro: bind\rsudo docker-compose up -d kibana 修改 kibana.yml 配置文件\r#\rsudo vim /DATA/kibana/config/kibana.yml\rserver.host: \u0026#34;0.0.0.0\u0026#34;\rserver.port: 15601\rserver.shutdownTimeout: \u0026#34;5s\u0026#34;\relasticsearch.hosts: [ \u0026#34;http://dataserver1:19200\u0026#34; ]\relasticsearch.username: \u0026#34;kibana_system\u0026#34;\relasticsearch.password: \u0026#34;bucunzaide2333\u0026#34;\ri18n.locale: \u0026#34;en\u0026#34;\rmonitoring.ui.container.elasticsearch.enabled: true\rsudo docker-compose restart kibana 打开防火墙并验证访问\r#\rsudo ufw allow 15601/tcp\rhttp://192.168.1.11:15601/\r# 在 dev_tools 中尝试查询\r# es集群健康状态\rGET _cat/health?v\r# es集群节点个数\rGET _cat/nodes?v\r# es 集群索引\rGET _cat/indices?v\r# 查看插件列表\rGET /_cat/plugins?v 安装IK分词器(每个节点都要装)\r#\r# 安装 每个节点都需要装\rsudo docker exec -it es /bin/bash\rbin/elasticsearch-plugin install https://get.infini.cloud/elasticsearch/analysis-ik/8.15.0\rexit\r# 重启es\rsudo docker-compose restart es\r# 移除 ik 分词器\r./bin/elasticsearch-plugin remove analysis-ik\r# kibana 查看插件列表\rGET /_cat/plugins?v\rname component version\res-node2 analysis-ik 8.15.0\res-node1 analysis-ik 8.15.0\res-node3 analysis-ik 8.15.0 测试IK分词器\r#\rik分词器提供了两种分词方式\n# ik_smart 智能分词\r# 会做最粗粒度的拆分, 比如会将\u0026#34;中华国歌\u0026#34;分成如下\u0026#34;中华\u0026#34;, “国歌”\r# 适合 Phrase 查询\rPOST /_analyze\r{\r\u0026#34;analyzer\u0026#34;: \u0026#34;ik_smart\u0026#34;,\r\u0026#34;text\u0026#34;: \u0026#34;我爱北京天安门\u0026#34;\r}\r# result\r# 我 爱 北京 天安门\r{\r\u0026#34;tokens\u0026#34;: [\r{\r\u0026#34;token\u0026#34;: \u0026#34;我\u0026#34;,\r\u0026#34;start_offset\u0026#34;: 0,\r\u0026#34;end_offset\u0026#34;: 1,\r\u0026#34;type\u0026#34;: \u0026#34;CN_CHAR\u0026#34;,\r\u0026#34;position\u0026#34;: 0\r},\r{\r\u0026#34;token\u0026#34;: \u0026#34;爱\u0026#34;,\r\u0026#34;start_offset\u0026#34;: 1,\r\u0026#34;end_offset\u0026#34;: 2,\r\u0026#34;type\u0026#34;: \u0026#34;CN_CHAR\u0026#34;,\r\u0026#34;position\u0026#34;: 1\r},\r{\r\u0026#34;token\u0026#34;: \u0026#34;北京\u0026#34;,\r\u0026#34;start_offset\u0026#34;: 2,\r\u0026#34;end_offset\u0026#34;: 4,\r\u0026#34;type\u0026#34;: \u0026#34;CN_WORD\u0026#34;,\r\u0026#34;position\u0026#34;: 2\r},\r{\r\u0026#34;token\u0026#34;: \u0026#34;天安门\u0026#34;,\r\u0026#34;start_offset\u0026#34;: 4,\r\u0026#34;end_offset\u0026#34;: 7,\r\u0026#34;type\u0026#34;: \u0026#34;CN_WORD\u0026#34;,\r\u0026#34;position\u0026#34;: 3\r}\r]\r}\r# ik_max_word 是最细粒度的分词模式，会尽可能多地输出分词结果 穷举所有可能 中文语法下的\r# 适合 Term Query 查询\rPOST /_analyze\r{\r\u0026#34;analyzer\u0026#34;: \u0026#34;ik_max_word\u0026#34;,\r\u0026#34;text\u0026#34;: \u0026#34;我爱北京天安门\u0026#34;\r}\r# result\r# 我 爱 北京 天安门 天安 门\r{\r\u0026#34;tokens\u0026#34;: [\r{\r\u0026#34;token\u0026#34;: \u0026#34;我\u0026#34;,\r\u0026#34;start_offset\u0026#34;: 0,\r\u0026#34;end_offset\u0026#34;: 1,\r\u0026#34;type\u0026#34;: \u0026#34;CN_CHAR\u0026#34;,\r\u0026#34;position\u0026#34;: 0\r},\r{\r\u0026#34;token\u0026#34;: \u0026#34;爱\u0026#34;,\r\u0026#34;start_offset\u0026#34;: 1,\r\u0026#34;end_offset\u0026#34;: 2,\r\u0026#34;type\u0026#34;: \u0026#34;CN_CHAR\u0026#34;,\r\u0026#34;position\u0026#34;: 1\r},\r{\r\u0026#34;token\u0026#34;: \u0026#34;北京\u0026#34;,\r\u0026#34;start_offset\u0026#34;: 2,\r\u0026#34;end_offset\u0026#34;: 4,\r\u0026#34;type\u0026#34;: \u0026#34;CN_WORD\u0026#34;,\r\u0026#34;position\u0026#34;: 2\r},\r{\r\u0026#34;token\u0026#34;: \u0026#34;天安门\u0026#34;,\r\u0026#34;start_offset\u0026#34;: 4,\r\u0026#34;end_offset\u0026#34;: 7,\r\u0026#34;type\u0026#34;: \u0026#34;CN_WORD\u0026#34;,\r\u0026#34;position\u0026#34;: 3\r},\r{\r\u0026#34;token\u0026#34;: \u0026#34;天安\u0026#34;,\r\u0026#34;start_offset\u0026#34;: 4,\r\u0026#34;end_offset\u0026#34;: 6,\r\u0026#34;type\u0026#34;: \u0026#34;CN_WORD\u0026#34;,\r\u0026#34;position\u0026#34;: 4\r},\r{\r\u0026#34;token\u0026#34;: \u0026#34;门\u0026#34;,\r\u0026#34;start_offset\u0026#34;: 6,\r\u0026#34;end_offset\u0026#34;: 7,\r\u0026#34;type\u0026#34;: \u0026#34;CN_CHAR\u0026#34;,\r\u0026#34;position\u0026#34;: 5\r}\r]\r} "},{"id":9,"href":"/codestack/docs/deploy/minio/","title":"MinIO","section":"部署","content":"\rMinIO\r#\r部署方式：单节点\n运行方式：docker-compose\n目录创建\r#\rsudo mkdir /DATA/minio /DATA/minio/data /DATA/minio/config docker-compose.yml\r#\rsudo vim /DATA/docker-compose.yml\rservices:\rminio:\rimage: minio/minio\rrestart: always\rmem_limit: 1G\rports:\r- \u0026#34;9000:9000\u0026#34;\r- \u0026#34;19001:9001\u0026#34;\rcontainer_name: minio\rcommand: server /data --console-address \u0026#34;:9001\u0026#34;\renvironment:\r- MINIO_ROOT_USER=admin\r- MINIO_ROOT_PASSWORD=_admin123\r- MINIO_BROWSER_DEFAULT_LOCALE=zh_CN\rvolumes:\r- /DATA/minio/data:/data\r- /DATA/minio/config:/root/.minio 9000 是MInIO S3 API端口 9001 是MinIO WebUI 控制台端口 需要的节点才映射出来即可\n启动\r#\rsudo docker-compose up -d minio 防火墙打开\r#\rsudo ufw allow 19001/tcp "},{"id":10,"href":"/codestack/docs/deploy/","title":"部署","section":"Docs","content":"\r部署\r#\r"},{"id":11,"href":"/codestack/docs/basic/net/application/http/","title":"HTTP","section":"应用层","content":"\rHTTP\r#\rHTTP是应用层的，基于TCP的超文本传输协议\n无状态：协议自身不对请求和响应之间的通信状态进行保存，任何两次请求之间没有依赖关系 无连接：每次连接只处理一个请求 使用80作为默认端口 报文结构\r#\r请求报文\r#\r请求报文总体四个部分\n请求行 包括请求方法、URL、协议版本，彼此使用空格分隔 请求头 KV形式的辅助信息 空行 分隔报头(请求行+请求头)和请求体，由回车符和换行符组成 请求体 请求发送时携带的数据 请求行\n方法 说明 支持的HTTP协议版本 GET 获取资源 1.0，1.1 POST 传输实体主体(提交信息) 1.0，1.1 PUT 传输文件 1.0，1.1 HEAD 获得报文首部 1.0，1.1 DELETE 删除文件 1.0，1.1 OPTIONS 询问支持的方法 1.1 TRACE 追踪路径 1.1 CONNECT 要求用隧道协议连接代理 1.1 LINK 建立和资源之间的联系 1.0 UNLINE 断开连接关系 1.0 请求头\n请求头 含义 示例 Cache-Control 用于控制缓存策略，设置缓存的行为，如是否允许缓存、缓存时间、缓存验证方式等 Cache-Control: max-age=3600 Connection 指示客户端和服务器之间的连接选项，常见值有 keep-alive 和 close，分别表示保持连接和关闭连接 Connection: keep-alive Date 表示请求发送的日期和时间，采用 HTTP 日期格式，服务器可据此进行时间相关处理 Date: Wed, 18 Apr 2025 12:00:00 GMT Accept 告知服务器客户端能够接受的响应内容类型，服务器会根据此选择合适的内容格式返回 Accept: text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8 Accept-Encoding 指定客户端能够接受的编码方式，如 gzip、deflate 等，服务器会对响应数据进行相应的编码压缩 Accept-Encoding: gzip, deflate Accept-Language 表示客户端偏好的语言，服务器可根据此返回对应语言的内容 Accept-Language: en-US,en;q=0.9,zh-CN;q=0.8,zh;q=0.7 Host 指定请求的目标主机和端口号，用于区分同一服务器上的不同虚拟主机或服务 Host: www.example.com:8080 Referer 标识请求发起的来源页面的 URL，服务器可以借此了解请求的上下文和来源路径 Referer: https://www.example.com/page1.html User-Agent 包含客户端的相关信息，如浏览器类型、版本、操作系统等，服务器可根据此进行不同的适配和处理 User-Agent: Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/112.0.5615.137 Safari/537.36 Content-Type 用于 POST、PUT 等请求，指示请求体中数据的类型，如 application/json、application/x-www-form-urlencoded、multipart/form-data 等 Content-Type: application/json Content-Length 表示请求体的长度，以字节为单位，服务器可据此判断是否完整接收了请求数据 Content-Length: 1024 响应报文\r#\r响应报文总体四个部分：\n状态行：包含协议版本、状态码，状态码描述 响应头：响应体的KV形式附属信息 空行：回车符和换行符组成，分隔报头和响应体 响应体：响应的数据 常用状态码含义 1xx多用于实验场景\n状态码 含义 200 OK 请求成功，服务器已成功处理请求并返回了请求的资源。 201 Created 请求成功，并且服务器创建了一个新的资源。通常在使用 POST 方法创建新资源时返回。 204 No Content 请求成功，但服务器没有返回任何内容。常用于只需要执行某个操作而不需要返回数据的情况。 301 Moved Permanently 请求的资源已被永久移动到新的 URL。客户端应使用新的 URL 进行后续请求。 302 Found 请求的资源临时移动到了新的 URL。客户端应使用新的 URL 进行本次请求，但后续请求仍可使用原 URL。 304 Not Modified 客户端发送了附带条件的请求（如 If - Modified - Since 等头信息），服务器认为资源未被修改，客户端可以使用缓存的资源。 400 Bad Request 客户端发送的请求有语法错误或不符合请求规范，服务器无法理解请求。 401 Unauthorized 客户端请求需要身份验证，但客户端未提供有效的身份凭证或凭证无效。 403 Forbidden 服务器理解请求，但拒绝执行该请求，通常是因为客户端没有足够的权限访问资源。 404 Not Found 服务器无法找到请求的资源。可能是 URL 输入错误或资源已被删除。 405 Method Not Allowed 客户端请求使用的方法（如 GET、POST 等）不被服务器允许用于请求的资源。 415 Unsupported Media Type 客户端发送的请求体中的数据格式不被服务器支持，如服务器不支持请求的 Content - Type。 500 Internal Server Error 服务器内部发生错误，无法完成请求。通常是服务器端的代码出现异常或配置问题。 502 Bad Gateway 服务器作为网关或代理，从上游服务器收到了无效的响应。 503 Service Unavailable 服务器暂时无法处理请求，通常是因为服务器过载或正在进行维护。 504 Gateway Time - out 服务器作为网关或代理，在等待上游服务器响应时超时。 多版本差异\r#\rHTTP/0.9 1991年发布。极其简单，只能传输纯文本，仅支持GET请求，没有HTTP头信息和状态码.服务器只能回复HTML格式字符串，不能回应别的格式\n已被弃用\nHTTP/1.0 1996年发布。\n在0.9基础上扩展了请求方法，包括GET，POST，HEAD 新增了1xx-5xx五类状态码 定义了消息头部 可以支持长连接keep-alive，但需要显式设置 不支持连接复用，每次请求都要建立TCP连接 请求为blocking，下一个请求发送必须在收到前一个请求包的响应包后 导致：请求延迟大，网络带宽不能充分利用 队头阻塞：在计算机网络范畴中是性能首先的现象\n是一列数据的第一个数据包(队头)被阻塞，导致整列数据包受阻的现象\nTCP会引起队头阻塞，HTTP/1.0也会引起队头阻塞\nHTTP/1.1（目前使用最广泛的版本） 1997年发布\n引入缓存机制 扩展错误状态码 新增Host字段 可以将请求发往一台服务器的不同网站\n在一台WEB服务器上同一个IP地址和端口号上使用不同的主机名的虚拟WEB站点\n也就是使用nginx在收到相同的ip和端口号后针对用户请求的Host再次进行转发\n默认开启keepalive 一个连接被多个请求复用，减少连接建立和断开的开销 请求范围引入range域 引入管道机制 管道机制允许客户端同时发起多个请求，无需等待响应到来 一定程度上缓解了队头阻塞问题，但没有完全解决\n因为服务端是按照接收到请求包的顺序响应的，也就是说如果先后收到请求AB，服务端必须先响应A再响应B\nHTTP/2 必须搭配TLS1.2一起使用，即必须HTTPS 头部和数据用二进制表示，而不再是ASCII的文本 一条连接内支持多条流并行，即多路复用 一条流阻塞不会阻塞其他流，解决了HTTP协议中的队头阻塞问题，但传输层TCP的队头阻塞仍然存在 首部压缩 允许服务器未经请求，主动向客户端发送资源 除了TLS强制使用之外，各个改动极大降低了网络延迟，提升网页加载速度\nHTTP/3 不再采用TCP作为传输层协议，而是使用UDP。UDP不提供可靠保证和流控服务，引入了应用层的QUIC，工作在UDP和HTTP之间。QUIC保证数据有序，拥塞控制等，而且继承了TLS\n在HTTP/2的多路复用解决HTTP队头阻塞基础上，绕开TCP后，完整解决队头阻塞问题；不再需要TCP三次握手，进一步降低请求延迟\n解决连接迁移问题：TCP协议在移动切换到wifi时因为IP改变，需要重建连接。HTTP3采用CID标识一条流，改变IP不会造成影响\n常用机制\r#\r跨域(CORS)处理\r#\r跨域问题源于浏览器的同源策略\n同源策略规定，只有当两个URL的协议、域名和端口都相同时，浏览器才允许他们之间进行资源共享\n当前端服务器所在的域和后端服务器所在的域不相同时，即请求前端用A域名端口，请求后端用B域名端口，则产生跨域问题\n浏览器将在收到服务器响应时阻止跨域\n浏览器接收跨域响应，检查响应头信息，如果相关字段表明当前请求不允许被跨域访问，浏览器将阻止该请求的响应被前端页面获取和处理 所以想要避免跨域问题，可以在后端服务器响应报文中添加相应的字段信息，以避免浏览器阻止跨域 关键字段和含义:\nAccess-Control-Allow-Origin: 指定允许访问该资源的外域URI，可以是具体的域名，也可以用*标识允许所有域名访问（携带凭证如Cookie的请求不能用通配符） Access-Control-Allow-Method：指定服务器允许的跨域请求方法，如GET,POST,PUT,DELETE等 Access-Control-Allow-Credentials：指定是否允许客户端在跨域请求中携带凭证，值为true或false Access-Control-Allow-Headers：列出服务器允许的请求头字段 Access-Control-Expose-Headers：允许客户端访问的响应头。 Access-Control-Max-Age：预检请求的缓存时间（单位：秒） 身份认证与授权\r#\rCookie\r#\rCookie由服务器端生成\n在浏览器请求服务器时，服务端在HTTP响应中携带Set-Cookie: xxx=yyy，以键值对形式表示，如果有多个Cookie键值对，就有多个Set-Cookie\n再次发起请求时，浏览器会自动在Request Header中增加Cookie字段，以Cookie: xxx=yyy; aaa=bbb形式，携带Cookie信息\n通过Cookie，服务器可以为请求设置一些标识，比如通过Cookie知道某些请求来自某些用户等\n浏览器会将Cookie键值对信息缓存在本地，这些键值对信息会以域名为界存储，Cookie也只会被设置到相同域名的请求中，防止不同域名之间的 Cookie 相互干扰和泄露用户信息\n浏览器会根据 Cookie 的过期时间来管理 Cookie。当 Cookie 过期后，浏览器会自动删除该 Cookie\nCookie 还可以设置路径属性，只有当请求的路径与 Cookie 的路径匹配或为其子路径时，浏览器才会发送该 Cookie\n由于 Cookie 存储在用户本地，并且可能包含敏感信息，如用户登录凭证等，因此在使用 Cookie 时需要注意安全性，防止 Cookie 被窃取或篡改\n可以设置Set-Cookie: key=value; HttpOnly 或Set-Cookie: key=value; Secure来增强安全性\nHttpOnly使得该Cookie键值对只能被Http协议(包含Https)访问，不能被Js脚本访问，主要用于防止跨站脚本攻击(XSS)\nSecure使得浏览器仅在HTTPS请求下才发送该Cookie，主要用于防止中间人攻击\nXSS跨站脚本攻击：攻击者通过注入恶意脚本到他的网页中，当用户访问该网页时，恶意脚本会在用户的浏览器中执行。如果网页中的某些敏感信息（如用户的会话 ID、身份验证 Token 等）存储在 Cookie 中，且这些 Cookie 没有设置HttpOnly属性，那么恶意脚本就可以通过 JavaScript 代码（如document.cookie）获取这些 Cookie 信息，进而利用这些信息来模拟用户身份进行恶意操作。而设置了HttpOnly属性后，恶意脚本无法访问这些 Cookie\n中间人攻击：HTTP 协议中，数据是以明文形式传输的，这意味着在数据传输过程中，攻击者可以截获和篡改数据。如果用户的敏感信息存储在 Cookie 中，且这些 Cookie 没有设置Secure属性，那么中间人就有可能截获这些 Cookie 信息，进而利用这些信息来模拟用户身份进行恶意操作。而设置了Secure属性后，只有在使用 HTTPS 协议进行通信时，浏览器才会发送这些 Cookie，而HTTPS数据在传输过程中是加密的，中间人无法截获和篡改数据\nToken\r#\rtoken指令牌或凭证，在Web开发中一般指用户登录凭证\n前端指引用户表单输入信息进行登陆后，登录接口返回token，前端可以将token缓存在本地，每次将token设置在请求中约定的header处便于后端识别请求的用户和用户的登陆状态\n后端产生token，一般是随机字符串，并在后端数据库中与用户信息进行绑定，在请求到来时从约定header中取出token，并用token寻找用户信息，从而知道用户是否登录、接口权限、数据归属等信息\n重定向\r#\r重定向机制主要指服务器返回给客户端的响应中，状态码为302，且Header中由Location字段指定需要客户端重定向到的网址，主要用于服务器在客户端提交表单后并处理成功后，指引客户端跳转到下一个页面，比如登陆后跳转到主页等\n如下代码以SpringMVC为基础开发指引客户端重定向 流式传输\r#\rSSE\r#\rSSE(Server-Sent Events) 服务器发送事件\n客户端发起一个请求，服务器保持连接打开，并不断向客户端发送事件流 后端服务器需要设置响应头Content-Type为text/event-stream，并保持连接打开，不断向客户端发送事件数据\nSSE 的数据格式是简单的文本，每行以特定的字段开头，如data:表示事件数据，event:表示事件类型等。每个事件以两个换行符\\n\\n结尾\n分块传输编码（Chunked Transfer Encoding）\r#\r分块传输编码允许服务器在发送响应时，将数据分成多个块进行传输，而不必事先知道响应的总长度\n前端通常不需要特殊处理，浏览器会自动处理分块传输编码的响应，将接收到的块组合成完整的数据\n后端服务器需要设置响应头Transfer - Encoding为chunked，并按块发送数据。每个块由块的长度（以十六进制表示）和换行符开头，接着是块的数据，最后以换行符结尾\n每个块由块的长度（十六进制表示）、换行符、块数据、换行符组成，最后以长度为 0 的块（0\\r\\n\\r\\n）结束\n缓存\r#\r强缓存\r#\r只要本地的资源在缓存有效期内，直接取本地缓存，避免与服务器交互\nCache-Control: HTTP/1.1用于控制缓存的通用首部字段，有多种指令\nmax-age: 指定资源缓存时间，单位为秒 no-cahce: 需要先与服务器验证资源的有效性，再决定是否使用缓存 no-store: 禁止使用任何缓存\nExpires：是 HTTP/1.0 中用于控制缓存的首部字段\n它指定了一个具体的日期和时间，在这个时间之前，浏览器可以使用本地缓存的资源。不过，由于Expires使用的是服务器的时间，可能会因为客户端和服务器时间不一致而导致缓存失效，因此在 HTTP/1.1 中推荐使用Cache-Control\n协商缓存\r#\r当强缓存失效时，浏览器会向服务器发送一个请求，询问服务器该资源是否有更新\n服务器根据请求中的信息进行判断，如果资源没有更新，则返回 304 状态码，告诉浏览器可以使用本地缓存；如果资源有更新，则返回新的资源和 200 状态码\nETag：是服务器为资源生成的一个唯一标识符\n当资源发生变化时，ETag的值也会相应改变。浏览器在后续请求时，会通过If-None-Match首部字段将之前缓存的ETag值发送给服务器，服务器将其与当前资源的ETag进行比较，如果相同则表示资源未更新。\nLast - Modified：表示资源的最后修改时间\n浏览器在后续请求时，会通过If-Modified-Since首部字段将之前缓存的最后修改时间发送给服务器，服务器将其与当前资源的最后修改时间进行比较，如果相同则表示资源未更新\n缓存策略的应用场景\r#\r频繁更新的资源：对于经常更新的资源，如新闻资讯、实时数据等，建议设置较短的缓存时间或使用no-cache指令，以确保用户能够及时获取到最新的内容。 不经常更新的资源：对于不经常更新的资源，如图片、CSS、JavaScript 文件等，可以设置较长的缓存时间，以减少对服务器的请求，提高网站的性能。 敏感信息资源：对于包含敏感信息的资源，如用户的个人信息、订单信息等，应使用no-store指令，禁止浏览器进行缓存，以确保信息的安全性 一次请求来说明缓存流程\r#\r客户端发起请求，可能是请求网页、图片、服务器数据等 检查强缓存 缓存key内容可能包含请求方法、URL、请求头等\n浏览器查看本地是否有本次请求的缓存资源，同时根据缓存中保存的Cache-Control首部字段的max-age指令或Expires首部字段指定的时间来判断缓存是否过期\n如果缓存资源未过期，直接使用缓存资源，不向服务器请求，即命中强缓存\n如果缓存资源不存在或者已经过期，则检查协商缓存\n检查协商缓存 强缓存未命中，客户端会在请求中携带If-None-Match(对应ETag)和If-Modified-Since(对应Last-Modified)首部字段发送请求给服务器。服务器接收到请求后根据这两个字段来判断资源是否有更新\n如果资源未更新，即ETag和Last-Modified值与客户端发送的一致，服务器返回304 Not Modified状态码。客户端收到后直接使用本地缓存的资源\n资源已更新，服务器返回200 OK状态码和新的资源内容\n客户端更新缓存 客户端收到服务器返回的新资源(状态码200 OK),或者收到304NotFound但缓存已经过期需要更新有效期，会对本地缓存进行替换或者根据服务器的缓存控制信息更新缓存属性\n如果服务器返回Cache-Control首部包含no-cache或no-store，客户端则不使用缓存或删除缓存\n内容协商\r#\r请求方发送头\nAccept 用于告知服务器客户端能够接受的响应内容类型，即媒体类型（MIME 类型）。如Accept: text/html Accept-Encoding 作用：指定客户端能够接受的内容编码方式，服务器可以根据这个字段对响应数据进行相应的编码压缩，以减少数据传输量。 示例：Accept-Encoding: gzip, deflate 表示客户端支持 gzip 和 deflate 两种编码方式 Accept-Language 作用：表示客户端偏好的语言，服务器可以根据这个字段返回对应语言的内容。 示例：Accept - Language: en-US;zh-CN; 表示客户端优先接受中文（中国大陆），其次是美式英语 Accept-Charset 作用：指定客户端能够接受的字符编码，服务器会根据这个字段选择合适的字符编码来发送响应数据。 示例：Accept-Charset: UTF-8 表示客户端优先接受 UTF-8 编码 响应方返回头\nContent-Type 作用：指示响应内容的媒体类型和字符编码。服务器通过这个字段告知客户端响应数据的格式和编码方式。 示例：Content-Type: text/html; charset=UTF-8 表示响应内容是 HTML 格式，使用 UTF-8 字符编码 Content-Encoding 作用：说明响应内容所使用的编码方式，与客户端的 Accept-Encoding 字段相对应。客户端需要根据这个字段对响应数据进行解码。 示例：Content-Encoding: gzip 表示响应数据使用了 gzip 编码。 Content-Language 作用：指定响应内容所使用的语言，与客户端的 Accept-Language 字段相对应。 示例：Content-Language: en - US 表示响应内容使用的是美式英语 常见的数据类型（媒体类型）\n文本类型 text/html：超文本标记语言，用于创建网页。 text/plain：纯文本，没有任何格式。 text/css：层叠样式表，用于定义网页的样式。 text/javascript：JavaScript 代码，用于实现网页的交互效果。 图像类型 image/jpeg：JPEG 图像格式，常用于照片等。 image/png：PNG 图像格式，支持透明通道，常用于图标、图形等。 image/gif：GIF 图像格式，支持动画效果。 应用类型 application/json：JSON（JavaScript Object Notation）数据格式，常用于前后端数据交互。 application/xml：XML（eXtensible Markup Language）数据格式，用于数据的存储和传输。 application/pdf：PDF（Portable Document Format）文档格式，用于跨平台的文档展示。 application/octet - stream：二进制流，通常用于下载文件，服务器不指定具体的文件类型，由客户端自行判断。 "},{"id":12,"href":"/codestack/docs/basic/net/transport/tcp/","title":"TCP","section":"传输层","content":"\rTCP\r#\rTCP是一种面向连接的、可靠的、基于字节流的传输层通信协议\n报文结构\r#\r源端口：发送方使用的端口号，16位 目的端口：接收方使用的端口号，16位 序号：本报文段发送数据的第一个字节的编号，32位 确认号：接收方期望接收到的下一个报文段的第一个字节的编号 数据偏移(首部长度)：指数据段中的数据部分的起始处距离TCP报文段起始处的偏移量，也就是TCP报文的报头部分的长度，接收端根据这个知道数据（有效载荷）从何处开始 4位 保留字段：TCP协议将来的发展预留的空间，目前必须全部为0，6位 标志位字段：共六个标志位，每个1bit 窗口大小：表示发送该TCP报文的接收窗口还可以接受多少字节的数据量，用于TCP的流量控制，16位 校验和：用于确认传输的数据有无损坏。发送端基于数据内容校验生成一个数值，接收端同样生成一个数值进行对比，相同的数据有效，反之无效则丢弃数据包，16位 紧急指针：仅当标志位的URG字段值位1才有意义。指出有效载荷中位紧急数据的字节数。当所有紧急数据处理完，TCP告知应用程序恢复到正常操作。即使接收方窗口大小为0，也可以发送紧急数据，因为紧急数据无需缓存，16位 选项字段：长度不定，但是必须是32bit的整数倍，即4字节的整数倍。内容可变，所以使用首部长度来区分选项部分的具体长度 如何分离首部和载荷（确认首部长度）\r#\rTCP固定首部长度20字节，以及选项字段 首部长度字段为4bits，最大可表示长度为1111，即15。表示单位是4字节 所以TCP首部最长是15*4 = 60字节 固定首部为20字节，选项部分为4字节的倍数，最大为40字节 这说明了数据偏移字段标识首部长度的原理 根据首部长度，可以分离首部和载荷\n连接的建立和断开\r#\rTCP连接是TCP协议在网络中建立的可靠通信链路\n这种可靠指的是不丢包，就是网络不太好的情况下可以尽量保证数据的完整接收（发送确认和重发）\n由IP协议锚定双方地址，由底层协议传输数据包，由高层协议进行数据的加解密\n换言之，TCP的可靠通信链路中保证的是传输和接收数据包的完整性，而不是包揽了链路的实际构建、数据包防伪等过程。不要把可靠性的理解在TCP扩展太多\n为什么要建立连接\r#\r可靠性验证：建立连接的过程实际就是通信双方验证各自的发送和接受能力是否正常，双方的信道是否通畅 协商参数：如序号初始值，MSS，是否启用SACK等 连接的建立 - 三次握手\r#\r服务器初始化状态 服务器端进程函数顺序：socket =\u0026gt; bind =\u0026gt; listen =\u0026gt; accept socket()创建套接字listenfd bind()将套接字和端口绑定 listen()让listenfd成为监听套接字，后续连接通过监听套接字获取，服务器处于监听状态 accept()进程阻塞，直到有客户连接请求到达才返回 客户端发起连接请求 - 第一次握手 客户端进程函数顺序:socket =\u0026gt; connect socket()创建套接字 connect()调用时操作系统自动bind()，然后客户端进程就会向服务端进行发送连接请求报文 连接请求报文首部的标志位SYN=1\n同时选定一个初始序号SEQ=x，x是随机产生的整数\nTCP规定SYN=1的报文段不可以携带数据，但消耗一个序号\n此时客户端进程进入SYN-SENT(同步报文已发送状态)\n服务器同意建立连接，回复确认 - 第二次握手 服务器端进程收到连接请求报文，同意建立连接 从listenfd监听套接字获取客户端信息 服务器端操作系统向客户端发送SYN报文段进行确认 连接确认报文首部标志位SYN=1，ACK=1，确认号ack=x+1\n同时为自己选择一个初始序号seq=y 同样不能携带数据，消耗一个序号\nTCP服务器进入SYN-RCVD(同步报文已收到)状态\n客户端确认连接已经被确认，发送确认连接信息 - 第三次握手 客户端进程收到服务器的确认报文，向服务器发送确认报文表示自己收到 确认报文首部ACK=1，确认号ack=y+1，序号seq=x+1 可以携带数据，不携带数据则不消耗序号\n客户端认为连接建立成功，进入ESTABLISHED(已建立连接)状态，准备发送数据\n服务器收到确认报文，进入ESTABLISHED(已建立连接)状态，准备接受数据\n形象理解和问题\r#\r三次握手的形象理解\r#\r客户端用seq=x标识自己，发送SYN=1的连接请求报文，告诉服务器我想建立连接 服务器用seq=y标识自己，发送ACK=1 SYN=1 确认号ack=x+1的确认报文，告诉客户端我是y，同意了序号x的连接请求 客户端发送确认连接报文ACK=1，确认号ack=y+1，告诉服务器这是序号x的连接确认报文(+1)，而且我收到了seq=y的连接同意信息，我认为我们之间的连接已经建立 服务器收到确认报文，认为连接已经建立 初始序列号SEQ为什么要随机?\r#\rseq序号表示的是发送的TCP报文数据部分的起始字节位置，服务器/客户端可以通过序号正确读取数据。如果不是随机分配起始序列号，那么黑客就会很容易获取客户端与服务器之间TCP通信的初始序列号，然后通过伪造序列号让通信主机读取到携带病毒的TCP报文，发起网络攻击\n服务器没有收到客户端的确认报文怎么办?\r#\r操作系统会给每个处于SYN-RCVD状态的服务器进程设定一个计时器，如果超过一定时间还没有收到客户端第三次握手的ACK确认报文，将会重新发送第二次握手的确认报文，直到重发达到一定次数才会放弃\n为什么不能两次握手?\r#\r两次握手意味着，服务器来确认连接的建立\n如果确认报文丢失，客户端不知道服务器确认连接已经建立，就不会发送数据，服务器会维护不成功的TCP连接 容易遭受SYN洪水攻击，攻击者发送大量的SYN请求连接报文，服务器对每个报文都建立连接，消耗大量资源 可能有已失效的连接报文传输到服务器，服务器维护失效连接 失效连接的产生原因和两次握手的后果 客户端A发送给服务器B连接报文，但报文在某个网路节点滞留，迟迟不到达服务器 客户端A等待服务器B确认报文太久，以至于客户端认为刚才的连接报文失效，不再等待确认报文 服务器B突然收到连接报文，并确认连接发回确认报文 客户端没有在等待确认报文，就不会处理确认报文，也不会向服务器发送数据，于是服务器维护的是一个无效连接\n只要握手次数是偶数次，就会把连接的确认带来的成本转移给服务器\n为什么必须是三次握手?\r#\r奇数次握手，客户端先建立连接 防止已失效的连接报文突然传到服务器，导致错误 三次握手时已失效的连接报文突然传到服务器，服务器发回确认报文 客户端无回复，服务器也不会认为连接确认，不会做接受数据准备等，连接仍然未被建立\n三次是验证双方信道通畅，发送接收能力正常的最小成本 怎么处理SYN洪水攻击?\r#\rSYN Flood是互联网上最原始、最经典的DDoS（Distributed Denial of Service）攻击之一 攻击方式：\n攻击者短时间伪造大量不存在的IP地址，并用这些IP地址向服务器发送大量SYN连接请求报文 服务器需要为每个SYN报文回复ACK，但是一直收不到客户端的ACK报文，就要重发一定次数才放弃，这回非常消耗资源 导致没有资源处理正常的连接，服务器处理连接能力停摆 解决方法：\n缩短SYN Timeout：SYN洪水攻击的效果取决于服务器保持的半连接数量=SYN攻击频率 * SYN Timeout，缩短接收到SYN报文到确认报文废弃并丢弃连接的时间，可以大量减少服务器载荷 设置SYN Cookie：为每个连接请求的IP地址分配Cookie，如果短时间收到某个IP地址的大量连接请求，就不再处理这个IP地址的连接报文 设置防火墙，白名单或者黑名单 连接的断开 - 四次挥手\r#\r客户端发送FIN结束报文 - 第一次挥手 客户端主动断开连接，客户端进程调用close(fd)关闭套接字，操作系统发送FIN结束报文，并停止发送数据，主动关闭TCP连接 FIN结束报文，FIN=1，seq=u，u是前面已发送的最后一个字节的序号+1\n客户端进入FIN_WAIT_1(终止等待)状态，等待服务器发送确认报文\nFIN报文不携带数据，消耗一个序号\n服务器收到，回复确认报文 - 第二次挥手 服务器收到客户端的FIN结束报文，并立即发送确认报文 确认报文ack=u+1，seq=v，v等于服务器之前已发送的数据的最后一个字节的序号+1\n服务器进入CLOSE_WAIT(关闭等待)状态\n服务器通知上层应用程序，客户端不再向服务器发送数据，但服务器如果有数据发送，客户端仍要接受，服务器会继续发送未发完的数据给客户端\nTCP连接处于半关闭状态(half-close)\n客户端收到服务器确认报文后，客户端进入FIN_WAIT2(终止等待2)状态，等待服务器数据发送完，发送FIN结束报文\n服务器发送FIN结束报文 服务器数据发送完毕后，应用进程调用close(fd)通知TCP释放连接，向客户端发送FIN结束报文 结束报文FIN=1，seq=w，w是此前发送数据的最后一个字节序号\n同时需要回复确认号ack=u+1\n服务器进入LASK_ACK(最后确认)状态，等待客户端确认\n客户端收到，回复确认报文 - 第四次挥手 客户端收到服务器FIN结束报文，向服务器发送报告ACK确认报文 确认报文ACK=1，确认号ack=w+1，序号seq=u+1(第一次挥手的FIN报文消耗一个序号)\n客户端进入TIME_WAIT(时间等待状态)\nTCP连接此时仍未被释放，必须经过时间等待器TIME_WAIT timer设置的时间2MSL后，客户端才进入CLOSED状态\nMSL(Maximum Segment Lifetime，最长报文寿命)，是一个TCP报文存活的最长时间，RFC793建议为2分钟，可以根据实际情况设置更小的值\n即客户端进入TIME_WAIT状态后，要经过4分钟才进入CLOESD状态，才可以建立下一个连接 当客户端撤销相应的传输控制快TCB(socket调用前建立)，才算结束TCP连接\n先发起释放连接请求的，后结束TCP连接\n形象理解与问题\r#\r四次挥手的形象理解\r#\r客户端数据发送完毕，决定断开连接，发送结束报文告诉服务器，我最后发送的数据是u，我要断开了 服务器收到，回复收到了关于最后发送数据是u的断开请求，告知我目前最后发送数据是v，我还可能会继续发送数据 客户端收到服务器的确认，知道服务器知道自己要断开，同时知道服务器还会继续发送数据，自己仍须接收，直到收到服务器的结束FIN报文 服务器数据发送完毕，发送FIN结束报文，标示自己这边已经发送完毕数据，可以断开。我的这次断开针对最后收到数据是u的那个连接，我最后发送的数据序号是w 客户端收到服务器说他结束了，回复收到服务器的结束，知道对方发送的最后数据是w。客户端开始等待一段时间2MSL，没什么问题就释放TCP连接 为什么连接是三次握手，关闭是四次挥手？\r#\r建立连接也可以是四次握手，中间服务器发回的SYN和ACK可能被分成两个报文发送 关闭连接时中间服务器给客户端发送的确认报文和FIN结束报文可能合并，如果服务器已经没有数据要发送的话。但是如果还有数据要发送就得分开，发送完数据才发送FIN\nTCP通信是全双工的，发送FIN表示一端不再继续发送，但是还会继续接收。\n收到FIN报文，只是关闭一个方向的连接，TCP处于半关闭状态\n为什么客户端要等待2MSL才进入CLOSED状态？\r#\r保证客户端最后发送的ACK能到达服务器 保证可靠的终止TCP连接。因为如果报文丢失，服务器接收不到ACK报文，处于LAST_ACK状态的服务器会超时重传FIN报文，而客户端能在2MSL时间内收到重传的FIN报文。收到后客户端会重传确认，并重新计时。最后双方可以正常进入CLOSED状态 防止已经失效的连接请求报文出现在本次TCP连接 客户端发送完最后的ACK报文后经过2MSL，可以让本次TCP连接持续时间内产生的所有报文都从网络上消散。下一个新的TCP连接就不会出现旧的请求报文 TIME_WAIT状态何时出现？带来哪些问题？\r#\rTIME_WAIT是发起连接的一方收到对方的FIN结束报文，发出ACK确认报文后进入的状态 TIME_WAIT是为了让TCP报文得以自然消散，被动关闭的一方能够正常关闭连接\n服务器TIME_WAIT：如果短时间内大量关闭客户端连接，会出现大量TIME_WAIT状态，TCP连接没有释放，就会占据大量的tuple数据(包含目的和源IP、协议号、目的和源端口号)，严重消耗服务器资源 客户端TIME_WAIT：短时间大量TIME_WAIT无法释放端口，大量消耗客户端的端口号，只有65535个，消耗完毕就无法开启新的TCP连接 可靠性策略\r#\r校验和（单包数据无损）\r#\rTCP报文首部存在校验和字段，用于验证数据是否完整传输 发送端基于数据内容校验生成一个数值，接收端同样生成一个数值进行对比，相同的数据有效，反之无效则丢弃数据包\n序列号(数据包有序、去重)\r#\rTCP在操作系统中有自己的缓冲区，应用层调用的write、sendto等接口，是将自己定义的额缓冲区数据，拷贝到TCP的发送缓冲区 TCP面向字节流，TCP缓冲区中以字节为单位，将缓冲区划分为类似字符数组的形式，数组自带的下标作为TCP缓冲区字节的编号 TCP传输的每个字节都会按顺序编号 数据可以在接收到后有序拼接 由于网络延迟导致的重发数据重复接收等，可以用序列号去重\n确认应答\r#\rTCP协议规定，接收方接收数据，必须发送确认报文 序列号和确认号是TCP缓冲区的下标\n序列号：是本报文第一个字节的编号。TCP连接中传输的字节流的每个字节都会按顺序编号。序列号x：我给你的第一个字节是编号x的\n确认号：发送方给接收方发送数据，接收方收到数据就要给发送方发送确认报文。确认报文中的确认号表示接收方期望收到发送方下一个报文的第一个字节的编号。确认号y：我期望你下次给我发的第一个字节是编号y的\n接收方收到数据后，根据序列号给出确认号，让发送方知道接收方接受到哪些数据 应答报文ACK=1，此时确认号字段才有效\n确认应答可以提升通信效率 发送方完全可以一次性发送多个报文，每个报文是不同段的数据\n如果中间确认应答丢失，但是只要收到靠后确认号的应答，就可以确认前面的数据接收方已经收到 如果靠前序列号的报文丢失，接收方即使收到了后面序列号的数据，也只会给发送方返回丢失之前的序号的确认应答。前面的丢失报文由这个确认应答触发重传，而后面的发送报文没有返回确认报文，触发超时重传。 超时重传\r#\r数据在网络传输过程中可能丢包 发送方的发送报文和接收方的确认报文都可能丢失 都会导致发送方收不到接收方的确认报文 TCP规定，在报文发送后的一个时间间隔后，如果还没收到确认报文，发送方一律认为报文丢失，要重发报文\n超时时间的考虑\n最理想状态，保证确认应答一定能在这个时间内返回 设置太长影响重传效率，设置太短会频繁发送重复报文 不同网络环境要设置不同的超时时间 TCP动态计算超时时间\n各种操作系统中，超时以500ms为一个单位控制，每次设置超时时间都是500ms的整数倍 重发一次后仍得不到应答，等待2*500ms再重传 仍得不到应答，等待4*500ms再重传，指数递增 累积到一定重传次数，TCP认定对方主机异常，强制关闭连接 连接管理（通信能力检测）\r#\r就是三次握手四次挥手 数据传输前，验证双方的发送和接收能力，以及通信环境的正常\n流量控制（滑动窗口）\r#\r接收端处理数据速度有限，发送端发送太快打满接收缓冲区，会导致丢包，引起丢包重传等一系列反应 TCP根据接收端接受能力决定发送端发送速度（滑动窗口机制）\n拥塞控制\r#\r如果网络状态比较拥堵，不清楚网络状态，盲目根据接收方窗口大小发送数据，将导致网络更加拥堵，数据发送不出去 TCP引入慢启动机制，先发送少量数据，探测信道状态，了解拥堵情况，再决定按照多大的速度传输数据 设置拥塞窗口cwnd，大小为swnd 慢启动：\n一开始将cwnd设置为一个较小的值，通常是一个MSS 每经过一个传输轮次（即cwnd所允许发送的报文都连续发出去，且收到了对已发送的最后一个字节的确认），cwnd的大小就会加倍 通过指数级增长的方式，快速探测网络的可用带宽，但为了防止增长过快导致网络拥塞，还要引入慢开始门限ssthresh\n拥塞避免：\n当swnd超过ssthresh时，就会从慢开始算法切换到拥塞避免算法 在拥塞避免阶段，拥塞窗口不再加倍增长，而是每次收到一个确认报文，拥塞窗口就增加 1 个 MSS。也就是说，拥塞窗口以线性的方式缓慢增长 避免拥塞窗口增长过快，导致网络拥塞，让网络能够在一个相对稳定的状态下运行\n快恢复： 在每次超时重传(快重传)后，慢启动阈值会变成检测到网络拥塞时的窗口大小的一半，同时将拥塞窗口cwnd设置为1\nMSS：TCP协议报文能传输的最大数据段长度\n理论值：TCP报文最长65535字节，去掉20字节IP首部，最小20字节TCP首部，理论MSS=65495 字节\n实际值：主要由链路层的最大传输单元（MTU）决定。MTU 是指数据链路层能够承载的最大数据长度。例如，以太网的 MTU 通常是 1500 字节，在这种情况下，减去 20 字节的 IP 首部和 20 字节的 TCP 首部，MSS 的值为 1500 - 20 - 20 = 1460 字节\n协商机制：MSS 的值是在 TCP 连接建立时通过三次握手进行协商确定的。在客户端和服务器进行 TCP 连接建立的过程中，双方会在 SYN 报文中交换各自能够支持的 MSS 值，最终会选择一个双方都能接受的最小值作为本次连接的 MSS\n性能提升策略\r#\r滑动窗口\r#\r发送方一次发送多个报文，报文的数量由滑动窗口大小确定 TCP报文首部中，有一个16位大小的窗口值，该字段反映的是发送该报文的主机的接收缓冲区的剩余大小，也就是发送方反应自己的接受能力 三次握手时，就会通报对方自己的窗口大小，双方基于每次通信的报文中的窗口大小，来动态调整自己要发送给对方的报文数量，就是滑动窗口\n发送方根据对端发送的窗口大小，将自己的发送缓冲区分成三个部分 滑动窗口是可以发送未收到应答的部分\n窗口大小是指无需等待确认应答而可以继续发送数据的最大值 发送滑动窗口内的数据，不需要等待任何ACK，直接发送 收到一个ACK后，滑动窗口向后移动，继续发送后续的数据 操作系统内核维护滑动窗口，开辟发送缓冲区记录哪些数据没有应答，确认应答的数据从缓冲区删除（被后续数据覆盖） 窗口越大，网络吞吐率越高 相关问题\n滑动窗口只能向右，不能向左 因为左边数据已经发送且收到接收应答，不应该再发送 滑动窗口大小可以变化，可以为0 滑动窗口大小取决于对方的通告，可以辩变化。0表示对方暂时不能接收数据，可能是接收缓冲区满，于是发送方不再发送数据，但是会定期发送窗口探测报文，知晓接收方的窗口大小 滑动窗口能一直向右滑动不越界 因为发送缓冲区是环形队列，左边的部分会被新的数据覆盖 丢包如何重传 如果数据送到，ACK丢失，可以用后续的ACK进行确认 如果是数据没送到，则有快重传机制 快重传\r#\r数据包丢失情况下，发送方会一直收到前序报文序号+1的应答 如果连续三次收到前序报文序号+1的应答，发送端会立即重发丢失的数据包 即快重传机制\n延迟应答\r#\r接收方收到数据放入接收缓冲区，应用层会将缓冲区数据取走处理，释放接收缓冲区 如果接收方收到数据就立即返回ACK，返回的窗口会比较小，但是实际上一会会空出更大的窗口，接收方实际可以在一会后处理更多的数据 所以如果接收端等一会再应答，通报的窗口可以更大 窗口越大，网络吞吐量越大，传输效率越高 延迟应答：\n每隔N个包就应答一次 超过最大延迟时间就应答一次 不同操作系统不同，一半N=2，延迟时间取200ms 捎带应答\r#\r和确认应答搭配使用，在一方返回确认应答ACK报文时，可以在报文中携带数据，携带数据的确认应答就是捎带应答，提升数据传输效率\n拆包和粘包问题\r#\r包指的是应用层的数据包 拆包，即应用层的数据在TCP被拆成多个数据包分别传输和被接收 拆包传输，需要保证接收方能够根据拆包还原原本数据包 由TCP数据包的序列号连接和可靠性传输不丢包来保证\n粘包，两个应用层包的结尾和开头在一个TCP包内，即前后的多个应用层数据包粘连 粘包传输，需要接收方能够分离应用层的数据包，即明确边界 TCP的协议头没有数据长度字段，只有序列号便于分解TCP首部和载荷\n在传输层角度，TCP接收TCP报文，按序号将报文按顺序放在接收缓冲区，等待上层应用读取时，将载荷分离向上交付 在应用层角度，接收到TCP传输的载荷，载荷时一串连续字节数据。应用程序无法得知完整数据包的边界，多个包混杂粘连在一起，无法合理解析 所以应用层协议应该明确数据包的边界。比如HTTP header中有length，明确一个HTTP body部分的长度，取这个长度的数据作为一个response进行解析 明确包的边界是避免粘包问题的根本\n对于定长的包，每次按固定大小读取 对于变长的包，约定包总长度的字段，从而知道包的结束位置 对于变长的包，也可以约定包之间的分隔符 总览\r#\rTCP是字节流的传输层协议\nTCP的任务是保证数据的完整传输\nTCP通过三次握手检测双方发送和接收能力，以及信道传输能力\n通过校验和保证数据传输的无损\n通过序列号来保证数据包的顺序，让接收方能还原数据包\n通过确认应答、超时重传机制来保证不丢包\n通过滑动窗口机制(流量控制)来根据对方的接受能力调整发送速度\n通过拥塞控制来探测网络情况调整发送速度\n在确认应答机制中通过延迟应答，增大滑动窗口大小，提升数据吞吐\n在超时重传机制中通过快重传提升丢包重传速度\n在确认应答机制中通过捎带应答，多传输一些数据\n"},{"id":13,"href":"/codestack/docs/basic/net/transport/","title":"传输层","section":"计算机网络","content":"\r传输层 Transport Layer\r#\r"},{"id":14,"href":"/codestack/docs/javaee/spring/ioc/","title":"依赖注入（DI）、控制反转（IOC）和自动装配","section":"Spring","content":"\r依赖注入（DI）、控制反转（IOC）和自动装配\r#\r控制反转基本概念： 将对象的创建和管理的控制权，从某个实体类，转交给Spring。\n依赖注入基本概念： 对象间的依赖关系将被自动注入到需要他们的对象中去。\n在传统模式中，类需要哪些资源就要自己去new出来， 现在则统一由Spring提供，从主动变成了被动。称为控制反转。\nSpring框架控制的资源全部放置在Spring底层的IOC容器中。\n控制反转可以理解为一种交给外部管理类依赖资源的设计模式 依赖注入是控制反转的一种实现形式 指的是组件自身提供普通的Java方法声明依赖关系。容器全权负责组件依赖关系的装配，将根据这些声明主动将符合依赖关系的对象传递给需要的对象。 为了实现控制反转的概念，Spring实现了依赖注入的机制 依赖注入机制的使用方式：\n属性注入形式 xml方式：使类有Set方法，并设置bean和property。Spring读取xml文件时，认为需要向bean a注入bean b。这实质上是通过，使类有set方法，从而可实现用xml文件声明属性依赖关系，从而声明依赖关系，寻求注入的方式。 构造器注入形式 xml方式：使类具备有参构造函数，并设置bean和property。实质上与上述是相似的，只是多支持了一种声明的方式。 Java显式配置\n通过注解，描述某个类应该作为Bean被容器管理，且内部包含一些如何在上下文中创建Bean的细节。如@Configuration。 通过注解，描述某个方法的返回结果应该作为Bean被容器管理，如@Bean。 上述的依赖注入的使用方式，实际上都是在告诉Spring如何装配对象间的依赖关系。 Spring对于描述Bean如何进行装配时，提供了三种主要的装配机制：\nXML中显式配置描述 Java中显式配置描述（就是通过@Configuration+@Bean描述Bean的创建） 隐式的Bean发现机制和自动装配（就是通过@Component+@Autowired等描述自动扫描和注入） 自动装配的Spring实现：\n组件扫描：通过注解配置，Spring会自动发现应用上下文中创建的Bean\n通过@ComponentScan配置组件扫描的包 通过@Component声明一个类为组件 Spring将扫描包并找到组件，为这些组件创建Bean并放入容器中 自动装配：Spring自动满足Bean之间的依赖关系\n在构造器上加上@Autowired，则Spring构造对象时，将传入对应的Bean。（注解式的构造器注入） 在Setter或其他方法上加上@Autowired，则Spring初始化Bean后，会尽量满足Bean的依赖，就会注入指定的Bean。（注解式的属性注入） 将@Autowired直接加在属性上 控制反转的优点： （理解中，依赖注入和自动装配机制，都是为了让控制反转模式能够合理运行的实现） 如A需要B实现功能 按传统模式，则需要在A中new B()，这时当B需要改动时，则A与B有关的功能代码可能都需要改动。 有了控制反转，将依赖关系交给容器装配，则我们只需改动B，就可以让容器初始化一个不同的B注入到A中，尽量少地避免了上层的改动。 这其实是依赖倒置原则的实现。实现依赖倒置原则，使得高层建筑可以不关心底层建筑的实现，避免牵一发动全身。 为了实现依赖倒置原则，思路是做控制反转，方法是实现依赖注入，为了实现依赖注入，做了个IOC容器去管理Bean的生成和装配等。 降低了组件间的耦合度。\n在Spring项目中的影响逻辑： 由于依赖倒置原则具有修改底层建筑，尽量少地影响上层建筑地好处。 Spring为了实现依赖倒置原则，构想了控制反转的模式，即将对象的创建、装配、生命周期管理等，交给IOC容器来进行，相比让对象自己去new，使得组件间耦合度降低 IOC容器管理Bean，首先是在启动时，通过读取XML、Java注解等方式，理解声明的Bean和装配方式，生成Bean并注册到容器中。进行后续管理。 组件的耦合度降低页实现了Controller、Service、DAO软件各层之间的解耦 IOC容器创建Bean提供了单例模式的支持，使得开发人员不需要自己实现 切面机制受IOC的影响暂定 组件间的解耦使得Spring使用第三方组件时可以实现无痛的切换底层实现，优势仅需修改一些配置，即可使得实例化地Bean是另一套实现，则被注入地是另一套实现，只需做好底层接口即可。\n"},{"id":15,"href":"/codestack/docs/basic/net/application/","title":"应用层","section":"计算机网络","content":"\r应用层 Application Layer\r#\r"},{"id":16,"href":"/codestack/docs/basic/net/","title":"计算机网络","section":"计算机基础","content":"\r计算机网络\r#\r"}]