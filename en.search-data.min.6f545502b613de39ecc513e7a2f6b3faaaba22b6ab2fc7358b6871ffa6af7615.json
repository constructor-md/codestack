[{"id":0,"href":"/codestack/docs/basic/net/application/http/","title":"HTTP","section":"应用层","content":"\rHTTP\r#\rHTTP是应用层的，基于TCP的超文本传输协议\n无状态：协议自身不对请求和响应之间的通信状态进行保存，任何两次请求之间没有依赖关系 无连接：每次连接只处理一个请求 使用80作为默认端口 报文结构\r#\r请求报文\r#\r请求报文总体四个部分\n请求行 包括请求方法、URL、协议版本，彼此使用空格分隔 请求头 KV形式的辅助信息 空行 分隔报头(请求行+请求头)和请求体，由回车符和换行符组成 请求体 请求发送时携带的数据 请求行\n方法 说明 支持的HTTP协议版本 GET 获取资源 1.0，1.1 POST 传输实体主体(提交信息) 1.0，1.1 PUT 传输文件 1.0，1.1 HEAD 获得报文首部 1.0，1.1 DELETE 删除文件 1.0，1.1 OPTIONS 询问支持的方法 1.1 TRACE 追踪路径 1.1 CONNECT 要求用隧道协议连接代理 1.1 LINK 建立和资源之间的联系 1.0 UNLINE 断开连接关系 1.0 请求头\n请求头 含义 示例 Cache-Control 用于控制缓存策略，设置缓存的行为，如是否允许缓存、缓存时间、缓存验证方式等 Cache-Control: max-age=3600 Connection 指示客户端和服务器之间的连接选项，常见值有 keep-alive 和 close，分别表示保持连接和关闭连接 Connection: keep-alive Date 表示请求发送的日期和时间，采用 HTTP 日期格式，服务器可据此进行时间相关处理 Date: Wed, 18 Apr 2025 12:00:00 GMT Accept 告知服务器客户端能够接受的响应内容类型，服务器会根据此选择合适的内容格式返回 Accept: text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8 Accept-Encoding 指定客户端能够接受的编码方式，如 gzip、deflate 等，服务器会对响应数据进行相应的编码压缩 Accept-Encoding: gzip, deflate Accept-Language 表示客户端偏好的语言，服务器可根据此返回对应语言的内容 Accept-Language: en-US,en;q=0.9,zh-CN;q=0.8,zh;q=0.7 Host 指定请求的目标主机和端口号，用于区分同一服务器上的不同虚拟主机或服务 Host: www.example.com:8080 Referer 标识请求发起的来源页面的 URL，服务器可以借此了解请求的上下文和来源路径 Referer: https://www.example.com/page1.html User-Agent 包含客户端的相关信息，如浏览器类型、版本、操作系统等，服务器可根据此进行不同的适配和处理 User-Agent: Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/112.0.5615.137 Safari/537.36 Content-Type 用于 POST、PUT 等请求，指示请求体中数据的类型，如 application/json、application/x-www-form-urlencoded、multipart/form-data 等 Content-Type: application/json Content-Length 表示请求体的长度，以字节为单位，服务器可据此判断是否完整接收了请求数据 Content-Length: 1024 响应报文\r#\r响应报文总体四个部分：\n状态行：包含协议版本、状态码，状态码描述 响应头：响应体的KV形式附属信息 空行：回车符和换行符组成，分隔报头和响应体 响应体：响应的数据 常用状态码含义 1xx多用于实验场景\n状态码 含义 200 OK 请求成功，服务器已成功处理请求并返回了请求的资源。 201 Created 请求成功，并且服务器创建了一个新的资源。通常在使用 POST 方法创建新资源时返回。 204 No Content 请求成功，但服务器没有返回任何内容。常用于只需要执行某个操作而不需要返回数据的情况。 301 Moved Permanently 请求的资源已被永久移动到新的 URL。客户端应使用新的 URL 进行后续请求。 302 Found 请求的资源临时移动到了新的 URL。客户端应使用新的 URL 进行本次请求，但后续请求仍可使用原 URL。 304 Not Modified 客户端发送了附带条件的请求（如 If - Modified - Since 等头信息），服务器认为资源未被修改，客户端可以使用缓存的资源。 400 Bad Request 客户端发送的请求有语法错误或不符合请求规范，服务器无法理解请求。 401 Unauthorized 客户端请求需要身份验证，但客户端未提供有效的身份凭证或凭证无效。 403 Forbidden 服务器理解请求，但拒绝执行该请求，通常是因为客户端没有足够的权限访问资源。 404 Not Found 服务器无法找到请求的资源。可能是 URL 输入错误或资源已被删除。 405 Method Not Allowed 客户端请求使用的方法（如 GET、POST 等）不被服务器允许用于请求的资源。 415 Unsupported Media Type 客户端发送的请求体中的数据格式不被服务器支持，如服务器不支持请求的 Content - Type。 500 Internal Server Error 服务器内部发生错误，无法完成请求。通常是服务器端的代码出现异常或配置问题。 502 Bad Gateway 服务器作为网关或代理，从上游服务器收到了无效的响应。 503 Service Unavailable 服务器暂时无法处理请求，通常是因为服务器过载或正在进行维护。 504 Gateway Time - out 服务器作为网关或代理，在等待上游服务器响应时超时。 多版本差异\r#\rHTTP/0.9 1991年发布。极其简单，只能传输纯文本，仅支持GET请求，没有HTTP头信息和状态码.服务器只能回复HTML格式字符串，不能回应别的格式\n已被弃用\nHTTP/1.0 1996年发布。\n在0.9基础上扩展了请求方法，包括GET，POST，HEAD 新增了1xx-5xx五类状态码 定义了消息头部 可以支持长连接keep-alive，但需要显式设置 不支持连接复用，每次请求都要建立TCP连接 请求为blocking，下一个请求发送必须在收到前一个请求包的响应包后 导致：请求延迟大，网络带宽不能充分利用 队头阻塞：在计算机网络范畴中是性能首先的现象\n是一列数据的第一个数据包(队头)被阻塞，导致整列数据包受阻的现象\nTCP会引起队头阻塞，HTTP/1.0也会引起队头阻塞\nHTTP/1.1（目前使用最广泛的版本） 1997年发布\n引入缓存机制 扩展错误状态码 新增Host字段 可以将请求发往一台服务器的不同网站\n在一台WEB服务器上同一个IP地址和端口号上使用不同的主机名的虚拟WEB站点\n也就是使用nginx在收到相同的ip和端口号后针对用户请求的Host再次进行转发\n默认开启keepalive 一个连接被多个请求复用，减少连接建立和断开的开销 请求范围引入range域 引入管道机制 管道机制允许客户端同时发起多个请求，无需等待响应到来 一定程度上缓解了队头阻塞问题，但没有完全解决\n因为服务端是按照接收到请求包的顺序响应的，也就是说如果先后收到请求AB，服务端必须先响应A再响应B\nHTTP/2 必须搭配TLS1.2一起使用，即必须HTTPS 头部和数据用二进制表示，而不再是ASCII的文本 一条连接内支持多条流并行，即多路复用 一条流阻塞不会阻塞其他流，解决了HTTP协议中的队头阻塞问题，但传输层TCP的队头阻塞仍然存在 首部压缩 允许服务器未经请求，主动向客户端发送资源 除了TLS强制使用之外，各个改动极大降低了网络延迟，提升网页加载速度\nHTTP/3 不再采用TCP作为传输层协议，而是使用UDP。UDP不提供可靠保证和流控服务，引入了应用层的QUIC，工作在UDP和HTTP之间。QUIC保证数据有序，拥塞控制等，而且继承了TLS\n在HTTP/2的多路复用解决HTTP队头阻塞基础上，绕开TCP后，完整解决队头阻塞问题；不再需要TCP三次握手，进一步降低请求延迟\n解决连接迁移问题：TCP协议在移动切换到wifi时因为IP改变，需要重建连接。HTTP3采用CID标识一条流，改变IP不会造成影响\n常用机制\r#\r跨域(CORS)处理\r#\r跨域问题源于浏览器的同源策略\n同源策略规定，只有当两个URL的协议、域名和端口都相同时，浏览器才允许他们之间进行资源共享\n当前端服务器所在的域和后端服务器所在的域不相同时，即请求前端用A域名端口，请求后端用B域名端口，则产生跨域问题\n浏览器将在收到服务器响应时阻止跨域\n浏览器接收跨域响应，检查响应头信息，如果相关字段表明当前请求不允许被跨域访问，浏览器将阻止该请求的响应被前端页面获取和处理 所以想要避免跨域问题，可以在后端服务器响应报文中添加相应的字段信息，以避免浏览器阻止跨域 关键字段和含义:\nAccess-Control-Allow-Origin: 指定允许访问该资源的外域URI，可以是具体的域名，也可以用*标识允许所有域名访问（携带凭证如Cookie的请求不能用通配符） Access-Control-Allow-Method：指定服务器允许的跨域请求方法，如GET,POST,PUT,DELETE等 Access-Control-Allow-Credentials：指定是否允许客户端在跨域请求中携带凭证，值为true或false Access-Control-Allow-Headers：列出服务器允许的请求头字段 Access-Control-Expose-Headers：允许客户端访问的响应头。 Access-Control-Max-Age：预检请求的缓存时间（单位：秒） 身份认证与授权\r#\rCookie\r#\rCookie由服务器端生成\n在浏览器请求服务器时，服务端在HTTP响应中携带Set-Cookie: xxx=yyy，以键值对形式表示，如果有多个Cookie键值对，就有多个Set-Cookie\n再次发起请求时，浏览器会自动在Request Header中增加Cookie字段，以Cookie: xxx=yyy; aaa=bbb形式，携带Cookie信息\n通过Cookie，服务器可以为请求设置一些标识，比如通过Cookie知道某些请求来自某些用户等\n浏览器会将Cookie键值对信息缓存在本地，这些键值对信息会以域名为界存储，Cookie也只会被设置到相同域名的请求中，防止不同域名之间的 Cookie 相互干扰和泄露用户信息\n浏览器会根据 Cookie 的过期时间来管理 Cookie。当 Cookie 过期后，浏览器会自动删除该 Cookie\nCookie 还可以设置路径属性，只有当请求的路径与 Cookie 的路径匹配或为其子路径时，浏览器才会发送该 Cookie\n由于 Cookie 存储在用户本地，并且可能包含敏感信息，如用户登录凭证等，因此在使用 Cookie 时需要注意安全性，防止 Cookie 被窃取或篡改\n可以设置Set-Cookie: key=value; HttpOnly 或Set-Cookie: key=value; Secure来增强安全性\nHttpOnly使得该Cookie键值对只能被Http协议(包含Https)访问，不能被Js脚本访问，主要用于防止跨站脚本攻击(XSS)\nSecure使得浏览器仅在HTTPS请求下才发送该Cookie，主要用于防止中间人攻击\nXSS跨站脚本攻击：攻击者通过注入恶意脚本到他的网页中，当用户访问该网页时，恶意脚本会在用户的浏览器中执行。如果网页中的某些敏感信息（如用户的会话 ID、身份验证 Token 等）存储在 Cookie 中，且这些 Cookie 没有设置HttpOnly属性，那么恶意脚本就可以通过 JavaScript 代码（如document.cookie）获取这些 Cookie 信息，进而利用这些信息来模拟用户身份进行恶意操作。而设置了HttpOnly属性后，恶意脚本无法访问这些 Cookie\n中间人攻击：HTTP 协议中，数据是以明文形式传输的，这意味着在数据传输过程中，攻击者可以截获和篡改数据。如果用户的敏感信息存储在 Cookie 中，且这些 Cookie 没有设置Secure属性，那么中间人就有可能截获这些 Cookie 信息，进而利用这些信息来模拟用户身份进行恶意操作。而设置了Secure属性后，只有在使用 HTTPS 协议进行通信时，浏览器才会发送这些 Cookie，而HTTPS数据在传输过程中是加密的，中间人无法截获和篡改数据\nToken\r#\rtoken指令牌或凭证，在Web开发中一般指用户登录凭证\n前端指引用户表单输入信息进行登陆后，登录接口返回token，前端可以将token缓存在本地，每次将token设置在请求中约定的header处便于后端识别请求的用户和用户的登陆状态\n后端产生token，一般是随机字符串，并在后端数据库中与用户信息进行绑定，在请求到来时从约定header中取出token，并用token寻找用户信息，从而知道用户是否登录、接口权限、数据归属等信息\n重定向\r#\r重定向机制主要指服务器返回给客户端的响应中，状态码为302，且Header中由Location字段指定需要客户端重定向到的网址，主要用于服务器在客户端提交表单后并处理成功后，指引客户端跳转到下一个页面，比如登陆后跳转到主页等\n如下代码以SpringMVC为基础开发指引客户端重定向 流式传输\r#\rSSE\r#\rSSE(Server-Sent Events) 服务器发送事件\n客户端发起一个请求，服务器保持连接打开，并不断向客户端发送事件流 后端服务器需要设置响应头Content-Type为text/event-stream，并保持连接打开，不断向客户端发送事件数据\nSSE 的数据格式是简单的文本，每行以特定的字段开头，如data:表示事件数据，event:表示事件类型等。每个事件以两个换行符\\n\\n结尾\n分块传输编码（Chunked Transfer Encoding）\r#\r分块传输编码允许服务器在发送响应时，将数据分成多个块进行传输，而不必事先知道响应的总长度\n前端通常不需要特殊处理，浏览器会自动处理分块传输编码的响应，将接收到的块组合成完整的数据\n后端服务器需要设置响应头Transfer - Encoding为chunked，并按块发送数据。每个块由块的长度（以十六进制表示）和换行符开头，接着是块的数据，最后以换行符结尾\n每个块由块的长度（十六进制表示）、换行符、块数据、换行符组成，最后以长度为 0 的块（0\\r\\n\\r\\n）结束\n缓存\r#\r强缓存\r#\r只要本地的资源在缓存有效期内，直接取本地缓存，避免与服务器交互\nCache-Control: HTTP/1.1用于控制缓存的通用首部字段，有多种指令\nmax-age: 指定资源缓存时间，单位为秒 no-cahce: 需要先与服务器验证资源的有效性，再决定是否使用缓存 no-store: 禁止使用任何缓存\nExpires：是 HTTP/1.0 中用于控制缓存的首部字段\n它指定了一个具体的日期和时间，在这个时间之前，浏览器可以使用本地缓存的资源。不过，由于Expires使用的是服务器的时间，可能会因为客户端和服务器时间不一致而导致缓存失效，因此在 HTTP/1.1 中推荐使用Cache-Control\n协商缓存\r#\r当强缓存失效时，浏览器会向服务器发送一个请求，询问服务器该资源是否有更新\n服务器根据请求中的信息进行判断，如果资源没有更新，则返回 304 状态码，告诉浏览器可以使用本地缓存；如果资源有更新，则返回新的资源和 200 状态码\nETag：是服务器为资源生成的一个唯一标识符\n当资源发生变化时，ETag的值也会相应改变。浏览器在后续请求时，会通过If-None-Match首部字段将之前缓存的ETag值发送给服务器，服务器将其与当前资源的ETag进行比较，如果相同则表示资源未更新。\nLast - Modified：表示资源的最后修改时间\n浏览器在后续请求时，会通过If-Modified-Since首部字段将之前缓存的最后修改时间发送给服务器，服务器将其与当前资源的最后修改时间进行比较，如果相同则表示资源未更新\n缓存策略的应用场景\r#\r频繁更新的资源：对于经常更新的资源，如新闻资讯、实时数据等，建议设置较短的缓存时间或使用no-cache指令，以确保用户能够及时获取到最新的内容。 不经常更新的资源：对于不经常更新的资源，如图片、CSS、JavaScript 文件等，可以设置较长的缓存时间，以减少对服务器的请求，提高网站的性能。 敏感信息资源：对于包含敏感信息的资源，如用户的个人信息、订单信息等，应使用no-store指令，禁止浏览器进行缓存，以确保信息的安全性 一次请求来说明缓存流程\r#\r客户端发起请求，可能是请求网页、图片、服务器数据等 检查强缓存 缓存key内容可能包含请求方法、URL、请求头等\n浏览器查看本地是否有本次请求的缓存资源，同时根据缓存中保存的Cache-Control首部字段的max-age指令或Expires首部字段指定的时间来判断缓存是否过期\n如果缓存资源未过期，直接使用缓存资源，不向服务器请求，即命中强缓存\n如果缓存资源不存在或者已经过期，则检查协商缓存\n检查协商缓存 强缓存未命中，客户端会在请求中携带If-None-Match(对应ETag)和If-Modified-Since(对应Last-Modified)首部字段发送请求给服务器。服务器接收到请求后根据这两个字段来判断资源是否有更新\n如果资源未更新，即ETag和Last-Modified值与客户端发送的一致，服务器返回304 Not Modified状态码。客户端收到后直接使用本地缓存的资源\n资源已更新，服务器返回200 OK状态码和新的资源内容\n客户端更新缓存 客户端收到服务器返回的新资源(状态码200 OK),或者收到304NotFound但缓存已经过期需要更新有效期，会对本地缓存进行替换或者根据服务器的缓存控制信息更新缓存属性\n如果服务器返回Cache-Control首部包含no-cache或no-store，客户端则不使用缓存或删除缓存\n内容协商\r#\r请求方发送头\nAccept 用于告知服务器客户端能够接受的响应内容类型，即媒体类型（MIME 类型）。如Accept: text/html Accept-Encoding 作用：指定客户端能够接受的内容编码方式，服务器可以根据这个字段对响应数据进行相应的编码压缩，以减少数据传输量。 示例：Accept-Encoding: gzip, deflate 表示客户端支持 gzip 和 deflate 两种编码方式 Accept-Language 作用：表示客户端偏好的语言，服务器可以根据这个字段返回对应语言的内容。 示例：Accept - Language: en-US;zh-CN; 表示客户端优先接受中文（中国大陆），其次是美式英语 Accept-Charset 作用：指定客户端能够接受的字符编码，服务器会根据这个字段选择合适的字符编码来发送响应数据。 示例：Accept-Charset: UTF-8 表示客户端优先接受 UTF-8 编码 响应方返回头\nContent-Type 作用：指示响应内容的媒体类型和字符编码。服务器通过这个字段告知客户端响应数据的格式和编码方式。 示例：Content-Type: text/html; charset=UTF-8 表示响应内容是 HTML 格式，使用 UTF-8 字符编码 Content-Encoding 作用：说明响应内容所使用的编码方式，与客户端的 Accept-Encoding 字段相对应。客户端需要根据这个字段对响应数据进行解码。 示例：Content-Encoding: gzip 表示响应数据使用了 gzip 编码。 Content-Language 作用：指定响应内容所使用的语言，与客户端的 Accept-Language 字段相对应。 示例：Content-Language: en - US 表示响应内容使用的是美式英语 常见的数据类型（媒体类型）\n文本类型 text/html：超文本标记语言，用于创建网页。 text/plain：纯文本，没有任何格式。 text/css：层叠样式表，用于定义网页的样式。 text/javascript：JavaScript 代码，用于实现网页的交互效果。 图像类型 image/jpeg：JPEG 图像格式，常用于照片等。 image/png：PNG 图像格式，支持透明通道，常用于图标、图形等。 image/gif：GIF 图像格式，支持动画效果。 应用类型 application/json：JSON（JavaScript Object Notation）数据格式，常用于前后端数据交互。 application/xml：XML（eXtensible Markup Language）数据格式，用于数据的存储和传输。 application/pdf：PDF（Portable Document Format）文档格式，用于跨平台的文档展示。 application/octet - stream：二进制流，通常用于下载文件，服务器不指定具体的文件类型，由客户端自行判断。 "},{"id":1,"href":"/codestack/docs/javaee/mysql/innodb_index/","title":"InnoDB 索引","section":"MySQL","content":"\rInnoDB 索引\r#\r表数据结构\r#\r索引组织表\r#\r每张表必然有主键 没有显示建立主键，使用第一个非空唯一索引作为主键 没有非空唯一索引，存储引擎自动创建一个6字节大小的指针row_id作为主键 逻辑存储架构\r#\r所有数据存放在表空间中，表空间由段、区、页组成 段有数据段、索引段、回滚段等。概念上数据就是索引，数据段就是B+树的叶子节点，索引段是B+树的非叶子节点 区是连续页组成的空间，每个区大小固定1MB。页大小16KB，每区固定64个连续页 页是存储引擎数据管理最小单位，每次读写磁盘最小一页，即16KB 行：Innodb是面向列的存储引擎，数据按行存放，每页最多存放7992行记录 B+树\r#\rB+树由二叉查找树和二叉平衡树发展而来，但B+树是多叉树，减小树高度 B+树的记录数据都在叶子节点上，非叶子节点存放的数据是索引值 叶子节点之间以指针双向连接，形成链表，方便范围查找 B+树索引分成聚簇索引和二级索引，区别在于叶子节点是否存放所有行信息 B+树是平衡树，所有叶子节点在同一层，查询稳定性高 优势\r#\r树高度低，减少磁盘IO 每个非叶子节点存放多个范围的下一级节点的指针，而不只是普通二叉查找树的两个，靠这一点减少树高度 在索引树上查找时，先从磁盘读取根节点，每找到下一级索引就要从磁盘读取索引页得到数据继续判断，索引树高度低，使得读取一次磁盘筛选数据效率高，大幅减少磁盘IO次数 叶子链表范围查询高效 叶子节点形成索引值的顺序链表，支持顺序遍历，便于范围查询 查询稳定性 B+树使用分裂+合并技术保持结构稳定性。因为插入数据导致一个节点达到容量上限，就会分裂成两个节点；因为删除数据导致两个节点太小，空间利用率低，就会合并成一个节点。这也是它的自平衡策略的一部分，同层横向扩展 B+树高度变化少，一般最高四层就能存储千万以上数据 只有叶子节点才有具体数据，插入和删除对树结构影响小 对比B树\r#\rB树非叶子节点存放数据，使得一次读取磁盘筛选数据效率低，且树高度变高，磁盘IO负担大\n聚簇索引/聚集索引/主键索引\r#\r按主键构造B+树 叶子节点存放的行记录信息包含所有列 通过聚集索引查找数据，可以直接在叶子节点得到全部数据 二级索引\r#\r根据索引列值构造B+树 叶子节点有索引值、该索引值对应的主键 通过二级索引查找数据时，会根据索引找到对应的叶子节点，再根据叶子节点上的主键值，回表到主键索引获取更多列数据 索引失效情况枚举\r#\r隐式类型转换导致索引失效\r#\r原因：查询条件和主键类型不一致，转换失败时无法使用索引，导致全表扫描\n-- 索引`id`为INT类型\rSELECT * FROM t WHERE id = \u0026#39;100\u0026#39;; -- 字符串转INT，索引有效（依赖优化器）\rSELECT * FROM t WHERE id = \u0026#39;100ABC\u0026#39;; -- 转换失败，全表扫描 使用函数或计算索引列\r#\r原因：索引树结构逻辑为大小排列，函数计算后无法找到对应的节点\n# 取绝对值\rSELECT * FROM t WHERE ABS(id) = 100; -- 失效 NOT IN 或 NOT EXISTS\r#\r原因：索引树结构逻辑为大小排列，not in 查询将遍历所有数据来判断是否not，无法通过比较确定位置。否定查询导致全表扫描\nSELECT * FROM t WHERE id NOT IN (1,2,3); -- 失效（全表扫描） 不等于操作符 !=, \u0026lt;\u0026gt;\r#\r原因：同上\nSELECT * FROM t WHERE a != 5; -- 全表扫描\rSELECT * FROM t WHERE a \u0026lt;\u0026gt; 5; -- 同上 查询条件包含IS NULL/IS NOT NULL(可能失效)\r#\r原因：查询成本导致索引失效，如果IS NULL/IS NOT NULL过滤得到大量的数据，将会导致大量的查询和结果。失效原因并不是Null，因为innodb规定null值是最小的，数据节点会在B+树的最左边\nSELECT * FROM t WHERE id NOT IN (1, 2, 3); -- 可能失效\rSELECT * FROM t WHERE NOT EXISTS (SELECT 1 FROM t2 WHERE t.id = t2.id); -- 同上 OR查询索引失效\r#\r原因：OR 条件对单一索引表示可取可不取，含义模糊导致索引失效，除非优化器选择Index merge\n应该考虑使用union all 替换 or 条件\n-- 索引列`a`和`b`各自有独立索引\rSELECT * FROM t WHERE a = 1 OR b = 2; -- 可能触发全表扫描（除非优化器选择Index Merge） 前导模糊查询 Like \u0026lsquo;%xxx\u0026rsquo;\r#\r原因：非末尾的模糊通配，都无法在索引树上判断接下来应该走左子叶还是右子叶\nSELECT * FROM t WHERE name LIKE \u0026#39;%John\u0026#39;; -- 失效\rSELECT * FROM t WHERE name LIKE \u0026#39;John%\u0026#39;; -- 有效 索引选择性过低\r#\r原因：索引条件筛选数据能力低下，同样会遍历到很多数据，优化器可能会放弃索引\n-- 索引列`gender`只有\u0026#39;M\u0026#39;/\u0026#39;F\u0026#39;两种值\rSELECT * FROM t WHERE gender = \u0026#39;M\u0026#39;; -- 可能全表扫描 联合索引未遵循特性导致失效\r#\r原因：联合索引树先按左边列值进行排列，左列值相同再按右列值排列，以此类推。如果不遵循最左前缀，即无法确定左边列的定值，就会遍历左边列值，找到每一个左边定值再找右边列值，导致右边索引列加速作用实质上无效\n-- 组合索引`(a, b, c)`\r# 没有遵循最左前缀匹配原则\rSELECT * FROM t WHERE b = 2 AND c = 3; -- 失效（缺少最左列`a`）\r# 左列范围查询导致右列索引失效\r# 联合索引要全部生效，范围查询就要放最右边\rSELECT * FROM t WHERE a \u0026gt; 1 AND b = 2; -- 仅`a`使用索引，`b`失效\rSELECT * FROM t WHERE a = 1 AND b \u0026gt; 2 AND c = 3; -- `a`和`b`有效，\r# 跳过中间列，同样是不遵循最左前缀，也相当于中间列全表范围查询\rSELECT * FROM t WHERE a = 1 AND c = 3; -- 仅`a`有效，`c`失效\r# 排序字段和索引顺序不一致\r-- 组合索引`(a, b)`\rSELECT * FROM t WHERE a = 1 ORDER BY b DESC; -- 有效（利用索引排序）\rSELECT * FROM t WHERE a = 1 ORDER BY b, c; -- 失效（`c`不在索引中）\r-- 组合索引`(a, b)`\rSELECT * FROM t ORDER BY b, a; -- 无法利用索引排序 字符集不同，联表Join时索引失效\r#\r原因：字符集不同无法在索引树上匹配\n-- 表A的`code`字段为utf8，表B的`code`为utf8mb4\rSELECT * FROM A JOIN B ON A.code = B.code; -- 索引失效 索引设计原则\r#\r查多写少列建立索引\r#\r经常作为查询条件、联表字段(也是一种查)、排序字段和分组字段的条件，需要建立索引以提升这些查询的性能\n数据量大的索引字段，增删改的性能确实会低一些，但是如果大批量的增删改不会经常发生，倒也不太有所谓\n索引列应具备高选择性\r#\r如果索引列基数，也就是索引列值的枚举少，那么使用该索引进行筛选时，筛选数据的效率低，甚至可能导致全表扫描\n组合索引优化\r#\r经常组合筛选和查询的列，可以考虑建立组合索引，以利用覆盖索引 索引列顺序应该根据查询的方式设计，避免索引失效。 经常等值查询的放在前面 经常模糊、范围、不确定查询的放在后面，留待索引下推处理 查询索引优化方法\r#\r首先尽量使用索引，以及避免索引失效的操作\n其次还需要一些索引使用的技巧\n利用覆盖索引\r#\r原理：直接从索引树取得查询所需数据，避免回表操作 主要用于联合索引\n-- 索引 (a, b)\rSELECT a, b FROM table WHERE a = 1; -- 有效（覆盖索引）\rSELECT a, b, c FROM table WHERE a = 1; -- 失效（需回表查询c） 开启和倾向索引下推\r#\r索引下推 （index condition pushdown ）简称ICP 原理：MySQL服务层判断where条件可以交给存储引擎层筛选，于是下推交给存储引擎层筛选，筛选结果变少，于是减少回表次数\n只用于联合索引，作用是优化一部分联合索引查询的性能\n# 如 联合索引 (a, b)\rselect * from table where a \u0026gt; 10 and b = 20\rexplain 显示 using index condition 表示使用了索引下推 联合索引左侧范围查询后，右侧索引效果应该失效 未开启索引下推时，确实如此。。存储引擎层只根据a \u0026gt; 10筛选索引树，回表出大量数据交给Server层，server层再筛选b = 20，显然回表次数很多 开启索引下推后，b = 20会被判断可以交给存储引擎层筛选，于是存储引擎层根据a \u0026gt; 10筛选，满足的进一步根据b = 20筛选，筛选效率高，回表次数减少，返回给Server层的数据也更准确 开启方法：\nMySQL5.6版本引入，且默认开启 命令开启：set optimizer_switch=\u0026lsquo;index_condition_pushdown=on\u0026rsquo;; 注意点：\n仅用于二级索引，主要是联合索引 查询优化方法\r#\r综合前面的知识，可以得出以下查询优化的注意点\n这些注意点不是必须遵守的，需要根据业务需求、数据量、数据分布来分析查询成本，综合系统的可接受度来选择\n查询具体列，而不是 *\r#\r查询时 select 列表仅包含所需数据，不需要的数据不要查，不要使用 * 查询\n好处\n减少查询结果数据量，传输快 无效数据查过来也是无效占用内存，增大垃圾回收负担 更有可能触发覆盖索引 利用索引，避免失效\r#\r筛选、排序、分组、联表等操作使用索引字段\n注意不要对索引字段进行函数计算 注意联表字段使用相同字符集 注意不要对索引使用隐式数据转换，传入数据应该是对应类型 注意操作符\r#\r对于需要 OR 条件的场景，使用Union查询替代 不要在索引上使用不等于!= \u0026lt;\u0026gt;查询，考虑在业务上避免 Like 模糊查询匹配应该放最后 关注查询成本、筛选效率\r#\r索引数据量太少，选择性低，每次查询筛选剩余行数太多，效率很低 IS NULL / IS NOT NULL，也有可能筛选效率低，最好同时匹配其他筛选条件 对于联合索引，利用其特性\r#\r索引左列范围、模糊、不指定条件等不精确查询，都可能导致右列索引能力失效\n即需要左侧指定，右侧才有效。（涵盖了所谓的最左前缀匹配原则） 排序字段顺序遵循索引顺序，否则无法利用索引排序 深分页优化\r#\r分页性能瓶颈\r#\rMySQL分页采用Limit和Offset进行分页查询，Limit限制本次返回记录数，Offset表示需要跳过的记录数\n当Offset很大，即深分页时，需要跳过大量的记录找到取数据的起始点，会导致性能瓶颈\n大量数据行扫描，时间成本高、磁盘IO压力大 扫描过的数据多，影响数据多，也会被很多数据的状态影响，更可能导致锁竞争问题 优化方法\r#\r深分页性能瓶颈根因是Offset扫描数据量大，优化思路也围绕Offset，要么不使用Offset，要么Offset扫描数据不能多\n业务上避免深分页\n不用深分页了，普通深度的分页Offset不大，扫描数据的性能可以接受，自然不会有问题。页面或者应用层限制分页数量最大值即可 游标分页\n游标是上一次分页的终点，代表了本次查询的数据起点，每次查询记录在客户端，翻页时自然不用扫描数据 # 传统分页\rSELECT * FROM users ORDER BY id LIMIT 10 OFFSET 1000;\r# 游标分页\rSELECT * FROM users WHERE id \u0026gt; ? ORDER BY id LIMIT 10; 缺陷\n无法跳页，但往往业务上就是需要跳页 实现复杂，客户端存储游标倒是小事。主要是多列排序时的分页游标怎么确定比较困难，业务往往需要支持多字段的正逆序组合方式 索引优化\n主要是对排序列使用索引，减少排序所需的时间\n使用分区表\n分区表存放在不同的物理存储区域，数据扫描时仅扫描相关的物理区域，天然筛掉一部分数据，减少扫描数据量\n但分区的设计是固定的，无法同时支持多种排序分页条件的性能提升 预分页与缓存\n采用缓存存储分页查询的结果，减少数据库负担，对于短时间频繁的反复分页查询有很好的提速效果 避免大表联小表和无意义联表\r#\r以 from 驱动表 join 被驱动表 on condition where xxx 为例\n联表过程是：\n驱动表逐行根据condition查询被驱动表，将对应数据行互相连接形成中间表\nwhere对中间表进行筛选\n所以如果使用大表联小表，联表过程就可能产生大量的查询过程，反之则不然\n另外在代码层如果存在联表查询多表字段的SQL，但每次一些字段不需要查出的，也没必要联相关表，减少联表消耗\n业务代码层优化\r#\r避免循环中查询数据库\n反复的创建数据库链接和会话也是不小的开销，如果非必要，就不要这样做。否则会导致整体查询时间的延长，以及数据库负担的不必要提高 对于数据量不大的查询，最好一次性查出相关列，而不是在循环中等值查询 对于每次查询都是相同条件的，更不要在循环中执行，循环开始前查出，在内存中备用即可 避免一次查询大量结果\n大量结果的返回会造成较大的网络负担，应该进行分页，或者条件分组的查询\n缓存查询结果 使用缓存，减少数据库压力\n优化的认知\r#\r从前面的一些方法可以看到，优化的操作往往不能达到尽善尽美，总是具有各种限制，来自业务场景，或者方法本身效果没那么好 可以看出，优化这件事，本质是综合考虑了业务需求、数据量、数据分布，继而分析查询成本，考量系统的可接受度的基础上进行优化的，而且往往不能优化到理论上尽善尽美，而是在实际场景上，能好一些是一些 特别是考量整体的优化幅度，对于权重更高的场景优化更多，对整个系统的性能提升，远远大于对有限低发生量的场景的优化 更不应该因为技术情节，优化低权重场景，降低高权重场景性能，本末倒置 "},{"id":2,"href":"/codestack/docs/javaee/spring/","title":"Spring","section":"JavaEE","content":"\rSpring\r#\r"},{"id":3,"href":"/codestack/docs/deploy/ubuntu/","title":"Ubuntu","section":"部署","content":"\rUbuntu\r#\r采用版本：24.01\n安装过程：全部 Done\n非Root用户上传文件\r#\r# 赋予指定用户组用户在某个文件夹及其子文件夹上传文件的权限\rsudo chown -R quanta:quanta /DATA 时区设置\r#\r# 查看当前时区\rtimedatectl\r# 查看东八区全称\rtimedatectl list-timezones | grep Shanghai\r# 设置时区\rsudo timedatectl set-timezone Asia/Shanghai host设置\r#\r便于多主机内网互相访问\nsudo vim /etc/hosts\r# 补充相关机器的ip 主机名\r192.168.1.11 dataserver1\r192.168.1.12 dataserver2\r192.168.1.13 dataserver3 OpenSSH安装\r#\rsudo apt update \u0026amp;\u0026amp; sudo apt upgrade\rsudo apt install openssh-server\rservice ssh status\r# 随后可以本机SSH使用安装过程设置的账户密码登录服务器 修改监听端口\r#\rsudo vi /etc/ssh/sshd_config\r# 内容\rPort 2222 修改后要重启\n重启\r#\r# Ubuntu22版本之前：\rsudo systemctl restart sshd\r# Ubuntu22版本之后：\rsudo systemctl daemon-reload\rsudo systemctl restart ssh.socket Docker安装(指定版本)\r#\rapt依赖安装\r#\rsudo apt-get install apt-transport-https ca-certificates curl gnupg-agent software-properties-common 添加阿里云docker GPG密钥\r#\rcurl -fsSL http://mirrors.aliyun.com/docker-ce/linux/ubuntu/gpg | sudo apt-key add - 添加阿里云镜像源\r#\rsudo add-apt-repository \u0026#34;deb [arch=amd64] http://mirrors.aliyun.com/docker-ce/linux/ubuntu $(lsb_release -cs) stable\u0026#34;\r#更新\rsudo apt-get update 查看有哪些可安装版本\r#\rsudo apt-cache madison docker-ce\r# 列出版本\rsudo apt-cache madison docker-ce | awk \u0026#39;{ print $3 }\u0026#39; 第二列是版本号，第三列是存储库的名称\n版本号提取： 第二列的第一行字符串为 5:19.03.93-0ubuntu-bionic ，那么版本号为 5:19.03.93-0ubuntu-bionic，版本号字符串必须写全第二列的整个字符串\n安装最新版\r#\rsudo apt-get install -y docker-ce 安装指定版本\r#\rsudo apt-get install -y docker-ce=5:27.3.1-1~ubuntu.24.04~noble 安装检查(版本查看)\r#\rsudo docker --version 修改镜像源\r#\rsudo vim /etc/docker/daemon.json\r{\r\u0026#34;registry-mirrors\u0026#34;: [\r\u0026#34;https://docker.m.daocloud.io\u0026#34;\r]\r} 修改后要重启docker\nsudo systemctl daemon-reload\t#重启daemon进程\rsudo systemctl restart docker\t#重启docker 检查修改成功\nsudo docker info 限制容器日志大小\r#\r不限制会直接打到磁盘爆满\nsudo vim /etc/docker/daemon.json\r{\r\u0026#34;registry-mirrors\u0026#34;: [\u0026#34;https://docker.m.daocloud.io\u0026#34;],\r\u0026#34;log-driver\u0026#34;:\u0026#34;json-file\u0026#34;,\r\u0026#34;log-opts\u0026#34;: {\u0026#34;max-size\u0026#34;:\u0026#34;10k\u0026#34;, \u0026#34;max-file\u0026#34;:\u0026#34;3\u0026#34;}\r}\r# 重启docker\rsudo systemctl daemon-reload\rsudo systemctl restart docker Hello World\r#\rsudo docker pull hello-world\rsudo docker run hello-world 命令启停\r#\rsudo systemctl start docker\rsudo systemctl stop docker 自动唤醒\r#\r默认会开启自动唤醒，stop docker进程时会显示：\nStopping \u0026#39;docker.service\u0026#39;, but its triggering units are still active:\rdocker.socket docker被访问时会被自动启动\n一般不会想关闭，如果要关闭：\nsudo systemctl stop docker.socket 开启自启\r#\rsudo systemctl enable docker Curl安装\r#\rsudo apt install curl DockerCompose安装（指定版本）\r#\r与Docker的版本适配关系 https://docs.docker.com/compose/releases/release-notes/\n指定版本安装\r#\rdocker装的是27.3.1 对应compose版本是2.30.x\n使用2.30.1\nsudo curl -L \u0026#34;https://github.com/docker/compose/releases/download/v2.30.1/docker-compose-linux-x86_64\u0026#34; -o /usr/local/bin/docker-compose 或者自行下载上传后执行：\n# 下载：到github docker compose上找所需版本包\rhttps://github.com/docker/compose/releases/download/v2.30.1/docker-compose-linux-x86_64\rhttps://github.com/docker/compose/releases\r# 上传后转移目录\rsudo cp docker-compose-linux-x86_64 /usr/local/bin/docker-compose 添加Docker Compose执行权限\r#\rsudo chmod +x /usr/local/bin/docker-compose 安装检查\r#\rdocker-compose --version Docker卸载\r#\r完全卸载Docker及安装时自动安装的所有包\r#\rsudo apt-get autoremove docker docker-ce docker-engine docker.io containerd runc 删除没有删除的相关插件\r#\rsudo apt-get autoremove docker-ce-* 删除docker的相关配置\u0026amp;目录\r#\rsudo rm -rf /etc/systemd/system/docker.service.d\rsudo rm -rf /var/lib/docker 确认docker卸载完毕（查看版本）\r#\rsudo docker --version 如果还有，可能存在snap版本的，删除\nsudo snap remove --purge docker 删除Docker相关文件\r#\rwhereis docker\rsudo rm -rf /usr/bin/docker 防火墙UFW控制\r#\r查看防火墙状态\r#\rsudo ufw status 查看防火墙状态 包括默认规则\r#\rsudo ufw status verbose 设置默认拒绝入站流量\r#\rsudo ufw default deny incoming 设置默认允许出站流量\r#\rsudo ufw default allow outgoing 防火墙启停\r#\rsudo ufw enable\rsudo ufw disable 允许/禁用端口\r#\rsudo ufw allow 2222/tcp\rsudo ufw deny 22/tcp 删除规则\r#\rsudo ufw delete allow 6379/tcp 防火墙开机自启\r#\rsudo systemctl status ufw ifconfig使用安装\r#\rsudo apt install net-tools 扩容磁盘（分区扩展+提升逻辑卷大小和根目录空间）\r#\r# 操作之前先停止各个docker容器等程序\rsudo docker-compose stop container_name\r# 持续重启的容器可能无法接收停止命令 使用down强制停止\rsudo docker-compose down container_name\r# 进入 fdisk 程序\rsudo fdisk /dev/sda\r# 输入 d 表示要删除分区\rCommand (m for help): d\r# 输入 3 表示要删除的是 /dev/sda3\rPartition number (1-3, default 3): 3\r# 显示已删除\rPartition 3 has been deleted.\r# 输入 n 表示创建新分区\rCommand (m for help): n\r# 直接回车表示选择分区号为默认3\rPartition number (3-128, default 3): # 直接回车默认起始扇区\rFirst sector (4198400-1430257630, default 4198400): # 直接回车默认结束扇区为使用所有剩余空间\rLast sector, +/-sectors or +/-size{K,M,G,T,P} (4198400-1430257630, default 1430255615): Created a new partition 3 of type \u0026#39;Linux filesystem\u0026#39; and of size 680 GiB.\rPartition #3 contains a LVM2_member signature.\r# yes 表示删除原本的GPT/MBR签名 会导致分区信息丢失\r# no 表示保留旧签名 只是对磁盘进行小调整 比如扩展\rDo you want to remove the signature? [Y]es/[N]o: n\r# w 保存修改\rCommand (m for help): w\rThe partition table has been altered.\rSyncing disks.\r# 重新加载分区表\rsudo partprobe\r# 扩展 LVM物理卷\rsudo pvresize /dev/sda3\r# 扩展逻辑卷\rsudo lvextend -l +100%FREE /dev/mapper/ubuntu--vg-ubuntu--lv\r# 调整文件系统大小\rsudo resize2fs /dev/mapper/ubuntu--vg-ubuntu--lv\r# 查看当前的文件占用情况\rsudo fdisk -l\rDisk /dev/sda: 682 GiB, 732291923968 bytes, 1430257664 sectors\rDisk model: Virtual disk Units: sectors of 1 * 512 = 512 bytes\rSector size (logical/physical): 512 bytes / 512 bytes\rI/O size (minimum/optimal): 512 bytes / 512 bytes\rDisklabel type: gpt\rDisk identifier: 0493D914-0713-4A60-93B8-B83236128F4C\rDevice Start End Sectors Size Type\r/dev/sda1 2048 4095 2048 1M BIOS boot\r/dev/sda2 4096 4198399 4194304 2G Linux filesystem\r/dev/sda3 4198400 1430255615 1426057216 680G Linux filesystem\rDisk /dev/mapper/ubuntu--vg-ubuntu--lv: 680 GiB, 730140246016 bytes, 1426055168 sectors\rUnits: sectors of 1 * 512 = 512 bytes\rSector size (logical/physical): 512 bytes / 512 bytes\rI/O size (minimum/optimal): 512 bytes / 512 bytes\r# 已经给/dev/sda3和/dev/mapper/ubuntu--vg-ubuntu--lv扩展到了680G\rdf -h\rFilesystem Size Used Avail Use% Mounted on\rtmpfs 1.2G 114M 1.1G 10% /run\r/dev/mapper/ubuntu--vg-ubuntu--lv 669G 11G 631G 2% /\rtmpfs 5.9G 0 5.9G 0% /dev/shm\rtmpfs 5.0M 0 5.0M 0% /run/lock\r/dev/sda2 2.0G 95M 1.7G 6% /boot\rtmpfs 1.2G 12K 1.2G 1% /run/user/1000\r# 根目录可用空间已经扩展到了669G 切换用户和修改密码\r#\r# 切换用户\rsu user\r# 修改密码\rpasswd user\r# 修改root用户密码\rsudo passwd root 固定本机内网IP 禁用DHCP\r#\r# 编辑netplan配置文件\rsudo vim /etc/netplan/50-cloud-init.yaml\r# 内容如下 注释了原本的配置\r# This file is generated from information provided by the datasource. Changes\r# to it will not persist across an instance reboot. To disable cloud-init\u0026#39;s\r# network configuration capabilities, write a file\r# /etc/cloud/cloud.cfg.d/99-disable-network-config.cfg with the following:\r# network: {config: disabled}\r#network:\r# ethernets:\r# ens192:\r# dhcp4: true\r# version: 2\rnetwork:\rethernets:\r# ens192名称和原始配置保持一致\rens192:\rdhcp4: false\raddresses: [192.168.1.11/24] # 需要的本机ip\rroutes:\r- to: default\rvia: 192.168.1.1 # 网关地址\rnameservers:\raddresses: [192.168.1.1] # DNS地址\rversion: 2\r# 使得配置生效\rsudo netplan apply "},{"id":4,"href":"/codestack/docs/javaee/spring/ioc/","title":"依赖注入|控制反转|自动装配","section":"Spring","content":"\r依赖注入|控制反转|自动装配\r#\r控制反转(IOC)与依赖注入(DI)\r#\r控制反转基本概念： 将对象的创建和管理的控制权，从某个实体类，转交给 Spring 容器\n在传统模式中，对象需要哪些资源就要在类代码中写明自己去 new 出来\n现在则统一由 Spring 提供，从主动变成了被动。称为控制反转\n依赖注入基本概念：\n对象间的依赖关系，被 Spring 容器自动注入到需要他们的对象中去\n也就是由 Spring 容器来管理对象间的依赖关系 依赖注入是控制反转的一种实现形式\n指的是组件自身提供普通的 Java 方法声明依赖关系。容器全权负责组件依赖关系的装配，将根据这些声明主动将符合依赖关系的对象设置给需要的对象，实现原理是反射 为了实现控制反转的概念，Spring 实现了依赖注入的机制 依赖注入机制的使用方式：\n属性注入形式 xml方式：使类有 Set 方法，并设置 bean 和 property 。Spring 读取 xml 文件时，认为需要向 bean a 注入 bean b。这实质上是通过，使类有 set 方法，从而可实现用xml文件声明属性依赖关系，从而声明依赖关系，寻求注入的方式。 构造器注入形式 xml方式：使类具备有参构造函数，并设置 bean 和 property。实质上与上述是相似的，只是多支持了一种声明的方式。 Java显式配置\n通过注解，描述某个类应该作为 Bean 被容器管理，且内部包含一些如何在上下文中创建 Bean 的细节。如 @Configuration。 通过注解，描述某个方法的返回结果应该作为 Bean 被容器管理，如 @Bean。 自动装配\r#\r上述的依赖注入的使用方式，实际上都是在告诉 Spring 容器如何装配对象间的依赖关系 Spring 对于描述 Bean 如何进行装配时，提供了三种主要的装配机制：\nXML中显式配置描述 Java中显式配置描述（就是通过 @Configuration + @Bean 描述 Bean 的创建） 隐式的 Bean 发现机制和自动装配（就是通过 @Component + @Autowired 等描述自动扫描和注入） 自动装配的 Spring 实现：\n组件扫描：通过注解配置，Spring 会自动发现应用上下文中创建的Bean\n通过 @ComponentScan 配置组件扫描的包 通过 @Component 声明一个类为组件 Spring 将扫描包并找到组件，为这些组件创建 Bean 并放入容器中 自动装配：Spring自 动满足 Bean 之间的依赖关系\n在构造器上加上 @Autowired，则 Spring 构造对象时，将传入对应的 Bean。（注解式的构造器注入） 在Setter或其他方法上加上 @Autowired ，则 Spring 初始化 Bean后，会尽量满足 Bean 的依赖，就会注入指定的 Bean。（注解式的属性注入） 将 @Autowired 直接加在属性上 理解\r#\r控制反转的优点：\n（理解中，依赖注入和自动装配机制，都是为了让控制反转模式能够合理运行的实现）\n如A需要B实现功能\n按传统模式，则需要在 A 中 new B()，这时当 B 需要改动时，则 A 与 B 有关的功能代码可能都需要改动 有了控制反转，将依赖关系交给容器装配，则我们只需改动 B，就可以让容器初始化一个不同的 B 注入到 A 中，尽量少地避免了上层的改动 这其实是依赖倒置原则的实现 实现依赖倒置原则，使得高层建筑可以不关心底层建筑的实现，避免牵一发动全身 为了实现依赖倒置原则，思路是做控制反转，方法是实现依赖注入，为了实现依赖注入，做了个IOC容器去管理Bean的生成和装配等 降低了组件间的耦合度 在Spring项目中的影响逻辑：\n由于依赖倒置原则具有修改底层建筑，尽量少地影响上层建筑地好处 Spring为了实现依赖倒置原则，构想了控制反转的模式。即将对象的创建、装配、生命周期管理等，交给 IOC 容器来进行，相比让对象自己去 new，使得组件间耦合度降低 IOC 容器管理 Bean，首先是在启动时，通过读取 XML/ Java 注解等方式，理解声明的 Bean 和装配方式，生成 Bean 并注册到容器中，进行后续管理。 组件的耦合度降低页实现了 Controller、Service、Dao 软件各层之间的解耦 IOC 容器创建 Bean 提供了单例模式的支持，使得开发人员不需要自己实现 组件间的解耦使得 Spring 使用第三方组件时可以实现无痛的切换底层实现，优势仅需修改一些配置，即可使得实例化地 Bean 是另一套实现，则被注入地是另一套实现，只需做好底层接口即可。 "},{"id":5,"href":"/codestack/docs/basic/","title":"计算机基础","section":"Docs","content":"\r计算机基础\r#\r"},{"id":6,"href":"/codestack/docs/javaee/spring/aop/","title":"AOP","section":"Spring","content":"\rAOP\r#\r基本概念：\n编程时将所需逻辑写在切面中 这么做的好处是，让一些公共的逻辑，重复的代码，能够出现在统一的位置，即切面中，方便维护，减少重复代码的开发量。\n思路上，是通过为某些切面，为某些方法提供行为增强。这种增强可能出现在方法执行前，方法执行后，方法返回前，方法异常时等。 实现方法上，出于对某个方法进行前置或后置逻辑的编写的角度，想要通过代理模式来实现功能。 Spring的切面实现，支持了两种代理模式：JDK动态代理（默认）、CGLIB动态代理\nSpring的动态代理实现\r#\r众所周知，代理模式的实现方法就是为当前类或者方法创建代理类\n实际调用时调用代理类 代理类再调用原本方法逻辑，代理类本身可以在调用原本方法前后\u0026quot;编织\u0026quot;入一些定义好的代码，在调用原本方法前后执行\u0026quot;编织\u0026quot;入的方法，实现\u0026quot;方法增强\u0026quot; 探讨Spring如何实现动态代理，其实是探讨Spring如何动态创建代理类 静态代理是直接硬编码编写代理类，并替换调用方方法调用代理类 但是动态代理就需要有一套代码，能根据不同内容的原本类，动态构建一个代理类，并在调用原本方法前后调用切面类内编写的增强方法 静态代理示例\r#\rclass ProxySubject implements Subject {\rprivate RealSubject realSubject;\rpublic ProxySubject(RealSubject realSubject) {\rthis.realSubject = realSubject;\r}\r@Override\rpublic void request() {\r// 方法调用前的增强代码\rSystem.out.println(\u0026#34;ProxySubject: Before calling the real subject.\u0026#34;);\r// 调用被代理对象的方法\rrealSubject.request();\r// 方法调用后的增强代码\rSystem.out.println(\u0026#34;ProxySubject: After calling the real subject.\u0026#34;);\r}\r} Spring AOP 动态代理源码解析\r#\r接下来从源码层面逐一剖析Spring是如何实现AOP\n使用项目：跬步后端项目仓库 Branch: main commit: f2763b5c8308f59a399ad32ae2cdffef8aee1ee0 我的项目采用 SpringBoot:2.7.6 版本，直接引入 spring-boot-starter-aop 包 spring-boot-starter-aop 包内含 org.springframework.spring-aop 和 org.aspectj.aspectjweaver 包 在项目启动类中，加上了 @EnableAspectJAutoProxy 注解开启 AOP 功能，从这里开始往下梳理\n@SpringBootApplication\r@EnableAspectJAutoProxy\rpublic class Application {\rpublic static void main(String[] args) {\rSpringApplication.run(Application.class, args);\r}\r} 在 @EnableAspectJAutoProxy 注解中，导入了 AspectJAutoProxyRegistrar 类\n@Target({ElementType.TYPE})\r@Retention(RetentionPolicy.RUNTIME)\r@Documented\r@Import({AspectJAutoProxyRegistrar.class})\rpublic @interface EnableAspectJAutoProxy {\rboolean proxyTargetClass() default false;\rboolean exposeProxy() default false;\r} Spring启动过程中会对配置类进行解析和处理，其中包括对各种注解的解析\n当扫描到 @Import 注解时，会根据导入的类进行对应的处理，当前导入的 AspectJAutoProxyRegistrar 类是 ImportBeanDefinitionRegistrar 接口的实现类，对于这样的类，Spring 执行时会将它实例化，并执行其中的 registerBeanDefinitions 方法\nregisterBeanDefinitions 会调用 registerAspectJAnnotationAutoProxyCreatorIfNecessary 方法 在 registerAspectJAnnotationAutoProxyCreatorIfNecessary 方法调用链上，会将 AnnotationAwareAspectJAutoProxyCreator 类定义注册到 Spring ，Spring容器启动时会根据 BeanDefinition 创建 Bean 同时 AnnotationAwareAspectJAutoProxyCreator 的父类 AbstractAutoProxyCreator 实现了 BeanPostProcessor 接口的 postProcessAfterInitialization 方法，在容器内 Bean 初始化后，Spring 容器会遍历所有注册的 BeanPostProcessor 实现类，并依次调用它们的 postProcessAfterInitialization 方法，所以该方法会经过所有的 Bean 而 AbstractAutoProxyCreator 是 Spring AOP 中自动创建代理的抽象基类，其核心作用是在 Spring 容器创建 Bean 的过程中，自动为符合条件的 Bean 创建代理对象，包括各式各样需要代理类的方法，比如可能的Mapper、Service、Controller等会出现在这里\n我的项目中创建了 LoginAspect 切面\n@Aspect\r@Component\rpublic class LoginAspect {\r@Pointcut(value = \u0026#34;@annotation(com.awesome.kuibuservice.annotation.Login)\u0026#34;)\rpublic void pointCut() {\r}\r@Around(\u0026#34;pointCut()\u0026#34;)\rpublic Object checkToken(ProceedingJoinPoint joinPoint) throws Throwable {\r# 切面逻辑\r}\r} 该切面以一个注解定义切点，并在 UserController 的 getUserInfo 方法加上了注解\n@RequestMapping(\u0026#34;/user\u0026#34;)\r@RestController\rpublic class UserController {\r@Login\r@GetMapping(\u0026#34;/userinfo\u0026#34;)\rpublic R\u0026lt;UserInfoDto\u0026gt; getUserInfo() {\r# 接口逻辑\r}\r} 以下显示这个 Bean 被扫描到，发现该 Bean 具有适用的增强器 LoginAspect，需要创建代理对象 于是调用 createProxy 为这个 Bean 创建代理对象 在 createProxy 方法中，将增强器列表交给 ProxyFactory , 并调用 ProxyFactory.getProxy 创建代理对象\n在 getProxy 方法中，调用了 createAopProxy 方法，该方法属于 ProxyFactory 的父类 ProxyCreatorSupport ，ProxyCreatorSupport 的父类是 AdvisedSupport，之前被设置给 ProxyFactory 的增强器列表放在该类的 advisors 属性中\ncreateAopProxy 方法调用 AopProxyFactory 的 createAopProxy 方法，并将 ProxyCreatorSupport 对象本身传入，前面说过 ProxyCreatorSupport 带有增强器列表 advisors AopProxyFactory 的 createAopProxy 方法，带有增强器列表，根据条件选择创建 JDK 动态代理，或 Cglib 动态代理 代码解释：\nif (NativeDetector.inNativeImage() || !config.isOptimize() \u0026amp;\u0026amp; !config.isProxyTargetClass() \u0026amp;\u0026amp; !this.hasNoUserSuppliedProxyInterfaces(config)\r) {\rreturn new JdkDynamicAopProxy(config);\r} 如果处于原生镜像环境，就使用JDK动态代理 如果没有开启优化选项、且没有强制使用 CGLIB 代理目标类、且没有用户提供的代理接口，就使用JDK动态代理 else {\rClass\u0026lt;?\u0026gt; targetClass = config.getTargetClass();\rif (targetClass == null) {\rthrow new AopConfigException(\u0026#34;TargetSource cannot determine target class: Either an interface or a target is required for proxy creation.\u0026#34;);\r} else {\rreturn (AopProxy)(!targetClass.isInterface() \u0026amp;\u0026amp; !Proxy.isProxyClass(targetClass) \u0026amp;\u0026amp; !ClassUtils.isLambdaClass(targetClass) ? new ObjenesisCglibAopProxy(config) : new JdkDynamicAopProxy(config));\r}\r} 在能获取到目标类的基础上：\n如果目标类不是接口、不是 JDK 代理类且不是 Lambda 表达式类，则使用 CGLIB 代理\n接下来分别解释两种动态代理的创建\nCGLIB 动态代理\r#\r可能由于版本等原因，我的项目实现的自定义切面，就算让切点加在实现了接口的方法上，为目标类生成的代理类仍是 CGLib 代理\n可以设置强制其在切点加在实现了接口的方法上时实现JDK自动代理，以便 Debug ，但是目前注解加在没有实现接口的 controller api 方法上\n先讨论 CGLib 动态代理\n在这块代码中，if 中的判定结果和含义如下：\nNativeDetector.inNativeImage() 为 false ，表示当前不是运行在原生镜像环境，而是普通Java虚拟机环境 !config.isOptimize() 为 false ，表示 AOP 启用了某种优化设置 !config.isProxyTargetClass() 为 false ，表示 AOP 配置指定使用目标类代理，即无论目标对象是否实现接口，都优先使用 CGLIB 代理来创建代理对象，而不是 JDK 动态代理 else 中的判定结果和含义如下：\n!targetClass.isInterface() 为 true，表明目标类不是接口，而是具体类。JDK 动态代理只能对实现了接口的类进行代理，此时应使用 CGLIB 代理 !Proxy.isProxyClass(targetClass) 为 true，表明目标类不是一个 JDK 动态代理生成的类，可以考虑使用 CGLIB 对其生成代理 !ClassUtils.isLambdaClass(targetClass) 为 true，表明目标类不是 Lambda 表达式生成的类，可以考虑使用 CGLIB 对其生成代理 于是方法最终生成执行了 new ObjenesisCglibAopProxy(config)，主要功能是利用 CGLIB 库生成目标对象的代理对象，而 config 中包含了需要织入代理对象执行前后的增强器列表\n所以在 ProxyFactory.getProxy 方法中，createAopProxy() 返回的是 ObjenesisCglibAopProxy 对象 getProxy() 方法由 CglibAopProxy 实现 继续 Debug 进入 CglibAopProxy 的 getProxy() 方法实现\n其中关键在于，带有增强器方法的 callbacks 被带入代理对象的创建和实例化方法中 继续 debug createProxyClassAndInstance 方法，实际执行的是 ObjenesisCglibAopProxy 的实现 可见该方法就是创建代理类并实例化，并将带有增强器列表的 DynamicAdvisedInterceptor 对象设置到代理对象中\n以上源码揭示的是，CGLIB 创建代理对象的过程，而这一切代理对象的创建源头是最初 AbstractAutoProxyCreator 类的 BeanPostProcessor 接口的 postProcessAfterInitialization 方法实现被 Spring 扫描执行，所以对于当前被扫描到的 Bean userController，Cglib为其创建了代理对象如下，其代理对象包含了增强器方法，而 Spring 容器实际管理的 Bean 也是这个代理对象，也就是所谓的增强器被织入代理对象 调用 API 执行到该 userController 的方法时，Spring 实际是取得 userController 的 CGLib 代理对象，尝试调用其方法\n而在创建 CGLib 代理对象时，是使用字节码技术生成代理类并实例化，可以在 ObjenesisCglibAopProxy 的 createProxyClassAndInstance 查看 enhancer.createClass() 底层创建了类，生成的类中有诸多方法，不过无法看见其实现细节\n总之，代理类方法被调用时，会调用其回调方法，而前面提到，我们的代理对象中携带增强器列表的是 DynamicAdvisedInterceptor 对象，其带有自定义切面 LoginAspect 增强器，找到DynamicAdvisedInterceptor 进行 debug，它是 CglibAopProxy 的静态内部类，也是 MethodInterceptor 实现类，在 api 方法 被调用时，触发 MethodInterceptor 拦截，执行其实现的 interceptor 方法 interceptor 方法中debug，可见其构建了拦截器链，并 new CglibMethodInvocation 对象，执行了 proceed 方法 new CglibMethodInvocation 时传入了拦截器链，设置到了父类属性 ReflectiveMethodInvocation.interceptorsAndDynamicMethodMatchers 上\n而在执行 proceed 方法时，将拦截器取出并执行，可见执行的拦截器就是我们自定义切面中的代码\nJDK 动态代理\r#\r通过设置配置文件 spring.aop.proxy-target-class=false 可以生成 JDK 动态代理 无非是在创建代理对象时判定了执行 new JdkDynamicAopProxy(config) 条件分支，使用 JDK 提供的字节码生成技术来生成代理对象，而后的设置增强器列表、执行时执行拦截器方法等流程都和 CGLib 基本一致 总结\r#\r总的来说，Spring 的动态代理实现过程就是\n在 Bean 初始化过程中，判断如果需要生成代理对象，就根据当前配置，生成 JDK 动态代理对象或 CGLib 动态代理对象，然后将代理对象作为实际的 Bean 交给 Spring 容器管理 代理对象设置了 advice 拦截器方法链 （所谓的切面方法增强 织入目标方法前后） 当目标类方法被调用时，实际上是代理对象的方法被调用，而代理对象方法调用目标类方法前后，根据方法上的 advice 拦截器链执行各个切面代码，完成方法的增强功能 "},{"id":7,"href":"/codestack/docs/javaee/mysql/innodb_transaction/","title":"InnoDB 事务","section":"MySQL","content":"\rInnoDB 事务\r#\rMySQL中，事务功能主要是由 InnoDB 存储引擎来实现的\nInnoDB 事务特性（ACID）及实现\r#\r原子性（Atomicity）\r#\r事务内的操作要么全部成功，要么全部失败\n通过Undo Log实现原子性\nUndo Log 记录事务操作的反操作，或者说记录了每个操作前的数据，当事务需要回滚时，可以根据Undo Log恢复数据。\n从而实现事务内的操作要么全部执行，要么都不执行\n一致性（Consistency）\r#\r事务必须使数据库从一个一致性状态变换到另一个一致性状态\n依赖于原子性和隔离性的实现，还依赖于数据库自身的完整性约束(如外键、CHECK 约束等)和应用程序的正确逻辑\n持久性（Durability）\r#\r一个事务一旦被提交了，那么对数据库中的数据的改变就是永久性的，即便是在数据库系统遇到故障的情况下也不会丢失提交事务的操作\n通过数据写入磁盘，以及Redo Log记录写入内存未写入磁盘的操作，在系统崩溃恢复时写入磁盘。保证持久性\nRedo Log本身在磁盘顺序写入，速度很快\n隔离性（Isolation）\r#\r多个并发事务之间要相互隔离。对于任意两个并发的事务T1和T2，在事务T1看来，T2要么在T1开始之前就已经结束，要么在T1结束之后才开始\n通过MVCC和锁机制实现隔离性\n先说明MVCC隔离性实现原理，锁机制放在锁的篇章中\nMVCC\r#\rinnodb通过ReadView快照和版本链实现MVCC\nReadView 快照\r#\rReadview是代码中的对象，主要有如下属性：\nm_ids: 生成ReadView时当前系统中活跃的读写事务的事务id列表（未提交的事务） min_trx_id: 生成ReadView时当前系统中活跃的读写事务的最小事务id m_ids的最小值（最早的未提交事务） max_trx_id: 生成ReadView时系统应该分配给下一个事务的id值（下一个事务） creator_trx_id: 生成该ReadView的事务的id（所属事务） 版本链\r#\r在Innodb中，以最新记录和 undo log 中的历史记录形成了版本链\nInnodb的每行数据，都有两个隐藏字段：事务ID和回滚指针\n事务ID代表这行数据由哪个事务最后更新，回滚指针指向Undo Log中这行数据的上一个版本 Undo Log中记录了数据的每个版本，同样也携带着修改成该版本的事务ID和指向上一个版本的回滚指针 每行最新的数据，以及Undo Log中的历史版本中的数据，的回滚指针们形成了一条链表，即版本链 事务的每个修改，不论是否已经提交，都会被记录在版本链上 MySQL 中有专门的 Purge 线程，会定期检查 Undo Log，删除那些已经不再需要的记录\nPurge 操作会遍历 Undo Log 链表，找到那些没有被任何活动事务引用的节点，并将其从磁盘上删除，释放空间\n以可重复读为例说明MVCC的实现\r#\r在事务隔离级别为可重复读情况下，执行select前，会先生成ReadView\n通过ReadView在版本链中进行比较，可知版本链上的哪些数据是可以被自己访问的\ntrx_id是该行的版本链上某个版本的事务ID\ntrx_id == creator_trx_id Readview自己修改的数据，可以访问 trx_id \u0026lt; min_trx_id Readview创建之前的已提交数据，可以访问 trx_id \u0026gt; max_trx_id 创建在Readview事务之后的数据，不可访问 min_trx_id \u0026lt;= trx_id \u0026lt;= max_trx_id Readview创建时尚未提交的数据，不可访问 所以：通过ReadView的事务信息，以及版本链上数据的事务信息，以及事务ID的全局自增，可以得知当前事务可以访问哪些数据！\n对可重复读而言，仅在第一次select时生成ReadView即可\n此后每次查询，访问到的数据都是以该ReadView为基准\n从而每次要么访问到自己的最新修改，要么一直是生成当时的最新提交数据，不会变化\n同理可看其他事务级别：\n读已提交： 每次select都会生成ReadView，新的ReadView可以访问新提交的数据\n于是每次select都可以访问到最新的提交数据，或者是自己的修改数据 读未提交： 每次直接访问最新的版本链数据，不关心是否提交，不需要MVCC 串行化： 通过加锁互斥访问，不需要MVCC 对MVCC的误读\r#\r并非所有增删改查都使用快照读\n实际上只有select 使用MVCC快照读\n但update insert delete都是当前读！\n在 MySQL 的可重复读隔离级别下，UPDATE、DELETE、INSERT操作隐式使用当前读，并通过加锁（行锁、间隙锁或表锁）保证数据一致性和防止幻读\n"},{"id":8,"href":"/codestack/docs/javaee/","title":"JavaEE","section":"Docs","content":"\rJavaEE\r#\r"},{"id":9,"href":"/codestack/docs/deploy/mysql/","title":"MySQL","section":"部署","content":"\rMySQL\r#\r安装版本：MySQL 8.0.20\n部署方式：一主二从\n运行方式：docker-compose\n各节点安装\r#\r创建MySQL目录\r#\r# 放置所有mysql相关文件 比如my.cnf\rsudo mkdir /DATA/mysql\r# 放置mysql数据文件 也作为mysql\rsudo mkdir /DATA/mysql/mysql 创建MySQL用户并设置权限\r#\r# 创建mysql用户 设置为不可登陆系统 并设置用户的主目录为/DATA/mysql/mysql\rsudo useradd -r -s /sbin/nologin -d /DATA/mysql/mysql mysql\r# 指定mysql用户的主目录为/DATA/mysql/mysql\rsudo usermod -d /DATA/mysql/mysql mysql\r# 递归地将/DATA/mysql/mysql目录及其所有子目录和文件的所有者和所属组设置为mysql用户和mysql组\rsudo chown -R mysql:mysql /DATA/mysql/mysql\r# 递归地将/DATA/mysql/mysql目录及其子目录设和文件的权限设置为755\r# 755：所有者有读写和执行权限，组用户和其他用户有读和执行权限\rsudo chmod -R 755 /DATA/mysql/mysql\r# 查找/etc/passwd文件中包含mysql的行 /etc/passwd是系统用户信息文件，包含所有用户的基本信息\rgrep mysql /etc/passwd 操作失误时的可选操作\n# 删除用户及其主目录 没有r不删除主目录\rsudo userdel -r mysql\r# 手动删除主目录\rsudo rm -rf /DATA/mysql\r# 检查 grep mysql /etc/passwd\r# 删除用户组\rsudo groupdel mysql\r# 检查用户组是否删除\rgrep mysql /etc/group docker-compose文件\r#\r# 创建docker-compose文件在/DATA下，或者追加在已有文件中\rvim docker-compose.yml docker-compose.yml\nversion: \u0026#39;3\u0026#39; # 使用docker-compose版本3\rservices: # 定义服务\rmysql8: # 定义一个名为mysql8的服务\rimage: mysql:8.0.20 # 使用MySQL 8.0.20镜像\rcontainer_name: mysql8 # 指定容器名称为mysql8\rrestart: always # 系统重启时自动重新启动\rcap_add:\r- SYS_NICE\rports: # 定义容器和主机之间的端口映射\r- \u0026#34;33060:3306\u0026#34; # 将容器的3306端口映射到主机的33060端口\renvironment: # 定义环境变量\rMYSQL_ROOT_PASSWORD: \u0026#34;password\u0026#34; # 设置root用户的密码\rvolumes: # 定义数据卷\r- /DATA/mysql/mysql:/var/lib/mysql # 挂载数据目录\r- /DATA/mysql/my.cnf:/etc/mysql/my.cnf # 挂载my.cnf\rhealthcheck:\rtest: [\u0026#34;CMD\u0026#34;, \u0026#34;mysqladmin\u0026#34; ,\u0026#34;ping\u0026#34;, \u0026#34;-h\u0026#34;, \u0026#34;localhost\u0026#34;, \u0026#34;-u\u0026#34;, \u0026#34;user\u0026#34;, \u0026#34;-ppassword\u0026#34;] # 设置容器健康检查命令\rinterval: 20s # 每隔20秒进行一次健康检查\rtimeout: 10s # 健康检查超时时间为10秒\rretries: 3 # 健康检查失败时重试次数为3次 服务器间文件复制\r#\r# scp [源文件路径] [目标服务器用户名]@[目标服务器IP]:[目标路径]\rscp -P [ssh port] /home/user/file.txt user@192.168.1.2:/home/user/\r# scp [源服务器用户名]@[源服务器IP]:[源文件路径] [目标路径]\rscp -P [ssh port] user@192.168.1.2:/home/user/file.txt /home/user/ 授权文件\nsudo chmod 777 /DATA/docker-compose.yml my.cnf文件\r#\rsudo vim /DATA/mysql/my.cnf my.cnf\n[mysqld]\r# 指定数据目录\rdatadir = /var/lib/mysql\r# 安全文件前缀\rsecure-file-priv = NULL\r# 不进行域名解析\rskip-name-resolve\r# 默认存储引擎\rdefault-storage-engine = InnoDB\r# 服务器监听的ip地址\rbind-address = 0.0.0.0\r# 服务器监听的端口号\rport = 3306\r# 连接配置\r# 最大连接数\rmax_connections = 2000\r# 单个用户最大连接数\rmax_user_connections = 1000 # 最大连接错误数\rmax_connect_errors = 4000 # 空闲连接的超时时间\rwait_timeout = 300 # 交互式连接的超时时间 数据库管理工具的连接 那些手动执行SQL的可能长时间空闲\rinteractive_timeout = 600 # 最大允许的数据包大小 避免一次查出太多数据打崩数据库\rmax_allowed_packet = 32M # 日志设置\r# 使用短格式记录日志\rlog-short-format = 1 # 启用慢查询日志\rslow_query_log # 慢查询的时间阈值 2s及以上的查询被作为慢查询记录\rlong_query_time = 2 [mysqldump]\rquick # 快速导出数据\rmax_allowed_packet = 16M # 最大允许的数据包大小\r[mysqlhotcopy]\rinteractive-timeout = 3600 # 交互式超时时间，超时时间设置为 1 小时 授权文件\n# 所有者读写，组成员和其他用户可读不可写，完全不可执行\rsudo chmod 644 /DATA/mysql/my.cnf docker compose运行镜像\r#\rsudo docker-compose up -d mysql8 docker compose停止镜像\r#\rsudo docker-compose stop mysql8 docker compose重启镜像\r#\rsudo docker-compose restart mysql8 日志查看\r#\rsudo docker logs mysql8 防火墙配置\r#\rsudo ufw allow 33060/tcp root用户限制为局域网访问\r#\r# 进入docker\rsudo docker exec -it mysql8 /bin/bash\r# 登录mysql\rmysql -u root -p your_password\r# 使用mysql数据库\ruse mysql;\r# 删除\u0026#39;root\u0026#39;@\u0026#39;%\u0026#39; 不删除\u0026#39;root\u0026#39;@\u0026#39;localhost\u0026#39; 保留本机访问权限\rDROP USER \u0026#39;root\u0026#39;@\u0026#39;%\u0026#39;;\r# 创建\u0026#39;root\u0026#39;@\u0026#39;192.168.1.*\u0026#39; 建立局域网访问权限\rCREATE USER \u0026#39;root\u0026#39;@\u0026#39;192.168.1.%\u0026#39; IDENTIFIED BY \u0026#39;*******\u0026#39;;\rGRANT ALL PRIVILEGES ON *.* TO \u0026#39;root\u0026#39;@\u0026#39;192.168.1.%\u0026#39; WITH GRANT OPTION;\rFLUSH PRIVILEGES; 主从配置\r#\r主节点配置\r#\rmy.cnf配置\r#\rsudo vim /DATA/mysql/my.cnf 要在[mysqld]部分添加\n# 主从配置 - 主节点\r# MySQL服务id 各节点不同\rserver_id = 1010\r# 开启二进制日志\rlog-bin = mysql-bin\r# 日志格式\rbinlog_format = ROW 重启MySQL服务\r#\r# 要在所需docker-compose.yml文件同文件夹下执行\rsudo docker-compose restart mysql8 检查server-id配置确保生效\r#\r# 连接数据库执行\rSHOW VARIABLES LIKE \u0026#39;server_id\u0026#39;; 创建复制用户并赋予权限\r#\rCREATE USER \u0026#39;repl\u0026#39;@\u0026#39;192.168.1.%\u0026#39; IDENTIFIED WITH mysql_native_password BY \u0026#39;repl_password\u0026#39;;\rGRANT REPLICATION SLAVE ON *.* TO \u0026#39;repl\u0026#39;@\u0026#39;192.168.1.%\u0026#39;;\rFLUSH PRIVILEGES; 查看主服务器的二进制日志信息并记录\r#\rSHOW master status\r# 记录File和Position值 从节点配置\r#\rmy.cnf配置\r#\rsudo vim /DATA/mysql/my.cnf 要在[mysqld]部分添加\n# 主从配置 - 从节点\r# MySQL服务标识id 每个节点不同 大于0\rserver_id = 1020\r# 从节点不建议开启二进制日志\r# 从节点设置为只读 然后在应用层做数据源切换 读写分离\r# 仅read-only， root用户还是可以建表，普通用户只读\r# 5.7.8后添加了super_read_only root用户也不可以执行读以外的操作\rsuper_read_only = 1 重启MySQL服务\r#\rsudo docker-compose restart mysql8 配置从服务器连接主服务器\r#\r登录从服务器的MySQL数据库执行\nCHANGE MASTER TO\rMASTER_HOST = \u0026#39;192.168.1.x\u0026#39;, # 主服务器的 IP 地址\rMASTER_PORT = \u0026#39;33060\u0026#39;, # 主服务器MySQL端口\rMASTER_USER = \u0026#39;repl\u0026#39;, # 复制用户的用户名\rMASTER_PASSWORD = \u0026#39;repl_password\u0026#39;, # 复制用户的密码\rMASTER_LOG_FILE = \u0026#39;mysql-bin.00000x\u0026#39;, # 主服务器的二进制日志文件名\rMASTER_LOG_POS = 1234; # 主服务器的二进制日志位置\r# CHANGE MASTER TO之后，有任何SQL执行都会导致MASTER_LOG_POS变化\r# 需要再次查看Master Status，停止复制修改后，再开始复制 MASTER_LOG_FILE 和 MASTER_LOG_POS 的值从主服务器的 SHOW MASTER STATUS; 命令中获取\n启动从服务器的复制进程\r#\rSTART SLAVE; 停止从服务器的复制进程\r#\rSTOP SLAVE; 检查从服务器的复制状态\r#\rSHOW SLAVE STATUS;\r# 确保Slave_IO_Running和Slave_SQL_Running都是Yes 验证主从复制\r#\r主服务器写数据，查看从服务器是否变更\n一些常见操作\r#\r配置时主节点常用命令\r#\rSHOW VARIABLES LIKE \u0026#39;server_id\u0026#39;;\rSHOW master status;\rSHOW GRANTS FOR \u0026#39;repl\u0026#39;@\u0026#39;192.168.1.%\u0026#39;;\rDROP USER \u0026#39;repl\u0026#39;@\u0026#39;192.168.1.%\u0026#39;\rCREATE USER \u0026#39;repl\u0026#39;@\u0026#39;192.168.1.%\u0026#39; IDENTIFIED WITH mysql_native_password BY \u0026#39;repl_password\u0026#39;;\rGRANT REPLICATION SLAVE ON *.* TO \u0026#39;repl\u0026#39;@\u0026#39;192.168.1.%\u0026#39;;\rFLUSH PRIVILEGES; 配置时从节点常用命令\r#\rSHOW VARIABLES LIKE \u0026#39;server_id\u0026#39;;\rCHANGE MASTER TO\rMASTER_HOST = \u0026#39;192.168.1.11\u0026#39;,\rMASTER_PORT = 33060,\rMASTER_USER = \u0026#39;repl\u0026#39;,\rMASTER_PASSWORD = \u0026#39;repl_password\u0026#39;,\rMASTER_LOG_FILE = \u0026#39;mysql-bin.000001\u0026#39;,\rMASTER_LOG_POS = 1739;\rSTOP SLAVE;\rSTART SLAVE;\rSHOW SLAVE STATUS; 登陆的是从节点，查找主节点IP\r#\rSHOW SLAVE STATUS;\r# Master_Host 和 Master_Port 二进制日志格式的区别\r#\rROW（5.7之后官方默认的选择）： 基于行的复制，记录的是每行的变化，可读性差，文件大，传输慢，但可以应对各种情况的影响 对于 INSERT 操作，记录插入的每一行数据 对于 UPDATE 操作，记录修改前和修改后的每一行数据 对于 DELETE 操作，记录被删除的每一行数据 绝对的数据一致性保证 STATEMENT：最初的MySQL主从复制模式，不推荐选择 记录的是SQL，文件小传输快 遇到非确定函数如NOW RAND UUID等，主从库执行的结果会不同 遇到存储过程和触发器可能无法正确复制 遇到用户自定义函数，可能会在主从库产生不同的效果 某些场景下 LAST_INSERT_ID()可能在主从库上值不一致 MIXED：混合模式，一些情况下可能有人选择 普通SQL记录为STATEMENT形式，有可读性 遇到非确定性函数等转换为ROW格式记录 复杂场景下如存储过程、触发器，可能会导致数据不一致 如果对数据一致性要求极高，且对日志大小和性能的影响可以接受，建议使用 ROW 格式。↑\n如果需要在性能和一致性之间取得平衡，且希望减少日志大小和管理复杂性，建议使用 MIXED 格式\n完全不要用STATEMENT格式\n一主多从和多主多从的配置区别\r#\r多主多从： 主节点之间互为主从，可能出现数据冲突需要在应用层避免，或者引入冲突解决机制（如conflict-resolution 插件） 从节点要设置每个主节点为主节点，为每个主节点单独配置复制通道，便于从多个主节点获取数据（多源复制）\n"},{"id":10,"href":"/codestack/docs/javaee/mysql/","title":"MySQL","section":"JavaEE","content":"\rMySQL\r#\r逻辑架构\r#\r主要可以分为三层：\n最上层：包括客户端连接/线程处理，不是MySQL独有的部分，大多数基于网络的C/S架构的工具或者服务都有类似的架构。用于：连接处理、授权认证、安全等。 第二层：包括大多数MySQL的核心服务功能，包括查询解析、分析、优化、缓存和所有的内置函数（例如：日期、时间、数学和加密函数）。所有跨存储引擎的功能都在这层实现：存储过程、触发器、视图等。 第三层：包括存储引擎。存储引擎负责数据的存储和提取，每个存储引擎各有优劣。服务器通过API与存储引擎进行通信，使用接口屏蔽了存储引擎之间的差异。存储引擎API包含几十个底层函数，用于执行“开始一个事务”“根据主键提取一行记录”等操作。存储引擎不会解析SQL，存储引擎间不也互相通信，仅仅是响应上层服务器的请求。 连接管理与安全性\r#\r每个客户端都会在服务器进程中拥有一个线程，这个连接的查询只在这个单独的线程中执行，线程只能轮流在某个CPU核心或CPU中运行。服务器会缓存线程，避免为每个连接频繁创建和销毁线程。\n客户端连接使用用户名、原始主机信息和密码校验，也可使用SSL方式连接。连接成功后会验证是否有执行某个特定查询的权限。\n优化与执行\r#\rMySQL会解析查询，并创建内部数据结构（解析树），对其进行各种优化，包括重写查询、决定表的读取顺序以及选择合适的索引等。\n用户可以通过特殊的关键字提示(hint)优化器，影响它的决策过程。 也可以通过请求优化器解释(explain)优化过程的各个因素，让用户知道服务器如何进行优化，便于用户重构查询、修改相关配置使应用尽可能高效运行。\n优化器不关心表使用的存储引擎，但会请求存储引擎提供容量或者某个具体操作的开销信息，表数据的统计信息等。例如如果存在某些存储引擎的某种索引，可能会在特定的查询时进行优化。\n对于Select语句，解析查询前，会先检查查询缓存（Query Cache），如果能找到对应的查询，就不再执行后续过程，直接返回结果集。\n版本差异\r#\r5.5\r#\rinnodb成为默认存储引擎 此前是MyISAM，但Innodb在高并发、数据一致性要求高的场景更具优势 半同步复制 异步复制基础上改进，主服务器等待至少一个从服务器确认收到事务日志后才提交日志，提高了数据的安全性和复制的可靠性 分区表增强 支持哈希分区、键分区等，并提升了分区性能，提高大数据量下的查询性能 5.6\r#\r性能提升 引入索引合并优化、多范围读优化、批量键访问优化。减少磁盘IO次数，提升查询效率 复制改进 引入基于全局事务标识符(GTID)的复制，使复制配置和管理简单可靠，降低复制过程错误概率，同时支持并行复制，提升复制性能 内置审计 提供内置审计插件，可以对数据库操作进行审计，便于管理员监控和记录数据库的使用情况，增强数据库安全性 5.7\r#\rJSON数据类型支持 支持原生JSON数据类型，提供了操作JSON的函数，便于存储和处理半结构化数据 性能提升 引入即时ADD COLUMN操作，添加新列无需重建整个表，大大提高表结构修改效率。同时提升Innodb的并发处理能力 增强复制 在GTID复制基础上，支持多源复制，允许一个从服务器同时从多个主服务器复制数据 8.0\r#\r角色管理 允许管理员创建角色并分配权限，然后将角色授予用户，简化权限管理 窗口函数 支持如ROW_NUMBER()、RANK()、DENSE_RANK()等窗口函数，可以在不使用子查询的情况下进行复杂的排名和分组计算 Innodb增强 支持降序索引、优化自增主键性能等 "},{"id":11,"href":"/codestack/docs/javaee/mysql/innodb_lock/","title":"InnoDB 锁机制","section":"MySQL","content":"\rInnoDB 锁机制\r#\r锁分类和特性\r#\rS锁与X锁互斥，与S锁兼容 X锁与S/X锁互斥 加锁是实际是锁索引或者锁表 如果用了主键就锁聚簇索引 如果用了二级索引就锁定二级索引再锁定聚簇索引 如果没用到索引，就锁表 锁的释放时机是事务提交或回滚 行级锁\r#\r基本的加锁是临键锁，因为一些条件转换为间隙锁、行锁、表锁 记录锁（S/X锁）\r#\r单索引值锁\n间隙锁（S锁）\r#\r在两行/两索引之间的左开右开区间锁 间隙锁S与插入意向锁X互斥，作用是防止其他事务插入数据，避免幻读 间隙锁S之间是兼容的 临键锁（S/X记录锁+s间隙锁）\r#\r对记录行，以及以记录行本身主键/索引值为右边界，往前一个主键值/索引值为左边界的，左开右闭区间锁 临键锁的记录部分与其他临键锁的记录部分根据记录锁的S/X区分冲突 临键锁的记录部分与其他临键锁的间隙锁不会冲突，不如说不存在加了间隙锁还有记录在中间的情况，也不存在有记录锁居然能加间隙锁的情况 临键锁的间隙锁和其他临键锁的间隙锁不冲突 插入意向锁（X模式间隙锁）\r#\r与普通S间隙锁互斥，插入意向锁之间不互斥（特殊） insert插入数据时，需要对所在间隙加插入意向锁，多个事务可以对同一间隙加插入意向锁 如果该间隙存在普通间隙锁，则插入意向锁会被阻塞 多个事务插入数据，只要对应主键和索引无约束冲突，就可以并发执行 表级锁\r#\r表锁（S/X锁）\r#\r当进行需要加锁操作，但是未能明确指定主键/索引时，Innodb会扫描全表，对主键聚簇索引加临键锁（覆盖所有行，等效表锁） 或显示使用 Lock Tables xxx write/read (Innodb不推荐，应优先行锁) 是极端状态下的行锁集合（全表行锁+间隙锁），性能极差 S表锁阻塞各种行X锁，不阻塞S锁。X表锁阻塞各种行X锁 意向锁（IS/IX锁，表级信号锁）\r#\r当事务对某行加行级S锁，自动对表加意向共享锁（IS锁） 当事务对某行加行级X锁，自动对表加意向排他锁（IX锁） 永远与行级S/X锁共存（行锁必然带有对应意向锁） 作用仅是标记“表中存在行锁”，以与全表锁互斥，不阻塞其他行锁和表意向锁 语句加锁情况枚举（可重复读级别）\r#\r可以根据语句加锁情况和对应区域锁的S/X模式，来理论判断锁冲突情况\n普通查询\r#\r不加锁，快照读，不会导致并发阻塞。且因为是快照读，不会幻读 基于MVCC进行快照读，查询开始时生成快照，可读取已提交事务和本快照事务修改的数据 SELECT \u0026hellip; FOR UPDATE\r#\r唯一索引等值查询且匹配到数据，对匹配行加行锁（X锁） 唯一索引范围查询且匹配到数据，对所有匹配行加临键锁（X记录锁+S间隙锁） 唯一索引查询未匹配到数据，目标值所在间隙加间隙锁（S锁） 普通索引范围查询匹配到数据，范围内索引项加临键锁（X记录锁+S间隙锁），对应主键行锁（X锁） 普通索引查询未匹配到数据，目标值所在间隙加间隙锁（S锁） 不使用索引/索引失效，退化为全表锁（各行X锁，间隙S锁） SELECT \u0026hellip; LOCK IN SHARE MODE\r#\r唯一索引等值查询且匹配到数据，对匹配行加行锁（S锁） 唯一索引范围查询且匹配到数据，对所有匹配行加临键锁（S记录锁+S间隙锁） 唯一索引查询未匹配到数据，目标值所在间隙加间隙锁（S锁） 普通索引范围查询匹配到数据，范围内索引项加临键锁（S记录锁+S间隙锁），对应主键行锁（S锁） 普通索引查询未匹配到数据，目标值所在间隙加间隙锁（S锁） 不使用索引/索引失效，退化为全表锁（各行S锁，间隙S锁） insert\r#\r单行插入 尝试对插入间隙加插入意向锁X锁，如果存在间隙锁S锁，就阻塞等待 加锁成功后执行插入，对插入位置加X锁，仅自己能插入，并执行插入 如果位置上有别的数据插入的数据，则阻塞等待其他事务提交释放锁 多个事务可以并发插入同个间隙的不同位置，不互相阻塞 批量插入 逐行执行多个单行插入，重复上述过程 update\r#\r对where条件匹配的行加X锁 如果用了唯一索引（索引扫描），对匹配索引值加记录X锁 如果用了普通索引（索引扫描），对匹配索引值加临键X锁 如果没有使用索引或者索引失效（全表扫描），对全表加X表锁(所有记录X临键锁) 如果会更新索引字段，旧索引项加X锁 delete\r#\r对where条件匹配的行加X锁 如果用了唯一索引（索引扫描），对匹配索引值加记录X锁 如果用了普通索引（索引扫描），对匹配索引值加临键X锁 如果没有使用索引或者索引失效（全表扫描），对全表加X表锁(所有记录X临键锁) 可以优化的操作方向\r#\r测试机检查\r#\r测试SQL执行究竟是加表锁还是行锁等，修改以避免表锁\n慎用显式加锁\r#\rselect \u0026hellip; for update 和 select \u0026hellip; lock in share mode 必须使用索引，并检查加锁情况，避免锁表\n减小加锁范围\r#\r每次事务，加锁范围尽量小，以提高并发量，减少并发冲突\n减少持锁时间\r#\r锁施放时间为事务提交时，如果数据库操作完毕后续的步骤失败不需要回滚数据，可以先提交事务，避免长事务，减少持锁时间，提升并发\n需要警惕的死锁操作场景\r#\r死锁的条件是 并发资源争抢 + 不同的加锁顺序\n在数据库中，并发的是事务，资源是行或者表，锁指的是互斥的锁对（X-S, X-X）\n可以说，只要两个事务同时要操作同一部分数据，并且涉及加锁（加锁读/insert/update/delete），就需要警惕死锁\n一般来说，最常见的是批量的insert/update/delete并发\ninsert批量不容易死锁，毕竟是逐行插入，就算两事务并发插入，针对的也是一块空白区域，每一行A先填，B就等，A提交释放锁再执行 update批量容易死锁，两事务同时update两行数据(同表或不同表)，A事务先更新1再更新2，B事务先更新2再更新1，并发时互相等锁导致死锁 扩展为两事务并发批量更新两部分数据，但是更新数据行有所重叠，并且更新顺序不同，可能导致死锁 delete批量不容易死锁，删了就删了 具体场景具体分析，充分考量并发情况下的各种加锁组合判断，并在测试库中测试对应情况是否死锁 加锁场景众多，仍需实践具体辨析\n"},{"id":12,"href":"/codestack/docs/javase/","title":"JavaSE","section":"Docs","content":"\rJavaSE\r#\r"},{"id":13,"href":"/codestack/docs/deploy/redis/","title":"Redis","section":"部署","content":"\rRedis\r#\r安装版本：7.0.4\n部署方式：一主二从三哨兵\n节点分配：每节点一个Redis-Server，一个Sentinel\n运行方式：docker-compose\n目录和用户权限\r#\r创建Redis和Sentinel目录\r#\r# 存放所有Redis相关文件\rsudo mkdir /DATA/redis\r# 存放Redis和Sentinel配置文件\rsudo mkdir /DATA/redis/config\r# 存放Sentinel配置和文件\rsudo mkdir /DATA/redis/config/sentinel\r# 存放挂载docker内运行Redis的数据目录\rsudo mkdir /DATA/redis/data 创建redis用户并设置工作目录\r#\r# 创建 redis 用户 设置为不可登陆系统 并设置用户的主目录为/DATA/redis/data\rsudo useradd -r -s /sbin/nologin -d /DATA/redis/data redis\r# 指定 redis 用户的主目录为/DATA/redis/data\rsudo usermod -d /DATA/redis/data redis\r# 递归地将/DATA/redis/data目录及其所有子目录和文件的所有者和所属组设置为redis用户和redis组\rsudo chown -R redis:redis /DATA/redis/data\r# 递归地将/DATA/redis/data目录及其子目录设和文件的权限设置为755\r# 755：所有者有读写和执行权限，组用户和其他用户有读和执行权限\rsudo chmod -R 755 /DATA/redis/data\r# 查找/etc/passwd文件中包含mysql的行 /etc/passwd是系统用户信息文件，包含所有用户的基本信息\rgrep redis /etc/passwd 主节点配置\r#\rredis.conf\r#\rsudo vim /DATA/redis/config/redis.conf\r# 监听端口\rport 63790\r# 访问密码\rrequirepass password\r# 数据库数量 使用cluster模式时只会有一个database即DB0\rdatabases 16\r# 绑定本机的网络接口（网卡） 绑定的是网卡的IP地址\r# 0.0.0.0 监听所有 默认127.0.0.1\rbind 0.0.0.0\r# 默认开启\r# 如果没有设置密码和且没有设置bind，只允许本机访问\rprotected-mode yes\r# 单位秒，timeout时间内客户端没有数据交互，关闭连接\rtimeout 60\r# 客户端同时连接的最大数量 默认10000\r# 达到最大值时关闭新连接并返回max number of clients reached\rmaxclients 1000\r# 内存管理 # 最大内存，推荐最大设置为6GB\r# 不要设置过大内存，防止执行RDB内存快照文件或者AOF重写时因为数据太大阻塞太长时间\rmaxmemory 2GB\r# 内存淘汰策略 默认noeviction\r# noeviction -\u0026gt; 不删除任何 key，内存满了直接返回报错\r# 默认情况下slave节点会忽略maxmemory配置，除非被提升为master\r# 只有master会执行内存淘汰策略，master删除key后会发送DEL指令给slave\rmaxmemory-policy noeviction\r# 过期key滞留在内存的比例 默认值为1 表示10%\r# 设置的越小，一次淘汰周期需要消耗的CPU更多 需要删除更多的过期数据\ractive-expire-effort 1\r# 持久化\r# AOF持久化开启\rappendonly yes\r# AOF 持久化模式，默认为 \u0026#34;always\u0026#34;。可以是 always、everysec 或 no\r# always：每个写操作都立即同步到磁盘，最费性能\r# everysec：每秒钟同步一次到磁盘，折中的选择\r# no：完全依赖操作系统的行为，可能会丢失数据，但性能最高\rappendfsync everysec\r# AOF-RDB混合持久化\r# 配置成yes必须先开启AOF AOF重写生成的文件将同时包含RDB和AOF格式内容\r# 推荐开启\raof-use-rdb-preamble yes\r# 性能监控\r# 慢查询日志 执行时间只是命令阶段的时间，不包括建立连接发送回复等\r# slow log 仅保存在内存中，效率很高\r# 执行时间大于多少微秒的查询进行记录 1s = 1,000,000微秒 默认10000\rslowlog-log-slower-than 10000\r# 最多保存多少条慢查询日志 slowlog本身是FIFO 默认128\rslowlog-max-len 128 sentinel.conf\r#\rsudo vim /DATA/redis/config/sentinel/sentinel.conf\r# 哨兵端口\rport 26379\r# 监控的redis主节点的ip port\r# master-name 自定义\r# quorum 多少个sentinel主观认为master失联，认为客观上master失联\r# sentinel monitor \u0026lt;master-name\u0026gt; \u0026lt;ip\u0026gt; \u0026lt;redis-port\u0026gt; \u0026lt;quorum\u0026gt;\rsentinel monitor mymaster 192.168.1.11 63790 2\r# redis实例的密码 主从的访问密码必须要一样\rsentinel auth-pass mymaster password\r# 指定多少毫秒之后主节点没有应答哨兵\r# 此时哨兵主观上认为主节点下线\r# 默认30秒\r# sentinel down-after-milliseconds \u0026lt;master-name\u0026gt; \u0026lt;milliseconds\u0026gt;\rsentinel down-after-milliseconds mymaster 30000\r# 设置故障转移时，从节点同步新主节点数据的并发数量\r# 值越小，对主节点的压力越小，但同步速度可能较慢\r# sentinel parallel-syncs \u0026lt;master-name\u0026gt; \u0026lt;numslaves\u0026gt;\rsentinel parallel-syncs mymaster 1\r# 设置故障转移的超时时间（单位：毫秒）\r# 如果故障转移在这个时间内没有完成，则认为失败\rsentinel failover-timeout mymaster 180000\r# 配置哨兵自身的ip 避免走自动检测给出其他哨兵访问不到的地址\rsentinel announce-ip 192.168.1.11\rsentinel announce-port 36379 docker-compose.yml\r#\rsudo vim /DATA/docker-compose.yml\rversion: \u0026#39;3\u0026#39; # 使用docker-compose版本3\rservices: # 定义服务\rredis7:\rimage: redis:7.0.4\rcontainer_name: redis7\ruser: \u0026#34;996:986\u0026#34;\rrestart: always\rports:\r- 63790:63790\renvironment:\rTZ: \u0026#34;Asia/Shanghai\u0026#34;\rvolumes:\r- /DATA/redis/config/redis.conf:/etc/redis/redis.conf\r- /DATA/redis/data:/data\rcommand: [\u0026#34;redis-server\u0026#34;, \u0026#34;/etc/redis/redis.conf\u0026#34;]\rsentinel:\rimage: redis:7.0.4\rcontainer_name: sentinel\rrestart: always\rports:\r- 36379:26379\rvolumes:\r- /DATA/redis/config/sentinel:/etc/redis/config/sentinel\renvironment:\rTZ: \u0026#34;Asia/Shanghai\u0026#34;\rcommand: [\u0026#34;redis-sentinel\u0026#34;, \u0026#34;/etc/redis/config/sentinel/sentinel.conf\u0026#34;] docker-compose.yml语法验证\r#\rdocker-compose config 子节点配置\r#\rredis.conf\r#\rsudo vim /DATA/redis/config/redis.conf\r# 监听端口 sentinel不知道外面映射啥端口，只好把内外端口设置一样\rport 63790\r# 访问密码\rrequirepass password\r# 数据库数量 使用cluster模式时只会有一个database即DB0\rdatabases 16\r# 绑定本机的网络接口（网卡） 绑定的是网卡的IP地址\r# 0.0.0.0 监听所有 默认127.0.0.1\rbind 0.0.0.0\r# 默认开启\r# 如果没有设置密码和且没有设置bind，只允许本机访问\rprotected-mode yes\r# 单位秒，timeout时间内客户端没有数据交互，关闭连接\rtimeout 60\r# 客户端同时连接的最大数量 默认10000\r# 达到最大值时关闭新连接并返回max number of clients reached\rmaxclients 1000\r# 内存管理 # 最大内存，推荐最大设置为6GB\r# 不要设置过大内存，防止执行RDB内存快照文件或者AOF重写时因为数据太大阻塞太长时间\rmaxmemory 2GB\r# 内存淘汰策略 默认noeviction\r# noeviction -\u0026gt; 不删除任何 key，内存满了直接返回报错\r# 默认情况下slave节点会忽略maxmemory配置，除非被提升为master\r# 只有master会执行内存淘汰策略，master删除key后会发送DEL指令给slave\rmaxmemory-policy noeviction\r# 过期key滞留在内存的比例 默认值为1 表示10%\r# 设置的越小，一次淘汰周期需要消耗的CPU更多 需要删除更多的过期数据\ractive-expire-effort 1\r# 持久化\r# AOF持久化开启\rappendonly yes\r# AOF 持久化模式，默认为 \u0026#34;always\u0026#34;。可以是 always、everysec 或 no\r# always：每个写操作都立即同步到磁盘，最费性能\r# everysec：每秒钟同步一次到磁盘，折中的选择\r# no：完全依赖操作系统的行为，可能会丢失数据，但性能最高\rappendfsync everysec\r# AOF-RDB混合持久化\r# 配置成yes必须先开启AOF AOF重写生成的文件将同时包含RDB和AOF格式内容\r# 推荐开启\raof-use-rdb-preamble yes\r# 性能监控\r# 慢查询日志 执行时间只是命令阶段的时间，不包括建立连接发送回复等\r# slow log 仅保存在内存中，效率很高\r# 执行时间大于多少微秒的查询进行记录 1s = 1,000,000微秒 默认10000\rslowlog-log-slower-than 10000\r# 最多保存多少条慢查询日志 slowlog本身是FIFO 默认128\rslowlog-max-len 128\r# 主从复制\r# replicaof \u0026lt;masterip\u0026gt; \u0026lt;masterport\u0026gt;将当前实例成为master的从节点\rreplicaof 192.168.1.11 63790\r# master节点的requiepass\rmasterauth **********\r# 从节点只读，默认为yes，建议保留默认配置\rreplica-read-only yes\r# slave每10s Ping一次master\rrepl-ping-replica-period 10\r# slave与master之间的复制超时时间，默认60s\rrepl-timeout 60\r# slave优先级 哨兵使用 默认100\r# master节点挂掉，哨兵选择priority最小的slave节点作为新的master\rreplica-priority 100 sentinel.conf\r#\rsudo scp -P 2222 quanta@192.168.1.11:/DATA/redis/config/sentinel.conf /DATA/redis/config/sentinel.conf 修改配置sentinel ip\nsudo vim /DATA/redis/config/sentinel/sentinel.conf\r# 配置哨兵自身的ip 避免走自动检测给出其他哨兵访问不到的地址\rsentinel announce-ip 192.168.1.1x\rsentinel announce-port 36379 docker-compose.yml\r#\rsudo vim /DATA/docker-compose.yml\rversion: \u0026#39;3\u0026#39; # 使用docker-compose版本3\rservices: # 定义服务\rredis7:\rimage: redis:7.0.4\rcontainer_name: redis7\rrestart: always\rports:\r- 63811:6379\r# 指定时区，保证容器内时间正确\renvironment:\rTZ: \u0026#34;Asia/Shanghai\u0026#34;\rvolumes:\r# 映射配置文件和数据目录\r- /DATA/redis/redis-master.conf:/usr/local/etc/redis/redis.conf\r- ./data/redis-master:/data\r#sysctls:\r# net.core.somaxconn: \u0026#39;511\u0026#39;\rcommand: [\u0026#34;redis-server\u0026#34;, \u0026#34;/usr/local/etc/redis/redis.conf\u0026#34;]\rsentinel:\rimage: redis:7.0.4\rcontainer_name: redis-sentinel-1\rrestart: always\rports:\r- 26379:26379\rvolumes:\r- ./s1/:/usr/local/etc/redis/conf/\r# 指定时区，保证容器内时间正确\renvironment:\rTZ: \u0026#34;Asia/Shanghai\u0026#34;\r# sysctls:\r# net.core.somaxconn: \u0026#39;511\u0026#39;\rcommand: [\u0026#34;redis-sentinel\u0026#34;, \u0026#34;/usr/local/etc/redis/conf/redis-sentinel-1.conf\u0026#34;] docker-compose.yml语法验证\r#\rdocker-compose config 各节点启动\r#\rcd /DATA\rsudo docker-compose up -d redis7\rsudo docker-compose up -d sentinel\r# 停止容器\rsudo docker-compose stop redis7\rsudo docker-compose stop sentinel\r# 删除容器以清空容器的控制台日志\rsudo docker rm redis7\rsudo docker rm sentinel 打开防火墙端口\r#\r# 开放Redis端口给哨兵访问\rsudo ufw allow 63790/tcp\rsudo ufw deny 6379/tcp\r# 开放哨兵端口\rsudo ufw allow 36379/tcp\rsudo ufw deny 26379/tcp 验证哨兵\r#\r# 登录sentinel docker\rsudo docker exec -it sentinel /bin/bash\r# 登录sentinel\rredis-cli -p 26379\r# 查看信息\r# Sentinel部分 master行 显示了masterip:port slave数量 sentinel数量\rinfo\r# 看看哨兵认为目前有哪些主节点、从节点、哨兵节点\rSENTINEL MASTER mymaster\rSENTINEL SLAVES mymaster\rSENTINEL SENTINELS mymaster\r# 强制刷新主从信息\rSENTINEL RESET mymaster\r# sentinel会把一些信息在sentinel.conf里面记录下来\r# 包括选举次数 每次选举结果节点信息等\r# Sentinel重启时会根据sentinel.conf的记录\r# 将上次选举的结果作为主节点\r# 想要日志里面把选举次数、当前主节点清空，就要清理sentinel.conf 日志说明\r#\r1:X 17 Feb 2025 20:44:53.226 * Running mode=sentinel, port=26379.\r1:X 17 Feb 2025 20:44:53.228 * Sentinel new configuration saved on disk\r1:X 17 Feb 2025 20:44:53.228 # Sentinel ID is 6b8d5f11db078b21d5251456f5f7d5b4c117c3c9\r# 主节点监控\r1:X 17 Feb 2025 20:44:53.228 # +monitor master mymaster 192.168.1.11 63790 quorum 2\r# 从节点监控\r1:X 17 Feb 2025 20:45:03.273 * +slave slave 192.168.1.12:63790 192.168.1.12 63790 @ mymaster 192.168.1.11 63790\r1:X 17 Feb 2025 20:45:03.277 * Sentinel new configuration saved on disk\r# sentinel节点互相发现\r1:X 17 Feb 2025 20:45:03.617 * +sentinel sentinel cb3cce637d7611c93785059ebd3dd6c4a5a5d6ad 192.168.1.12 36379 @ mymaster 192.168.1.11 63790\r1:X 17 Feb 2025 20:45:03.620 * Sentinel new configuration saved on disk\r# sentinel节点互相发现\r1:X 17 Feb 2025 20:45:12.053 * +sentinel sentinel b4979ced54d276d73a9a16fb9ad1935e0e8a5e20 192.168.1.13 36379 @ mymaster 192.168.1.11 63790\r1:X 17 Feb 2025 20:45:12.056 * Sentinel new configuration saved on disk\r# 从节点监控\r1:X 17 Feb 2025 20:45:13.285 * +slave slave 192.168.1.13:63790 192.168.1.13 63790 @ mymaster 192.168.1.11 63790 验证主从\r#\r# 主从节点登录redis\rsudo docker exec -it redis7 /bin/bash\rredis-cli -p 63790 -a **********\rinfo replication 故障转移测试\r#\r停机操作\r#\r# 停止主节点\rsudo docker-compose stop redis7\r# 查看sentinel日志\rsudo docker logs --tail 100 -f sentinel 日志说明\r#\r1:X 17 Feb 2025 20:45:13.290 * Sentinel new configuration saved on disk\r# 主观下线\r1:X 17 Feb 2025 21:06:53.259 # +sdown master mymaster 192.168.1.11 63790\r# 两个节点投票 客观下线\r1:X 17 Feb 2025 21:06:53.315 # +odown master mymaster 192.168.1.11 63790 #quorum 2/2\r# 第一次选举\r1:X 17 Feb 2025 21:06:53.315 # +new-epoch 1\r# 尝试对主节点故障转移\r1:X 17 Feb 2025 21:06:53.315 # +try-failover master mymaster 192.168.1.11 63790\r1:X 17 Feb 2025 21:06:53.318 * Sentinel new configuration saved on disk\r# 本哨兵投票\r1:X 17 Feb 2025 21:06:53.318 # +vote-for-leader 6b8d5f11db078b21d5251456f5f7d5b4c117c3c9 1\r# 其他哨兵投票\r1:X 17 Feb 2025 21:06:53.324 # b4979ced54d276d73a9a16fb9ad1935e0e8a5e20 voted for 6b8d5f11db078b21d5251456f5f7d5b4c117c3c9 1\r# 其他哨兵投票\r1:X 17 Feb 2025 21:06:53.325 # cb3cce637d7611c93785059ebd3dd6c4a5a5d6ad voted for 6b8d5f11db078b21d5251456f5f7d5b4c117c3c9 1\r# 为旧主节点的故障转移 选举领导者\r1:X 17 Feb 2025 21:06:53.385 # +elected-leader master mymaster 192.168.1.11 63790\r# 为旧主节点的故障转移 选择合适的从节点\r1:X 17 Feb 2025 21:06:53.385 # +failover-state-select-slave master mymaster 192.168.1.11 63790\r# 为旧主节点的故障转移 选择了合适的从节点13 从节点13属于旧主节点11\r1:X 17 Feb 2025 21:06:53.452 # +selected-slave slave 192.168.1.13:63790 192.168.1.13 63790 @ mymaster 192.168.1.11 63790\r# 向选中的节点发送slaveof no one命令，让它不再作为其他节点的从节点，为提升为主节点做准备\r1:X 17 Feb 2025 21:06:53.452 * +failover-state-send-slaveof-noone slave 192.168.1.13:63790 192.168.1.13 63790 @ mymaster 192.168.1.11 63790\r# 等待13节点完成提升为主节点的操作\r1:X 17 Feb 2025 21:06:53.508 * +failover-state-wait-promotion slave 192.168.1.13:63790 192.168.1.13 63790 @ mymaster 192.168.1.11 63790\r1:X 17 Feb 2025 21:06:54.305 * Sentinel new configuration saved on disk\r# 13成功提升为主节点 之前是11的从节点\r1:X 17 Feb 2025 21:06:54.305 # +promoted-slave slave 192.168.1.13:63790 192.168.1.13 63790 @ mymaster 192.168.1.11 63790\r# 进入故障转移的重新配置从节点阶段 原主节点是11\r1:X 17 Feb 2025 21:06:54.305 # +failover-state-reconf-slaves master mymaster 192.168.1.11 63790\r# 向原先11的从节点12 发送了重新配置的命令\r1:X 17 Feb 2025 21:06:54.369 * +slave-reconf-sent slave 192.168.1.12:63790 192.168.1.12 63790 @ mymaster 192.168.1.11 63790\r# 从节点12正在更新自己的配置指向新的主节点\r1:X 17 Feb 2025 21:06:54.517 * +slave-reconf-inprog slave 192.168.1.12:63790 192.168.1.12 63790 @ mymaster 192.168.1.11 63790\r# 从节点12完成了重新配置操作 指向了新的主节点\r1:X 17 Feb 2025 21:06:54.517 * +slave-reconf-done slave 192.168.1.12:63790 192.168.1.12 63790 @ mymaster 192.168.1.11 63790\r# 旧节点11的故障转移操作结束\r1:X 17 Feb 2025 21:06:54.583 # +failover-end master mymaster 192.168.1.11 63790\r# 记录主节点切换完毕 原主节点11切换为新主节点13\r1:X 17 Feb 2025 21:06:54.583 # +switch-master mymaster 192.168.1.11 63790 192.168.1.13 63790\r# 记录12为从节点\r1:X 17 Feb 2025 21:06:54.372 * +slave slave 192.168.1.12:63790 192.168.1.12 63790 @ mymaster 192.168.1.13 63790\r# 记录11变为从节点 虽然下线了\r1:X 17 Feb 2025 21:06:54.372 * +slave slave 192.168.1.11:63790 192.168.1.11 63790 @ mymaster 192.168.1.13 63790\r1:X 17 Feb 2025 21:06:54.378 * Sentinel new configuration saved on disk\r# 记录11节点主观下线 +是增加主观下线标记\r1:X 17 Feb 2025 21:07:24.410 # +sdown slave 192.168.1.11:63790 192.168.1.11 63790 @ mymaster 192.168.1.13 63790 故障恢复\r#\r# 重启旧主节点\rsudo docker-compose start redis7\r# 查看sentinel日志\rsudo docker logs --tail 100 -f sentinel 日志说明\r#\r# 移除11 的主观下线标记\r1:X 17 Feb 2025 21:45:58.909 # -sdown slave 192.168.1.11:63790 192.168.1.11 63790 @ mymaster 192.168.1.13 63790\r# 转换11为新主节点13的从节点\r1:X 17 Feb 2025 21:46:08.884 * +convert-to-slave slave 192.168.1.11:63790 192.168.1.11 63790 @ mymaster 192.168.1.13 63790 服务发现和故障转移过程（哨兵选举）\r#\r服务发现\nsentinel根据配置指定的master监控master并通信 master知道slave的信息 sentinel根据redis的sub/pub机制获取其他sentinel信息 故障转移\n主节点下线后，一段时间sentinel ping主节点不通，记录主节点主观下线，并通知其他sentinel 认为主节点主观下线的sentinel个数超过quorm个数，也就是半数以上，标记主节点客观下线，开启故障转移流程 各sentinel开始投票选择节点作为主节点，并选择一个sentinel协调故障转移流程 获得选票过半的节点被选中准备提升为主节点 sentinel向被选中节点发送提升主节点命令，并等待其完成转换 被选中节点提升为新主节点后，sentinel向其他节点发送转换新主节点的信息 其他节点完成转换后，集群主节点状态转换完毕 旧主节点被记录为新主节点的从节点 旧主节点上线后，sentinel告知他将自己转换为新主节点的从节点 "},{"id":14,"href":"/codestack/docs/javaee/redis/","title":"Redis","section":"JavaEE","content":"\rRedis\r#\r"},{"id":15,"href":"/codestack/docs/javaee/spring/transaction/","title":"Spring事务","section":"Spring","content":"\rSpring事务\r#\r事务实现\r#\r基于数据库事务和AOP\n对于使用了@Transactional注解的Bean，创建代理对象 当调用代理对象的方法时，如果方法上有@Transactional注解，利用事务管理器创建一个数据库连接 修改数据库连接的autocommit属性为false，禁止此连接自动提交 执行当前方法，方法中会包含sql，没有异常就直接提交事务 出现异常且需要回滚则回滚事务，不需要回滚就仍然提交事务 Spring的事务隔离级别就是数据库的隔离级别 Spring事务的传播机制时Spring事务自己实现的，有很多种。用于设置不同场景下，对嵌套方法是否该用同一个事务执行的情况进行支持 传播机制是通过数据库连接来实现的，每个数据库连接一个事务，当传播机制配置为应该需要新开一个事务，实际上就是为方法新建一个数据库连接，在新连接上执行SQL。 默认事务传播机制是：REQUIRED，如果存在事务则加入，不存在则创建\n事务传播机制\r#\r事务传播机制指的是当事务方法被调用时，事务如何传播\n传播机制的指定：\n@Transactional(propagation = Propagation.REQUIRED)\rpublic void calledMethod() {\r} PROPAGATION_REQUIRED（默认）\r#\r如果调用方法不存在事务，则创建一个事务\n从数据源获取一个新的数据库连接并开启新事务 如果调用方法有事务，则加入该事务\n也就是不做处理，复用当前的数据库连接和事务 效果：存在且仅存在一个事务，回滚到最开始事务创建时\n调用方有事务，和调用方一起作为原子操作 调用方没有事务，自己是原子操作 PROPAGATION_SUPPORTS\r#\r如果调用方法不存在事务，以非事务方式运行\n获取数据源连接执行SQL，但不开启事务 如果调用方法有事务，则加入该事务\n复用当前的数据库连接和事务 效果：遵从被调用方的决定，有就用，没有也不开\n调用方有事务，和调用方一起作为原子操作 调用方没有事务，都不是原子操作 PROPAGATION_MANDATORY\r#\r如果调用方法不存在事务，抛出异常\n发现当前没有事务，抛出 IllegalTransactionStateException 异常 即要求必须在事务环境下执行 如果调用方法有事务，则加入该事务\n复用当前的数据库连接和事务 效果：必须有事务才能调用该方法\n调用方有事务，和调用方一起作为原子操作 调用方没有事务，报错 PROPAGATION_REQUIRES_NEW\r#\r如果调用方法不存在事务，则创建一个新事务 从数据源获取一个新的数据库连接并开启新事务 如果调用方法有事务，挂起当前事务，并创建新事务执行\n挂起调用者事务，获取新的链接并开启新事务，执行完毕后，回复调用者的事务 效果：不管调用方有无事务，自己都是单独事务执行 调用方和自己是两个原子，报错不影响调用方，也不被调用方影响\n事务挂起的实现方式：\r#\rSpring 调用方法时，创建新数据库链接并开启事务，用新事务执行SQL并提交或回滚，运行完毕后，再继续用原本事务\nPROPAGATION_NOT_SUPPORTED\r#\r如果调用方法不存在事务，以非事务方式运行\n不从数据库连接开启事务 如果调用方法有事务，挂起当前事务，以非事务方式运行\n挂起调用者事务，以非事务方式运行，执行完毕后，回复调用者的事务 效果：必须以无事务方式运行本方法\n调用方有事务，挂起调用方事务，用新连接不开启事务的方式执行SQL，报错不导致调用方回滚 调用方没有事务，用新连接不开启事务的方式执行SQL PROPAGATION_NEVER\r#\r如果调用方法不存在事务，以非事务方式运行\n不从数据库连接开启事务 如果调用方法有事务，抛出异常\n抛出 IllegalTransactionStateException 异常，即要求不在事务环境中执行 效果：调用方法时不可以有事务，否则报错\n调用方有事务，报错，触发回滚当前事务 调用方没有事务，用新连接不开启事务的方式执行SQL PROPAGATION_NESTED\r#\r如果调用方法不存在事务，则创建一个新事务 从数据源获取一个新的数据库连接并开启新事务 如果调用方法有事务，在调用者事务创建嵌套事务执行任务\n在调用者的事务中创建一个嵌套事务，使用同一个数据库连接，但有独立保存点，被调用方法发生异常，只回滚到保存点，不影响调用者事务 效果：调用方法时不可以有事务，否则报错\n调用方有事务，创建嵌套事务执行，本方法回滚不影响调用方，调用方回滚导致本方法回滚 调用方没有事务，用新连接开启事务执行SQL 嵌套事务的实现方式：\r#\rMySQL事务开启后还可以用 SAVEPOINT nested_savepoint; 语句建立保存点，通过 ROLLBACK TO SAVEPOINT nested_savepoint; 方式回滚到保存点，从而实现事务内的内嵌原子操作 保存点功能从MySQL5.0后 InnoDB 存储引擎开始支持 事务相关\r#\r@Transactional 失效情况\r#\r由于Spring事务基于AOP代理实现，如果方法被本类地其他方法调用，则没有经过代理对象，于是事务失效 如果@Transactional注解的方法不是public，则失效，因为不会对非public创建代理类 默认情况下，Spring事务会对Error和RuntimeException进行事务回滚，对其他继承自Exception.class的异常不会回滚(如IOException等)。解决方案是写死rollbackfor = Exception.class 异常被catch掉，抛不到切面回滚逻辑中，事务不会回滚 数据库引擎不支持事务，如MySQL MyISAM没有事务，仅Innodb有 事务传播属性propagation 设置错误 TransactionDefinition.PROPAGATION_NOT_SUPPORTED：以非事务方式运行，如果当前存在事务，则把当前事务挂起，以非事务方式运行，自然不会报错回滚 TransactionDefinition.PROPAGATION_NEVER：以非事务方式运行，如果当前存在事务，则抛出异常，回滚当前事务 "},{"id":16,"href":"/codestack/docs/project/server-runtime-excption/","title":"雪崩|限流|熔断|降级","section":"项目设计","content":"\r雪崩|限流|熔断|降级\r#\r服务雪崩：\r#\rA 调用 B，B 调用 C\n如果大量请求突然到 A，如果 A 撑住了，则 A 会将压力传导到 C 如果 C 撑不住，则 C 会请求堆积，从而 B 请求堆积，从而 A 不可用 解决方式是服务降级和服务熔断\n服务限流：\r#\r高并发下，为了保护系统，可以对访问服务的请求进行数量上的限制，防止系统不被大量请求压垮\n服务熔断：\r#\r服务 A 调用的某个服务 B 不可用时，A 为了保证自己不受影响，不再调用服务 B，直接返回一个结果，减轻两个服务的压力，直到 B 恢复\n服务降级：\r#\r发现系统压力过载时，通过关闭某个服务或限流减轻系统压力\n理解\r#\r都是为了防止系统崩溃，都会让用户体验到某些功能暂不可用\n熔断是下游服务故障触发 降级是为了主动降低系统负载 "},{"id":17,"href":"/codestack/docs/javaee/spring/bean-liftcycle-and-extension/","title":"Bean 生命周期与 SpringBoot 扩展点","section":"Spring","content":"\rBean 生命周期与 SpringBoot 扩展点\r#\r生命周期：\n从对象的创建到销毁的过程\n从 SpringBootApplication.run 方法出发，执行到 AbstractApplication.refresh 方法\n从此处开始进行 BeanFactory 等资源的准备、XML/注解的扫描\nSpring 创建 BeanFactory ，工厂扫描 XML、Java 注解等，生成 BeanDefinition 对象 调用工厂方法根据 BeanDefinition 对象通过反射生成 Bean 实例，完成实例化 Spring 将值和 Bean 引用注入到 Bean 对应属性 如果 Bean 实现了 BeanNameAware 接口，Spring 将 Bean 的 ID 传递给 setBeanName 方法 如果 Bean 实现了 BeanFactoryAware 接口，Spring 调用 setBeanFactory 将 BeanFactory 实例传入 如果 Bean 实现了 ApplicationContextAware 接口，Spring 调用 setApplicationAware 将应用上下文传入 如果 Bean 实现了 BeanPostProcessor 接口，Spring 调用 postProcessBeforeInitialization 方法 如果 Bean 中有 @PostConstruct 方法，执行该方法 如果 Bean 实现了 InitilizingBean 接口，Spring 调用 afterPropertiesSet 方法；如果 @Bean 声明了 initMethod，Spring 再调用该方法 如果 Bean 实现了 BeanPostProcessor 接口，Spring 调用 postProcessorAfterInitialization 方法 此时 Bean 的属性已经设置和前后置操作完毕，完成了初始化。Bean 将一直存在于应用上下文中，直到应用上下文被销毁 如果 Bean 中有 @PreDestory 方法，执行该方法 如果 Bean 实现了 DisposableBean 接口，Spring 将调用 destory 方法。如果 @Bean 声明了 destoryMethod，Spring 再调用该方法。 "},{"id":18,"href":"/codestack/docs/deploy/elasticsearch/","title":"ElasticSearch","section":"部署","content":"\rElasticSearch\r#\r安装版本：8.15.0\n部署方式：三节点\n运行方式：docker-compose\nLinux系统设置\r#\r# 修改内核参数\r# 设置每个进程最多拥有的最大内存映射区域数量 默认65536对ES来说不足\recho \u0026#34;vm.max_map_count=262144\u0026#34; | sudo tee -a /etc/sysctl.conf\rsudo sysctl -p 创建目录\r#\rsudo mkdir /DATA/es /DATA/es/data /DATA/es/logs /DATA/es/plugins /DATA/es/config 权限设置\r#\rsudo chmod -R 777 /DATA/es/data /DATA/es/logs /DATA/es/plugins /DATA/es/config 各单节点启动获取官方配置\r#\rsudo vim /DATA/docker-compose.yml\rversion: \u0026#39;3\u0026#39;\rservices:\res:\rimage: docker.elastic.co/elasticsearch/elasticsearch:8.15.0\rcontainer_name: es\rrestart: always\renvironment:\r- \u0026#34;ES_JAVA_OPTS=-Xms4g -Xmx4g\u0026#34; # 宿主机最大内存的一半 再留点给其他应用\r- \u0026#34;ELASTIC_PASSWORD=********\u0026#34;\r- \u0026#34;TZ=Asia/Shanghai\u0026#34;\rports:\r- \u0026#34;19200:19200\u0026#34;\r- \u0026#34;19300:19300\u0026#34;\rvolumes:\r- /DATA/es/data:/usr/share/elasticsearch/data\r- /DATA/es/logs:/usr/share/elasticsearch/logs\r- /etc/hosts:/etc/hosts\r- es_config:/usr/share/elasticsearch/config\r- /DATA/es/plugins:/usr/share/elasticsearch/plugins\rulimits:\r# mmap 映射内存不限制\rmemlock:\rsoft: -1 hard: -1\r# 文件描述符打开个数修改 nofile: soft: 65535 hard: 65535\r# 末尾添加 作用是不要让宿主机空目录覆盖\rvolumes:\res_config:\rdriver: local\rdriver_opts:\rtype: none\rdevice: /DATA/es/config\ro: bind #mmap 映射内存不限制\nES底层lucene底层使用mmap映射磁盘文件\nmemlock本意是限制内存映射的大小，默认为64KB，不够，修改为不用限制大小\n#文件描述符打开个数修改\nElasticsearch 需要打开大量的文件来处理索引数据、日志文件以及网络连接\n如果文件描述符的数量不足，导致“Too many open files” 和频繁的文件关闭和重新打开操作，从而降低性能\nElasticsearch 官方推荐将 nofile 的 soft 和 hard 值设置为 65535 或更高\nsoft （软限制）：是当前生效的限制值，用户可以动态调整，但不能超过 hard 限制。\nhard （硬限制）：是系统允许的最大值，用户无法超过这个限制\n# 启动 三个节点的es\rsudo docker-compose up -d es\r# 验证节点状态\rcurl --cacert /DATA/es/config/certs/http_ca.crt -u elastic:****** https://localhost:19200/_cluster/health?pretty 生成和复制节点间传输层证书\r#\r# 进入一个节点的 docker\rsudo docker exec -it es /bin/bash\r./bin/elasticsearch-certutil ca\r# Please enter the desired output file [elastic-stack-ca.p12]:\r# 直接空格默认文件名和路径\r# Enter password for elastic-stack-ca.p12 :\r# 设置密码 2333\r# 用刚生成的CA证书生成节点证书\r# elastic-stack-ca.p12在/usr/share/elasticsearch 目录下 # 在这个目录执行，elastic-certificates.p12也生成在这个目录下\r./bin/elasticsearch-certutil cert --ca elastic-stack-ca.p12\r# Enter password for CA (elastic-stack-ca.p12) : # 输入CA证书的密码 密码 2333\r# Enter password for elastic-certificates.p12 :\r# 输入节点证书的密码，设置密码 2333\r# 生成的证书都移动到config/certs目录下\rmv elastic-certificates.p12 config/certs/\rmv elastic-stack-ca.p12 config/certs/\rexit\r# 各个节点都需要这两个文件 复制到各节点\rscp -P 2222 quanta@192.168.1.11:/DATA/es/config/certs/elastic-certificates.p12 /DATA/es/config/certs\rscp -P 2222 quanta@192.168.1.11:/DATA/es/config/certs/elastic-stack-ca.p12 /DATA/es/config/certs\r# 密码加入各节点的信任库 覆盖原本的设置y\r# 提示输入节点证书密码 2333\rsudo docker exec -it es /bin/bash\r./bin/elasticsearch-keystore add xpack.security.transport.ssl.keystore.secure_password\r./bin/elasticsearch-keystore add xpack.security.transport.ssl.truststore.secure_password\rexit\r# https证书保持各节点自己的 各类客户端访问不使用https\r# 检查https是否可以访问 curl访问-k跳过证书验证 浏览器https高级继续 （不认自签名证书）\rcurl -k --cacert /DATA/es/config/certs/http_ca.crt -u elastic:********** https://localhost:19200/_cluster/health?pretty 修改各节点 elasticsearch.yml 文件\r#\rsudo vim /DATA/es/config/elasticsearch.yml\r# 集群名称 每个节点相同 根据他生成 cluster_uuid\r# cluster_uuid 相同的加入同一个集群，修改后只能删除data目录重来\rcluster.name: \u0026#34;es-cluster\u0026#34;\r# 节点名称 每个节点不同\rnode.name: \u0026#34;es-node1\u0026#34;\r# 节点主机名 在/etc/hosts换节点ip用\rnetwork.publish_host: dataserver1\rnetwork.host: 0.0.0.0\rtransport.port: 19300\rhttp.port: 19200\r#----------------------- BEGIN SECURITY AUTO CONFIGURATION -----------------------\r#\r# The following settings, TLS certificates, and keys have been automatically # generated to configure Elasticsearch security features on 28-02-2025 09:24:45\r#\r# --------------------------------------------------------------------------------\r# Enable security features\rxpack.security.enabled: true\rxpack.security.enrollment.enabled: true\r# Enable encryption for HTTP API client connections, such as Kibana, Logstash, and Agents\r# 关闭https访问\rxpack.security.http.ssl:\renabled: false\rkeystore.path: certs/http.p12\r# Enable encryption and mutual authentication between cluster nodes\rxpack.security.transport.ssl:\renabled: true\rverification_mode: certificate\rkeystore.path: certs/elastic-certificates.p12\rtruststore.path: certs/elastic-certificates.p12\r# Create a new cluster with the current node only\r# Additional nodes can still join the cluster later\rcluster.initial_master_nodes: [\u0026#34;es-node1\u0026#34;, \u0026#34;es-node2\u0026#34;, \u0026#34;es-node3\u0026#34;]\rdiscovery.seed_hosts: [\u0026#34;dataserver1\u0026#34;, \u0026#34;dataserver2\u0026#34;, \u0026#34;dataserver3\u0026#34;]\r#----------------------- END SECURITY AUTO CONFIGURATION -------------------------\r# 节点间复制并修改节点名和publish_host\rscp -P 2222 user@ip:/DATA/es/config/elasticsearch.yml /DATA/es/config/elasticsearch.yml\rsudo vim /DATA/es/config/elasticsearch.yml\r# 修改各节点防火墙\rsudo ufw allow 19200/tcp sudo ufw allow 19300/tcp\rsudo ufw delete allow 9200/tcp sudo ufw delete allow 9300/tcp\r# 重启各节点\rsudo docker-compose down es\r# 删除 data目录下的内容 因为修改了cluster_name\rsudo rm -rf /DATA/es/data/*\rsudo docker-compose up -d es 启动并验证\r#\rsudo docker-compose up -d es\r# 验证节点状态\rcurl -u elastic:******** http://localhost:19200/_cluster/health?pretty\r{\r\u0026#34;cluster_name\u0026#34; : \u0026#34;docker-cluster\u0026#34;,\r# green ：所有主分片和副本分片都已分配，集群状态良好。\r# yellow ：所有主分片已分配，但部分副本分片未分配。\r# red ：部分主分片未分配，集群状态不佳\r\u0026#34;status\u0026#34; : \u0026#34;green\u0026#34;,\r# 本次查询是否超时\r\u0026#34;timed_out\u0026#34; : false,\r# 集群节点数量\r\u0026#34;number_of_nodes\u0026#34; : 3,\r# 集群数据节点数量\r\u0026#34;number_of_data_nodes\u0026#34; : 3,\r\u0026#34;active_primary_shards\u0026#34; : 0,\r\u0026#34;active_shards\u0026#34; : 0,\r\u0026#34;relocating_shards\u0026#34; : 0,\r\u0026#34;initializing_shards\u0026#34; : 0,\r\u0026#34;unassigned_shards\u0026#34; : 0,\r\u0026#34;delayed_unassigned_shards\u0026#34; : 0,\r\u0026#34;number_of_pending_tasks\u0026#34; : 0,\r\u0026#34;number_of_in_flight_fetch\u0026#34; : 0,\r\u0026#34;task_max_waiting_in_queue_millis\u0026#34; : 0,\r\u0026#34;active_shards_percent_as_number\u0026#34; : 100.0\r}\rcurl -u elastic:********** http://localhost:19200/_cat/nodes?pretty\r192.168.1.13 13 71 2 0.07 0.31 0.22 cdfhilmrstw - es-node3\r192.168.1.12 14 71 2 0.24 0.38 0.26 cdfhilmrstw - es-node2\r192.168.1.11 18 53 2 0.07 0.30 0.22 cdfhilmrstw * es-node1 设置内置用户和密码\r#\rsudo docker exec -it es /bin/bash\r./bin/elasticsearch-reset-password -i -u kibana_system\r# 多节点验证是否可以登录\rcurl -u kibana_system:********** http://localhost:19200/_cat/nodes?pretty 用户和密码单独索引在security 数据目录挂载出来的情况下可以在docker重启后沿用\n安装kibana(单节点)\r#\r目录和权限\r#\rsudo mkdir -p /DATA/kibana/config /DATA/kibana/data\rsudo chmod -R 777 /DATA/kibana/config /DATA/kibana/data 启动kibana\r#\rsudo vim /DATA/docker-compose.yml\rversion: \u0026#39;3\u0026#39;\rservices:\rkibana:\rimage: kibana:8.15.0\rcontainer_name: kibana\rrestart: always\renvironment:\r- \u0026#34;TZ=Asia/Shanghai\u0026#34;\rports:\r- \u0026#34;15601:15601\u0026#34;\rvolumes:\r- kibana_config:/usr/share/kibana/config\r- /DATA/kibana/data:/usr/share/kibana/data\r- /etc/hosts:/etc/hosts\rvolumes:\rkibana_config:\rdriver: local\rdriver_opts:\rtype: none\rdevice: /DATA/kibana/config\ro: bind\rsudo docker-compose up -d kibana 修改 kibana.yml 配置文件\r#\rsudo vim /DATA/kibana/config/kibana.yml\rserver.host: \u0026#34;0.0.0.0\u0026#34;\rserver.port: 15601\rserver.shutdownTimeout: \u0026#34;5s\u0026#34;\relasticsearch.hosts: [ \u0026#34;http://dataserver1:19200\u0026#34; ]\relasticsearch.username: \u0026#34;kibana_system\u0026#34;\relasticsearch.password: \u0026#34;******\u0026#34;\ri18n.locale: \u0026#34;zh-CN\u0026#34;\rmonitoring.ui.container.elasticsearch.enabled: true\rsudo docker-compose restart kibana 打开防火墙并验证访问\r#\rsudo ufw allow 15601/tcp\rhttp://192.168.1.11:15601/\r# 在 dev_tools 中尝试查询\r# es集群健康状态\rGET _cat/health?v\r# es集群节点个数\rGET _cat/nodes?v\r# es 集群索引\rGET _cat/indices?v\r# 查看插件列表\rGET /_cat/plugins?v 安装IK分词器(每个节点都要装)\r#\r# 安装 每个节点都需要装\rsudo docker exec -it es /bin/bash\rbin/elasticsearch-plugin install https://get.infini.cloud/elasticsearch/analysis-ik/8.15.0\rexit\r# 重启es\rsudo docker-compose restart es\r# 移除 ik 分词器\r./bin/elasticsearch-plugin remove analysis-ik\r# kibana 查看插件列表\rGET /_cat/plugins?v\rname component version\res-node2 analysis-ik 8.15.0\res-node1 analysis-ik 8.15.0\res-node3 analysis-ik 8.15.0 测试IK分词器\r#\rik分词器提供了两种分词方式\n# ik_smart 智能分词\r# 会做最粗粒度的拆分, 比如会将\u0026#34;中华国歌\u0026#34;分成如下\u0026#34;中华\u0026#34;, “国歌”\r# 适合 Phrase 查询\rPOST /_analyze\r{\r\u0026#34;analyzer\u0026#34;: \u0026#34;ik_smart\u0026#34;,\r\u0026#34;text\u0026#34;: \u0026#34;我爱北京天安门\u0026#34;\r}\r# result\r# 我 爱 北京 天安门\r{\r\u0026#34;tokens\u0026#34;: [\r{\r\u0026#34;token\u0026#34;: \u0026#34;我\u0026#34;,\r\u0026#34;start_offset\u0026#34;: 0,\r\u0026#34;end_offset\u0026#34;: 1,\r\u0026#34;type\u0026#34;: \u0026#34;CN_CHAR\u0026#34;,\r\u0026#34;position\u0026#34;: 0\r},\r{\r\u0026#34;token\u0026#34;: \u0026#34;爱\u0026#34;,\r\u0026#34;start_offset\u0026#34;: 1,\r\u0026#34;end_offset\u0026#34;: 2,\r\u0026#34;type\u0026#34;: \u0026#34;CN_CHAR\u0026#34;,\r\u0026#34;position\u0026#34;: 1\r},\r{\r\u0026#34;token\u0026#34;: \u0026#34;北京\u0026#34;,\r\u0026#34;start_offset\u0026#34;: 2,\r\u0026#34;end_offset\u0026#34;: 4,\r\u0026#34;type\u0026#34;: \u0026#34;CN_WORD\u0026#34;,\r\u0026#34;position\u0026#34;: 2\r},\r{\r\u0026#34;token\u0026#34;: \u0026#34;天安门\u0026#34;,\r\u0026#34;start_offset\u0026#34;: 4,\r\u0026#34;end_offset\u0026#34;: 7,\r\u0026#34;type\u0026#34;: \u0026#34;CN_WORD\u0026#34;,\r\u0026#34;position\u0026#34;: 3\r}\r]\r}\r# ik_max_word 是最细粒度的分词模式，会尽可能多地输出分词结果 穷举所有可能 中文语法下的\r# 适合 Term Query 查询\rPOST /_analyze\r{\r\u0026#34;analyzer\u0026#34;: \u0026#34;ik_max_word\u0026#34;,\r\u0026#34;text\u0026#34;: \u0026#34;我爱北京天安门\u0026#34;\r}\r# result\r# 我 爱 北京 天安门 天安 门\r{\r\u0026#34;tokens\u0026#34;: [\r{\r\u0026#34;token\u0026#34;: \u0026#34;我\u0026#34;,\r\u0026#34;start_offset\u0026#34;: 0,\r\u0026#34;end_offset\u0026#34;: 1,\r\u0026#34;type\u0026#34;: \u0026#34;CN_CHAR\u0026#34;,\r\u0026#34;position\u0026#34;: 0\r},\r{\r\u0026#34;token\u0026#34;: \u0026#34;爱\u0026#34;,\r\u0026#34;start_offset\u0026#34;: 1,\r\u0026#34;end_offset\u0026#34;: 2,\r\u0026#34;type\u0026#34;: \u0026#34;CN_CHAR\u0026#34;,\r\u0026#34;position\u0026#34;: 1\r},\r{\r\u0026#34;token\u0026#34;: \u0026#34;北京\u0026#34;,\r\u0026#34;start_offset\u0026#34;: 2,\r\u0026#34;end_offset\u0026#34;: 4,\r\u0026#34;type\u0026#34;: \u0026#34;CN_WORD\u0026#34;,\r\u0026#34;position\u0026#34;: 2\r},\r{\r\u0026#34;token\u0026#34;: \u0026#34;天安门\u0026#34;,\r\u0026#34;start_offset\u0026#34;: 4,\r\u0026#34;end_offset\u0026#34;: 7,\r\u0026#34;type\u0026#34;: \u0026#34;CN_WORD\u0026#34;,\r\u0026#34;position\u0026#34;: 3\r},\r{\r\u0026#34;token\u0026#34;: \u0026#34;天安\u0026#34;,\r\u0026#34;start_offset\u0026#34;: 4,\r\u0026#34;end_offset\u0026#34;: 6,\r\u0026#34;type\u0026#34;: \u0026#34;CN_WORD\u0026#34;,\r\u0026#34;position\u0026#34;: 4\r},\r{\r\u0026#34;token\u0026#34;: \u0026#34;门\u0026#34;,\r\u0026#34;start_offset\u0026#34;: 6,\r\u0026#34;end_offset\u0026#34;: 7,\r\u0026#34;type\u0026#34;: \u0026#34;CN_CHAR\u0026#34;,\r\u0026#34;position\u0026#34;: 5\r}\r]\r} EFK 收集和查看多节点日志\r#\r目录配置\r#\rmkdir /DATA/filebeat /DATA/filebeat/data filebeat.yml\r#\rsudo vim /DATA/filebeat/filebeat.yml filebeat.inputs: #数据输入相关配置\r- type: filestream # (必填)数据输入类型是filestream\renabled: true\rpaths:\r- \u0026#34;/var/log/services/kuibu/info.log\u0026#34;\rfields:\rserver_ip: 192.168.1.23\rfields_under_root: true\rtags: [\u0026#34;kuibu\u0026#34;]\rparsers:\r- multiline: # 多行合并\rtype: pattern\rpattern: \u0026#39;^\\[\u0026#39; # 匹配模式。每一行日志是以 \u0026#34;[\u0026#34;开头。\rnegate: true\rmatch: after\r- type: filestream # (必填)数据输入类型是filestream\renabled: true\rpaths:\r- \u0026#34;/var/log/services/knowledge-chain/info.log\u0026#34;\rfields:\rserver_ip: 192.168.1.23\rfields_under_root: true\rtags: [\u0026#34;knowledge-chain\u0026#34;]\rparsers:\r- multiline: # 多行合并\rtype: pattern\rpattern: \u0026#39;^\\[\u0026#39; # 匹配模式。每一行日志是以 \u0026#34;[\u0026#34;开头。\rnegate: true\rmatch: after\r- type: filestream # (必填)数据输入类型是filestream\renabled: true\rpaths:\r- \u0026#34;/var/log/services/linda/info.log\u0026#34;\rfields:\rserver_ip: 192.168.1.23\rfields_under_root: true\rtags: [\u0026#34;linda-brain\u0026#34;]\rparsers:\r- multiline: # 多行合并\rtype: pattern\rpattern: \u0026#39;^\\[\u0026#39; # 匹配模式。每一行日志是以 \u0026#34;[\u0026#34;开头。\rnegate: true\rmatch: after\routput.elasticsearch:\renabled: true\rhosts: [\u0026#34;192.168.1.11:19200\u0026#34;, \u0026#34;192.168.1.12:19200\u0026#34;, \u0026#34;192.168.1.13:19200\u0026#34;]\rusername: \u0026#34;elastic\u0026#34;\rpassword: \u0026#34;************\u0026#34;\rindices:\r- index: \u0026#34;java-log-kuibu-service-%{+yyyy.MM.dd}\u0026#34; when.contains:\rtags: \u0026#34;kuibu\u0026#34;\r- index: \u0026#34;java-log-knowledge-chain-service-%{+yyyy.MM.dd}\u0026#34; when.contains:\rtags: \u0026#34;knowledge-chain\u0026#34;\r- index: \u0026#34;java-log-linda-brain-%{+yyyy.MM.dd}\u0026#34;\rwhen.contains:\rtags: \u0026#34;linda-brain\u0026#34;\r#必须把ilm索引生命周期管理关掉(否则上面的indecis索引条件、以及下面的setup.template.pattern将会生效)\rsetup.ilm.enabled: false\r#默认索引名称是filebeat，如果想上面自定义索引上面，需要设置 模板name和匹配。pattern必须能匹配 上面设置的索引名称\rsetup.template.name: \u0026#34;java-log-template\u0026#34;\rsetup.template.pattern: \u0026#34;java-log-*\u0026#34;\rsetup.template.overwrite: false\rsetup.template.settings:\rindex.number_of_shards: 3 # 索引在ES的分片数\rindex.number_of_replicas: 1 # 每个索引的分片在ES的副本数 docker-compose.yml\r#\r部署在每一个需要读取日志的服务\n负责读取日志，并存储到ES\nsudo vim /DATA/docker-compose.yml version: \u0026#39;3.8\u0026#39;\rservices:\rfilebeat:\rimage: docker.io/elastic/filebeat:8.7.0\rcontainer_name: filebeat\ruser: root\rrestart: always\renvironment:\r- TZ: Asia/Shanghai\rvolumes:\r- /DATA/filebeat/filebeat.yml:/usr/share/filebeat/filebeat.yml:ro\r- /DATA/java/kuibu/logs:/var/log/services/kuibu/:ro\r- /DATA/java/knowledge-chain/logs:/var/log/services/knowledge-chain/:ro\r- /DATA/filebeat/data:/usr/share/filebeat/data\r- /etc/localtime:/etc/localtime\rcommand: [\u0026#34;filebeat\u0026#34;, \u0026#34;-e\u0026#34;, \u0026#34;-strict.perms=false\u0026#34;] 启动\r#\rsudo docker-compose up -d filebeat 查看 Kibana\r#\r数据流索引创建成功 在Kibana创建数据视图查看数据\r#\r在Discover内查看数据视图 选定数据视图，找到对应字段，即可看到收集到的日志，并进行筛选 在Kibana设置索引自动删除\r#\r配置索引模板，刚才在filebeat.yml指定的索引模板为java-log-template 配置数据保留7天 删除刚才建立的数据流 删除filebeat的data目录，并重新启动filebeat\nfilebeat.yml的setup.template.overwrite: false索引模板重写必须设置为fasle\ndocker-compose down filebeat\rsudo rm -rf /DATA/filebeat/data/*\rdocker-compose up -d filebeat 新的数据流保留时间已经为7天 "},{"id":19,"href":"/codestack/docs/javaee/mysql/sql-execution/","title":"SQL执行过程","section":"MySQL","content":"\rSQL执行过程\r#\r查询SQL执行顺序\r#\r以如下SQL为例：\nselect distinct table1.id as card_id from table1\rjoin table2 on table1.id = table2.id\rwhere table1.id \u0026lt; 2\rgroup by card_id\rhaving max(card_id) \u0026gt; 10\rorder by card_id desc\rlimit 1, 1; 执行顺序如下\nFROM，查询语句的开始，每个步骤为下一个步骤生成一个虚拟表，作为下一个步骤的输入 如果是表，直接操作表 如果是子查询，先执行子查询 如果要关联表，执行下述JOIN、ON JOIN 关联表，生成笛卡尔乘积虚拟表 ON，对JOIN出来的虚拟表进行按条件筛选，并生成一个新虚拟表 WHERE，对虚拟表进行按条件筛选，生成一张新虚拟表 GROUP BY，将按指定列的值分组，得到新的虚拟表。后续的所有步骤都只能操作被分组的列。 AVG,SUM,MAX…，聚合函数 对分组的结果进行计算，不生成虚拟表 HAVING，按条件筛选，主要和GROUP BY配合使用。且是唯一一个应用到已分组数据的筛选器。生成新虚拟表 SELECT，选择指定列，生成新虚拟表 DISTINCT，去重，对上出结果进行去重，移除相同的行。产生新虚拟表。使用GROUP BY后，DISTINCT多余。 ORDER BY，按照对指定列升序或降序。返回游标，而不是虚拟表。 LIMIT，取出指定行的记录，产生虚拟表并返回结果。Limit m,n表示从第m到第n数据。 "},{"id":20,"href":"/codestack/docs/project/distributed-lock/","title":"分布式锁实现","section":"项目设计","content":"\r分布式锁实现\r#\r"},{"id":21,"href":"/codestack/docs/project/","title":"项目设计","section":"Docs","content":"\r项目设计\r#\r"},{"id":22,"href":"/codestack/docs/deploy/minio/","title":"MinIO","section":"部署","content":"\rMinIO\r#\r部署方式：单节点\n运行方式：docker-compose\n目录创建\r#\rsudo mkdir /DATA/minio /DATA/minio/data /DATA/minio/config docker-compose.yml\r#\rsudo vim /DATA/docker-compose.yml\rservices:\rminio:\rimage: minio/minio\rrestart: always\rmem_limit: 1G\rports:\r- \u0026#34;9000:9000\u0026#34;\r- \u0026#34;19001:9001\u0026#34;\rcontainer_name: minio\rcommand: server /data --console-address \u0026#34;:9001\u0026#34;\renvironment:\r- MINIO_ROOT_USER=admin\r- MINIO_ROOT_PASSWORD=_admin123\r- MINIO_BROWSER_DEFAULT_LOCALE=zh_CN\rvolumes:\r- /DATA/minio/data:/data\r- /DATA/minio/config:/root/.minio 9000 是MInIO S3 API端口 9001 是MinIO WebUI 控制台端口 需要的节点才映射出来即可\n启动\r#\rsudo docker-compose up -d minio 防火墙打开\r#\rsudo ufw allow 19001/tcp "},{"id":23,"href":"/codestack/docs/javaee/spring/three-party-jar-import/","title":"SpringBoot 引入第三方 Jar 包","section":"Spring","content":"\rSpringBoot 引入第三方 Jar 包\r#\rSpringBoot 通过 SPI 机制引入第三方 Jar 包\nSPI 机制\r#\rJAVA SPI：Server Provider Interface 服务提供者接口，服务发现机制\n以 JDBC 为例 JDBC：通常执行流程\n加载数据库驱动 通过DriverManager对象，获取Connection连接对象 创建Statement对象执行SQL语句 处理ResultSet结果集 关闭连接 但是其中驱动加载时，Java 仅提供了一个接口，具体的驱动实现类是由各个数据库厂商提供的\n接口不能被实例化，要想实例化，就必须知道具体驱动类的全限定名 即需要知道驱动类的全限定名 Java 开发者想出在项目下的 ClassPath 目录中，创建 META-INF/services 文件夹\n在文件夹内创建以实现接口全限定名为名的文件，内容为实现类的全限定名\n通过IO获取所有的全限定名，将指定的Class文件实例化存储到容器中，完成第三方的实现类的实例化\n通过java.util.ServiceLoader.load方法实现SPI\nSpringBoot 自动装配\r#\rSpringBoot的自动装配：\nSpringBoot 开发中必不可少需要将第三方框架的 Jar 包内容加载到 IOC 容器中 但是SpringBoot默认加载启动类所在包或子包的内容，或者指定包扫描路径，指令包扫描路径在很多第三方引入的时候显然太繁琐 由于包名未知，不能通过扫描注入 SpringBoot 实现思路： SpringBoot规定了要接入SpringBoot的第三方框架，需要在Classpath目录下的META-INF文件中定义spring.factories文件 在其中定义需要被加载到IOC容器的类 SpringBoot启动时会自动扫描ClassPath目录下的所有META-INF的spring.factories文件，读取其中的要注册的类，通过反射进行实例化 SPI机制让接口和具体实现类解耦，使得可以根据具体的业务情况启用或替换具体组件\n"},{"id":24,"href":"/codestack/docs/anomaly-investigation/","title":"在线异常排查","section":"Docs","content":"\r在线异常排查\r#\r"},{"id":25,"href":"/codestack/docs/javaee/spring/springmvc-http/indxe/","title":"SpringMVC 接收 HTTP","section":"Spring","content":"\rSpringMVC 接收 HTTP\r#\rSpringMVC 是一个基于 Spring 的 Web 框架，运行于 Tomcat 等 Servlet 容器上 SpringBoot 内置 Tomcat 容器 当使用原生 Java Servlet 实现 Web 服务器，运行于 Tomcat 上时\n用户发起一个 HTTP 请求，Tomcat 收到请求，解析 HTTP 报文 Tomcat 根据 URL 找到对应的 Servlet，构建 HttpServletRequest 和 HttpServletResponce 对象，调用 servlet 的 service 方法，将对象引用传入该方法 Service 方法获取 Http 请求相关的信息，区分请求类型调用不同的方法，将处理结果放入 Responce 对象。 Tomcat 将 Responce 对象封装成 Http 响应报文，返回给客户端。 当使用 SpringMVC 实现 Web 容器，运行于 Tomcat 上时：\n用户发起一个 HTTP 请求，Tomcat 收到请求，生成一个线程解析 HTTP 报文 Tomcat 生成 HttpRequest 和 HttpResponce 对象，调用 HttpServlet.service 方法，最终将对象转发给 DispatcherServlet.doService 方法（即全流程只有一个 servlet 存在，与 URL 无关） DispatcherServlet 是统一访问点，将请求委托给其他业务处理器。doService 方法调用 doDispatch 方法执行分发 在 Tomcat 初始化时，通知 Spring 初始化容器，SpringMVC 会遍历容器中的 Bean，找到每一个 Controller 的所有方法访问的 url，和 Controller 保存到一个 Map 中。（HandlerMapping 组件获得了 URL 和 Controller 的关系） 分发时 doDispatch 方法根据 URL 找到 Controller，找到 Controller 中对应的方法。将 request 的参数等和方法上的参数根据注解等进行绑定，最后通过反射调用方法。 具体业务逻辑执行完后，回到 DispatcherServlet，进行后续处理，封装视图等 Tomcat 将响应对象封装成 HTTP 响应报文，返回给客户端 拦截器是在 Spring 中起作用，具体在分发前执行前置拦截器逻辑，分发后执行后置拦截器逻辑 过滤器是在 Tomcat 中起作用，具体在进入 servlet 前后进行预处理 切面是在具体方法前起作用，具体在调用方法逻辑前后，会处理注解、切点等的逻辑 "},{"id":26,"href":"/codestack/docs/javaee/spring/springboot-spring/","title":"SpringBoot 相比 Spring","section":"Spring","content":"\rSpringBoot 相比 Spring\r#\rSpringBoot 的核心能力：快速启动、最小化配置\n内嵌 Servlet 容器 Tomcat，可以让 Web 项目打成 jar 包，通过 java -jar 运行 提供 starter pom 系列，简化 maven 的依赖加载，减少依赖冲突的产生 支持自动化配置 不需要像 Spring 一样配置 Bean，使用 properties 或 yaml 配置文件以及配置类简单配置即可。 "},{"id":27,"href":"/codestack/docs/deploy/jenkins/","title":"Jenkins","section":"部署","content":"\rJenkins安装与Web项目部署\r#\r考虑到可移植性、对宿主机的影响最小，方便试错等问题\n采用Docker-Compose运行Jenkins\n自定义jenkins镜像，镜像内安装jdk、maven、node以便安装运行\n如果需要支持多版本的软件环境，则定制多版本的镜像即可\n部署Jenkins单节点\r#\r目录及权限\r#\rsudo mkdir /DATA/jenkins /DATA/jenkins/data\rsudo chmod -R 777 /DATA/jenkins/data 定制Dockerfile\r#\r提前安装Maven及Node 便于Java和前端打包\n运行镜像后尽量减少一些配置\n# 使用最新的 Jenkins LTS 镜像\rFROM jenkins/jenkins:lts\r# 切换到 root 用户进行系统级操作\rUSER root\r# 更新系统软件包列表\rRUN apt-get update \u0026amp;\u0026amp; apt-get install -y \\\rwget \\\rgnupg2 \\\rsoftware-properties-common\r# 下载并安装 JDK 8\rRUN wget -O /tmp/openjdk-8.tar.gz https://download.java.net/openjdk/jdk8u41/ri/openjdk-8u41-b04-linux-x64-14_jan_2020.tar.gz\rRUN mkdir -p /usr/lib/jvm\rRUN tar -xzf /tmp/openjdk-8.tar.gz -C /usr/lib/jvm\rRUN rm /tmp/openjdk-8.tar.gz\r# 添加 NodeSource 源以安装 Node.js 18\rRUN curl -sL https://deb.nodesource.com/setup_18.x | bash -\r# 更新软件包列表\rRUN apt-get update\r# 安装 Node.js 18\rRUN apt-get install -y nodejs\r# 下载并安装 Maven 3.6.3\rRUN wget https://archive.apache.org/dist/maven/maven-3/3.6.3/binaries/apache-maven-3.6.3-bin.tar.gz -P /tmp\rRUN tar -xzf /tmp/apache-maven-3.6.3-bin.tar.gz -C /opt\rRUN ln -s /opt/apache-maven-3.6.3 /opt/maven\rRUN rm /tmp/apache-maven-3.6.3-bin.tar.gz\r# 配置 Maven 国内源\rRUN mkdir -p /usr/share/maven/ref/\rCOPY settings.xml /usr/share/maven/ref/settings.xml\r# 配置 Node.js 国内源\rRUN npm config set registry https://registry.npmmirror.com\r# 配置Maven环境变量\rENV MAVEN_HOME=/opt/maven\rENV PATH=$PATH:$MAVEN_HOME/bin\r# 切换回 jenkins 用户\rUSER jenkins 放在 /DATA/jenkins目录下\n预备 Maven 的 setting.xml\r#\r\u0026lt;settings xmlns=\u0026#34;http://maven.apache.org/SETTINGS/1.0.0\u0026#34;\rxmlns:xsi=\u0026#34;http://www.w3.org/2001/XMLSchema-instance\u0026#34;\rxsi:schemaLocation=\u0026#34;http://maven.apache.org/SETTINGS/1.0.0 http://maven.apache.org/xsd/settings-1.0.0.xsd\u0026#34;\u0026gt;\r\u0026lt;mirrors\u0026gt;\r\u0026lt;mirror\u0026gt;\r\u0026lt;id\u0026gt;alimaven\u0026lt;/id\u0026gt;\r\u0026lt;mirrorOf\u0026gt;central\u0026lt;/mirrorOf\u0026gt;\r\u0026lt;name\u0026gt;aliyun maven\u0026lt;/name\u0026gt;\r\u0026lt;url\u0026gt;http://maven.aliyun.com/nexus/content/repositories/central\u0026lt;/url\u0026gt;\r\u0026lt;/mirror\u0026gt;\r\u0026lt;/mirrors\u0026gt;\r\u0026lt;/settings\u0026gt; 放在 /DATA/jenkins目录下\n构建镜像\r#\rcd /DATA/jenkins\rsudo docker build -t custom-jenkins:latest . 预备命令\n# 删除镜像\r# 先停止容器\rsudo docker-compose stop jenkins\r# 删除停止状态的容器\rsudo docker rm custom-jenkins\r# 删除镜像\rsudo docker image rm custom-jenkins docker-compose.yml\r#\rversion: \u0026#34;3\u0026#34;\rservices:\rjenkins:\rimage: custom-jenkins:latest\rcontainer_name: jenkins\rrestart: always\renvironment:\rTZ: Asia/Shanghai\rvolumes:\r- /DATA/jenkins/data:/var/jenkins_home\rports:\r- \u0026#34;18080:8080\u0026#34;\r- \u0026#34;50000:50000\u0026#34; 启动Jenkins容器\r#\rsudo docker-compose up -d jenkins 初始化设置\r#\r尝试访问Jenkins控制台\r#\rip:18080 获取Jenkins初始密码登录\r#\r# 进入docker容器\rsudo docker exec -it jenkins /bin/bash\r# 查看初始密码\rcat /var/jenkins_home/secrets/initialAdminPassword\r# 或者通过查看 docker 启动日志获取\rsudo docker logs jenkins 登陆后选择安装推荐插件\r#\r创建管理员用户\r#\r实例配置\r#\r保持默认即可 初始化完毕\r#\r点击开始使用 全局配置（Maven JDK Git SSH Node）\r#\rMaven\r#\rsettings.xml 路径设置\r#\r以使换源的配置生效 安装Maven插件\r#\rMaven Integration/Maven Integration plugin\n安装maven集成插件，新建任务才可以新建Maven任务 全局配置\r#\r告知 jenkins maven 环境变量，用于后续命令执行 "},{"id":28,"href":"/codestack/docs/javaee/mysql/logfile/","title":"日志文件及作用","section":"MySQL","content":"\r日志文件及作用\r#\rerror.log 错误日志：\r#\r对MySQL的启动、运行、关闭过程进行了记录\r用于问题的排查，如例如权限问题、配置错误、磁盘空间不足\rslow.log 慢查询日志：\r#\r可通过slow_query_log_file参数在配置文件中指定文件名，若未指定，默认在数据目录下，文件名为hostname-slow.log\r默认情况下不启动慢查询日志，需要手动设置\r用于定位执行时间超过设置值的SQL，以及没有使用索引的SQL\r可以通过mysqldupmslow查找和筛选慢查询日志的内容\r查询日志：\r#\r其文件名可通过general_log_file参数在配置文件中指定，若未指定，默认在数据目录下，文件名为hostname.log\r记录了所有对MySQL数据库请求的信息，不论是否得到了正确执行\r但由于会记录所有语句，开启该日志会对性能产生较大影响，所以通常只在调试或测试环境中开启\r二进制日志bin.log\r#\r二进制日志由一系列文件组成，文件名格式为binlog.xxxxxx ，其中xxxxxx是一个 6 位的数字序号，从 000001 开始递增。其文件名前缀可通过log_bin参数在配置文件中指定\r记录了所有对MySQL数据库进行的更改\r作用：\r数据恢复，数据库全备文件恢复\r主从复制，通过复制和执行二进制日志，使从库和主库实时同步\r审计判断是否有对数据库攻击\r中继日志（Relay Log）\r#\r文件名格式为relay-log.xxxxxx ，其中xxxxxx是一个 6 位的数字序号，从 000001 开始递增。文件名前缀可通过relay_log参数在配置文件中指定。\r作用：\r在主从复制架构中，从服务器从主服务器接收二进制日志内容后，会将其存储在中继日志中\r从服务器的 SQL 线程会读取中继日志中的内容，并在本地执行相应的 SQL 语句，从而实现数据的同步\r事务日志（Innodb）\r#\rRedo log 重做日志:\r#\r默认文件名为ib_logfile0、ib_logfile1等，可通过innodb_log_files_in_group参数指定日志文件的数量，通过innodb_log_file_size参数指定每个日志文件的大小。\r用于保证事务的持久性\rMySQL中有大量缓存，数据修改时首先更新缓存，但是缓存并非马上同步到磁盘，即为脏页\r但是数据库如果宕机，则内存数据丢失，重启无法恢复\r所以每次修改内存就要写redo log，redo log顺序写入，磁盘的顺序读写速度远快于随机读写，写操作对性能影响较小\rRedo log是物理日志，记录数据页的物理修改，用于恢复提交后的物理数据页\r如果数据库意外重启，会根据redo log进行数据恢复\r如果redo log有事务提交，则提交事务修改数据。也仅能恢复到数据最后提交的状态\r可以利用 Redo Log 将未写入磁盘的数据页恢复到崩溃前的状态\rUndo log 回滚日志:\r#\rInnoDB Undo Log 没有单独的文件名，它是存储在系统表空间（ibdata1）或独立的 undo 表空间中的。可通过innodb_undo_tablespaces参数指定独立 undo 表空间的数量\rundo log是逻辑日志，每次修改数据，undolog中出现一条反操作的记录\r可以用于事务回滚，也可以根据undolog回溯到某个特定版本的数据\r用于实现事务的原子性和多版本并发控制（MVCC）\r在事务执行过程中，Undo Log 会记录数据修改前的状态，当事务需要回滚时，可以根据 Undo Log 将数据恢复到事务开始前的状态\r同时，MVCC 通过 Undo Log 提供数据的多个版本，使得不同事务可以同时访问同一数据的不同版本，提高并发性能\r"},{"id":29,"href":"/codestack/docs/javaee/mysql/explain/","title":"Explain参数解释和查询成本分析","section":"MySQL","content":"\rExplain参数解释和查询成本分析\r#\rExplain\r#\r通过执行 explain [sql] 得到执行计划\n如果from中包含子查询，会查并生成临时表\nexplain执行完之后执行show warnings，有时候可以直接拷贝出来直接使用，大多时候可以用于参考执行\n结果列分析\r#\rid\r#\r有几个select就有几个id，id按select出现的顺序增长，id大的先执行，null最后执行，相同则从上往下执行\nselect_type\r#\rsimple 简单查询，没有子查询和union primary 复杂查询中最外层迭代select subquery 包含在select中的子查询，不在from中 dependent subquery select语句出现的子查询，依赖外部查询 derived 包含在from子句的子查询，会把结果放在临时表（派生表） table\r#\r这一行的查询在访问哪个表\nfrom子句有子查询时，table列是格式，表示当前查询依赖id=N的查询，会先执行id=N的查询 有union时，union result的table列的值为union 1,2，1和2表示参与union的select的id type\r#\r表示关联类型或访问类型，表示mysql决定如何查找表中的行，查找数据行记录的大概范围, 从最优到最差依次为：\nsystem \u0026gt; const \u0026gt; eq_ref \u0026gt; ref \u0026gt; range \u0026gt; index \u0026gt; ALL 一般来说应该最少把查询保持在range级别，最好达到ref\nsystem MyIsm出现，表为空或者记录唯一时 const 主键索引或唯一索引的等值查询 eq_ref join的时候有驱动表和被驱动表，被驱动表走唯一或者主键索引时 ref 非主键或非唯一索引的等值查询，关联查询时被驱动表的驱动键走非唯一索引 range 一般索引的范围查询 index 全表扫描，非聚簇索引的叶子节点 All 聚簇索引的全表扫描 possible keys列\r#\r显示查询可能使用哪些索引来查找\nposible_keys有列而key为null，是因为根据成本分析，走索引比全表扫描成本高，选择了全表扫描 如果possible_keys为null，则没有索引。应检查where子句看是否可以创造索引提升查询性能 key列\r#\r显示MySQL实际采用哪个索引优化对该表的访问\n如果没有用索引，该列为null 如果想强制MySQL使用或者忽视possible_keys列中的索引，可以在查询时使用force index或ignore index 有时候数据量变化是会出现索引失效，可以考虑加上force index key_len\r#\r表示索引使用的字节数，可以判断索引的使用情况\n特别是组合索引情况下，判断索引有多少部分被使用到\n如abc组合索引，查询条件为ac，正常会使用a索引部分，有时会索引下推，用到ac索引\nref列\r#\r显示在key列记录的索引中，表查找值所用到的列或常量\n如 const、table.col1\nrows列\r#\r是MySQL根据索引统计信息估计要读取并检测的行数，不是结果集的行数\nfiltered列\r#\r是已筛选列，表示按表条件筛选的表行的估计百分比，最大值是100%，意味着没有筛选\n越小表示过滤量的增加\nrows显示检查的估计行数\nrows * filtered 显示与下表连接的行数，如果rows=1000，filtered=50.00，那么与下表联表的行数为1000*50%=500\nextra列\r#\rusing index 使用覆盖索引 using where 使用where语句处理结果，且查询列未被索引覆盖 using indxe condition 查询列不完全被索引覆盖，where条件中是一个前导列的范围 using temporary mysql需要创建临时表处理查询，必须优化，临时表开销大，首先想到用索引优化 using filesort 使用外部排序而不是索引排序，数据较小的时候从内存排序，否则需要在磁盘完成排序。这种情况下应考虑使用索引优化 全表扫描成本分析\r#\rMySQL的成本：\nMySQL执行一个查询可以有不同执行方案，MySQL会选择成本最低的方案执行查询 MySQL中一条查询语句的执行成本：IO成本+CPU成本 IO成本：一般MyISAM和InnoDB都是将数据和索引存储在磁盘，查询时需要将数据和索引加载到内存，这个加载过程损耗的时间为IO成本 CPU成本：读取和检测记录是否满足对应的搜索条件、对结果集进行排序的操作损耗的时间为CPU成本 对Innodb来说，全表扫描的含义是把聚簇索引中的记录都依次和给定的所有条件进行一下比较，把符合搜索条件的记录加入到结果集，所以需要将聚簇索引所在的页面加载到内存，再检测记录是否符合搜索条件\n查询成本 = 把二叉树叶子节点load进内存的IO成本 + 和叶子节点中每条数据compare的CPU成本\n要load多少次数据到内存？ 叶子节点有多少条数据？\n表统计信息表\r#\rMySQL为每个表维护了一系列的统计信息，可以通过以下语句查询指定表统计信息\nshow table status like \u0026#39;table_name\u0026#39; 内部的值和实际有一点偏差，类似估算值,从中可以查到Data_length字段，是数据表总大小\nrows是表记录数，对Innodb来说是一个估计值\nIO成本\r#\rData_length = 聚簇索引的页面数量 * 每个页面的大小（16kb）\n聚簇索引的页面数量=Data_length ÷ 16 ÷ 1027\nIO成本 = 聚簇索引的页面数量 * 1.0 + 1.1\n页面数 * 加载一个页面的IO成本常数 + 微调值\n微调值是硬编码在代码中，没有注释且值十分小，不影响大方向分析\nCPU成本\r#\r= 统计数据表中的rows * 0.2 + 1.0\n是统计记录数 * 访问一条记录需要的CPU成本常数 + 微调值\n总成本 = IO成本 + CPU成本\n上面分析的是聚簇索引，直接扫数据，没有回表\n可以自行分析二级索引\n索引优化\r#\r联合索引第一个字段用范围查询不走索引 第一个字段就用范围查询，回表效率不高，不如全表扫描\n联合索引第一个字段Like，走索引 可以在索引遍历过程中，对索引包含的所有字段先做判断，过滤不符合条件的记录再回表，减少回表次数\n覆盖索引优化 如果有查询经常要取某几个字段和筛某几个字段，可以搞成联合索引，这样可以直接从索引树上获取数据，不用回表\nJoin优化\r#\r嵌套循环连接Nested-Loop Join(NLJ)算法 一次一行循环地从驱动表读取数据，取关联字段在被驱动表找到满足条件的行，再取两表结果合集\n基于块地嵌套循环连接Block Nested-Loop Join(BNL)算法 把驱动表的数据读取到join_buffer中，然后扫描被驱动表，把被驱动表数据拉出和驱动表数据对比\n应该尽量嵌套循环进行连接，使用NLJ算法\n"},{"id":30,"href":"/codestack/docs/javase/exception/","title":"异常体系","section":"JavaSE","content":"\r异常体系\r#\rThrowable\r#\rThrowable 类是所有异常和错误的超类\n两个直接子类为 Error 和 Exception，分别表示错误和异常\nError\r#\rError 指的是程序无法处理的错误，由 JVM 产生和抛出\n如 OutOfMemoryError、StackOverFlowError、ThreadDeath 等。Error 发生时，JVM 会选择终止线程 Exception\r#\r分为不检查异常（unchecked Exception）和检查异常（checked exception）\n也是运行时异常（RuntimeException）和非运行时异常\nException 是程序可以处理的异常，分为两大类，运行时异常和非运行时异常。程序中需要尽量去解决这些异常 运行时异常\r#\r指 RuntimeException 类及其子类，如 NullPointerException、IndexOutOfBoundsException 等。\n属于不检查异常，程序可以选择捕获处理，也可以不处理 例如： NullPointerException - 空指针引用异常 ClassCastException - 类型强制转换异常 IllegalArgumentException - 传递非法参数异常 ArithmeticException - 算术运算异常 ArrayStoreException - 向数组中存放与声明类型不兼容对象异常 IndexOutOfBoundsException - 下标越界异常 NegativeArraySizeException - 创建一个大小为负数的数组错误异常 NumberFormatException - 数字格式异常 SecurityException - 安全异常 UnsupportedOperationException - 不支持的操作异常 非运行时异常\r#\r指 Exception 类及其子类中 RuntimeException 类及其子类以外的类\n如 IOException、SQLException 等，以及用户自定义的 Exception（一般不会自定义检查异常，而是自定义 RuntimeException） 属于检查异常，如果程序不去捕获并处理或抛出到最外层，则编译不能通过 "},{"id":31,"href":"/codestack/docs/project/design-theory/","title":"一些设计理论","section":"项目设计","content":"\r一些设计理论\r#\rCAP 理论\r#\rC 代表一致性：分布式系统中数据的一致性 A 代表可用性：分布式系统是否正常可用 P 代表分区容器性：分布式系统中出现网络问题的容错性 CAP 理论：分布式系统中不可能同时满足 C 和 A，即要么 CP 要么 AP 一致性和可用性只能取其一。需要数据强一致性就会损失可用性，需要可用性保证，就会损失强一致性 实际生产环境遵循 BASE 理论 BASE 理论\r#\rBA：Basically Availiable，基本可用，允许一定程度的不可用，如系统故障导致请求时间变长或非核心部分不可用 S：Soft state: 表示分布式系统可以处于一种中间状态，比如数据正在同步 E：Eventually consistent: 最终一致性。不要求分布式系统数据实时一致，允许经过一段时间后一致，过程中系统也是可用的 "},{"id":32,"href":"/codestack/docs/javaee/mysql/tree-high/","title":"索引树高度计算","section":"MySQL","content":"\r索引树高度计算\r#\r基本原理\r#\rInnodb是索引组织表，每个页都包含一个PAGE_LEVEL，表示当前页在索引上的高度\n默认叶子节点高度为0，ROOT节点PAGE_LEVEL+1就是这棵索引高度\nPAGE_LEVEL在每个页的64位偏移位置，占用2字节\n找到ROOT页位置，知道单页大小，使用hexdump在指定表空间找到第PAGE_NO页的64位偏移量的后两个字节即可\n找到ROOT页信息\r#\rSELECT b.name, a.name, index_id, type, a.space, a.PAGE_NO\rFROM information_schema.INNODB_SYS_INDEXES a,\rinformation_schema.INNODB_SYS_TABLES b\rWHERE a.table_id = b.table_id AND a.space \u0026lt;\u0026gt; 0; 结果： 其中（space、PAGE_NO）指向ROOT页\nspace是表空间，可以是系统表空间（如ibdata1文件）或独立表空间（如每个InnoDB表的.ibd文件）。表空间由多个区（extent）组成，每个区包含连续的页（page）\n也就是ROOT页是space的page_no页\n查看innodb_page_size\r#\rshow variables like \u0026#39;innodb_page_size\u0026#39; 结果： 也就是Innodb默认的页大小16KB\n找到ROOT的PAGE_LEVEL，得到索引高度\r#\r首先要找到表对应的ibd文件，也就是表空间文件\n所在位置是MySQL的数据目录下的数据库名文件夹下\n#查找MySQL数据目录\rshow variables like \u0026#39;datadir\u0026#39; 我的MySQL是用Docker起的，docker中没有安装hexdump命令，不过这个目录被挂载出来了，考虑在宿主机上分析其中的ibd文件\n但所在文件夹和文件权限限制了宿主机外用户访问文件夹和文件 修改权限需要到docker容器中修改该文件和对应文件夹权限\nchmod 755 path 原本权限为750，禁止其他用户读写文件夹\n修改后在宿主机进入文件夹中，找到所需文件，在文件夹执行命令\nhexdump -C -s 49216 -n 10 goods_info_100M.ibd 前两个字节是PAGE_LEVEL，所以这个索引树高度为3+1 = 4\n后面8个字节是index_id，32十六进制转10进制就是50，49216 = 16384*3 + 64，是ROOT页在PAGE_NO=3的索引树\n总结\r#\r关键命令：\nhexdump -C -s [innodb_page_size*PAGE_NO + 64] -n 10 [ibd filename] "},{"id":33,"href":"/codestack/docs/javase/java-softwre-package/","title":"JDK|JRE|JVM","section":"JavaSE","content":"\rJDK|JRE|JVM\r#\rJVM：\r#\rJava 虚拟机，Java 程序能够跨平台运行的核心\n所有的 Java 程序都会被编译为.class 的类文件，同代码在任何平台上编译字节码都相同 .class 文件在虚拟机上运行，由虚拟机将字节码解释给本地系统执行 JRE：\r#\rJava 运行时环境，即 Java 程序必须在 JRE 上运行\n包含 JVM 和 Java 核心类库 JVM 不能直接执行 class，还需要 Java 核心类库来解释 class 安装 jre 后有 bin 和 lib 两个文件夹，可简单理解为分别是 JVM 和 Lib JDK：\r#\rJava 开发工具包，包括 JRE、Java 工具、编译器和调试器组成\n自带工具：\njava：Java 运行工具，运行.class 或 jar 包 javac: Java 编译工具，将 Java 源代码编译为字节码 javap: Java 反编译工具，将 Java 字节码反汇编为源代码 jmap：Java 内存映射工具，打印执行 Java 进程、核心文件或远程调试服务器的配置信息 jps: Java 进程状态工具，显示目标系统上的 HotSpot JVM 的 Java 进程信息 jinfo: Java 配置信息工具，用于打印指定 Java 进程、核心文件或远程调试服务器的配置信息 jstack: Java 堆栈跟踪工具，用于打印 Java 进程、核心为念 u 哦远程调试服务器的 Java 现成的堆栈跟踪信息 jvisualvm: Java 可视化 JVM 检测、故障分析工具。图形化界面提供指定虚拟机的 Java 应用程序的详细信息 jconsole：图形化界面的检测工具，监测并显示 Java 平台上的应用程序的性能和资源占用等信息 javadoc: Java 文档工具，根据源代码中的注释信息生成 HTML 格式的 API 帮助文档 三者的关系：\r#\rJDK 包含 JRE、JRE 包含 JVM JVM 不能单独搞定 class 的执行，解释 class 需要使用 JRE 中的 Java 核心类库 lib 我们利用 JDK 开发 Java 源程序，通过 JDK 提供的 javac 编译程序将源程序编译成 Java 字节码，在 JVM 使用 JRE 的 lib 解释这些字节码，映射到 CPU 指令集或 OS 的系统调用 "},{"id":34,"href":"/codestack/docs/deploy/","title":"部署","section":"Docs","content":"\r部署\r#\r"},{"id":35,"href":"/codestack/docs/basic/net/transport/tcp/","title":"TCP","section":"传输层","content":"\rTCP\r#\rTCP是一种面向连接的、可靠的、基于字节流的传输层通信协议\n报文结构\r#\r源端口：发送方使用的端口号，16位 目的端口：接收方使用的端口号，16位 序号：本报文段发送数据的第一个字节的编号，32位 确认号：接收方期望接收到的下一个报文段的第一个字节的编号 数据偏移(首部长度)：指数据段中的数据部分的起始处距离TCP报文段起始处的偏移量，也就是TCP报文的报头部分的长度，接收端根据这个知道数据（有效载荷）从何处开始 4位 保留字段：TCP协议将来的发展预留的空间，目前必须全部为0，6位 标志位字段：共六个标志位，每个1bit 窗口大小：表示发送该TCP报文的接收窗口还可以接受多少字节的数据量，用于TCP的流量控制，16位 校验和：用于确认传输的数据有无损坏。发送端基于数据内容校验生成一个数值，接收端同样生成一个数值进行对比，相同的数据有效，反之无效则丢弃数据包，16位 紧急指针：仅当标志位的URG字段值位1才有意义。指出有效载荷中位紧急数据的字节数。当所有紧急数据处理完，TCP告知应用程序恢复到正常操作。即使接收方窗口大小为0，也可以发送紧急数据，因为紧急数据无需缓存，16位 选项字段：长度不定，但是必须是32bit的整数倍，即4字节的整数倍。内容可变，所以使用首部长度来区分选项部分的具体长度 如何分离首部和载荷（确认首部长度）\r#\rTCP固定首部长度20字节，以及选项字段 首部长度字段为4bits，最大可表示长度为1111，即15。表示单位是4字节 所以TCP首部最长是15*4 = 60字节 固定首部为20字节，选项部分为4字节的倍数，最大为40字节 这说明了数据偏移字段标识首部长度的原理 根据首部长度，可以分离首部和载荷\n连接的建立和断开\r#\rTCP连接是TCP协议在网络中建立的可靠通信链路\n这种可靠指的是不丢包，就是网络不太好的情况下可以尽量保证数据的完整接收（发送确认和重发）\n由IP协议锚定双方地址，由底层协议传输数据包，由高层协议进行数据的加解密\n换言之，TCP的可靠通信链路中保证的是传输和接收数据包的完整性，而不是包揽了链路的实际构建、数据包防伪等过程。不要把可靠性的理解在TCP扩展太多\n为什么要建立连接\r#\r可靠性验证：建立连接的过程实际就是通信双方验证各自的发送和接受能力是否正常，双方的信道是否通畅 协商参数：如序号初始值，MSS，是否启用SACK等 连接的建立 - 三次握手\r#\r服务器初始化状态 服务器端进程函数顺序：socket =\u0026gt; bind =\u0026gt; listen =\u0026gt; accept socket()创建套接字listenfd bind()将套接字和端口绑定 listen()让listenfd成为监听套接字，后续连接通过监听套接字获取，服务器处于监听状态 accept()进程阻塞，直到有客户连接请求到达才返回 客户端发起连接请求 - 第一次握手 客户端进程函数顺序:socket =\u0026gt; connect socket()创建套接字 connect()调用时操作系统自动bind()，然后客户端进程就会向服务端进行发送连接请求报文 连接请求报文首部的标志位SYN=1\n同时选定一个初始序号SEQ=x，x是随机产生的整数\nTCP规定SYN=1的报文段不可以携带数据，但消耗一个序号\n此时客户端进程进入SYN-SENT(同步报文已发送状态)\n服务器同意建立连接，回复确认 - 第二次握手 服务器端进程收到连接请求报文，同意建立连接 从listenfd监听套接字获取客户端信息 服务器端操作系统向客户端发送SYN报文段进行确认 连接确认报文首部标志位SYN=1，ACK=1，确认号ack=x+1\n同时为自己选择一个初始序号seq=y 同样不能携带数据，消耗一个序号\nTCP服务器进入SYN-RCVD(同步报文已收到)状态\n客户端确认连接已经被确认，发送确认连接信息 - 第三次握手 客户端进程收到服务器的确认报文，向服务器发送确认报文表示自己收到 确认报文首部ACK=1，确认号ack=y+1，序号seq=x+1 可以携带数据，不携带数据则不消耗序号\n客户端认为连接建立成功，进入ESTABLISHED(已建立连接)状态，准备发送数据\n服务器收到确认报文，进入ESTABLISHED(已建立连接)状态，准备接受数据\n形象理解和问题\r#\r三次握手的形象理解\r#\r客户端用seq=x标识自己，发送SYN=1的连接请求报文，告诉服务器我想建立连接 服务器用seq=y标识自己，发送ACK=1 SYN=1 确认号ack=x+1的确认报文，告诉客户端我是y，同意了序号x的连接请求 客户端发送确认连接报文ACK=1，确认号ack=y+1，告诉服务器这是序号x的连接确认报文(+1)，而且我收到了seq=y的连接同意信息，我认为我们之间的连接已经建立 服务器收到确认报文，认为连接已经建立 初始序列号SEQ为什么要随机?\r#\rseq序号表示的是发送的TCP报文数据部分的起始字节位置，服务器/客户端可以通过序号正确读取数据。如果不是随机分配起始序列号，那么黑客就会很容易获取客户端与服务器之间TCP通信的初始序列号，然后通过伪造序列号让通信主机读取到携带病毒的TCP报文，发起网络攻击\n服务器没有收到客户端的确认报文怎么办?\r#\r操作系统会给每个处于SYN-RCVD状态的服务器进程设定一个计时器，如果超过一定时间还没有收到客户端第三次握手的ACK确认报文，将会重新发送第二次握手的确认报文，直到重发达到一定次数才会放弃\n为什么不能两次握手?\r#\r两次握手意味着，服务器来确认连接的建立\n如果确认报文丢失，客户端不知道服务器确认连接已经建立，就不会发送数据，服务器会维护不成功的TCP连接 容易遭受SYN洪水攻击，攻击者发送大量的SYN请求连接报文，服务器对每个报文都建立连接，消耗大量资源 可能有已失效的连接报文传输到服务器，服务器维护失效连接 失效连接的产生原因和两次握手的后果 客户端A发送给服务器B连接报文，但报文在某个网路节点滞留，迟迟不到达服务器 客户端A等待服务器B确认报文太久，以至于客户端认为刚才的连接报文失效，不再等待确认报文 服务器B突然收到连接报文，并确认连接发回确认报文 客户端没有在等待确认报文，就不会处理确认报文，也不会向服务器发送数据，于是服务器维护的是一个无效连接\n只要握手次数是偶数次，就会把连接的确认带来的成本转移给服务器\n为什么必须是三次握手?\r#\r奇数次握手，客户端先建立连接 防止已失效的连接报文突然传到服务器，导致错误 三次握手时已失效的连接报文突然传到服务器，服务器发回确认报文 客户端无回复，服务器也不会认为连接确认，不会做接受数据准备等，连接仍然未被建立\n三次是验证双方信道通畅，发送接收能力正常的最小成本 怎么处理SYN洪水攻击?\r#\rSYN Flood是互联网上最原始、最经典的DDoS（Distributed Denial of Service）攻击之一 攻击方式：\n攻击者短时间伪造大量不存在的IP地址，并用这些IP地址向服务器发送大量SYN连接请求报文 服务器需要为每个SYN报文回复ACK，但是一直收不到客户端的ACK报文，就要重发一定次数才放弃，这回非常消耗资源 导致没有资源处理正常的连接，服务器处理连接能力停摆 解决方法：\n缩短SYN Timeout：SYN洪水攻击的效果取决于服务器保持的半连接数量=SYN攻击频率 * SYN Timeout，缩短接收到SYN报文到确认报文废弃并丢弃连接的时间，可以大量减少服务器载荷 设置SYN Cookie：为每个连接请求的IP地址分配Cookie，如果短时间收到某个IP地址的大量连接请求，就不再处理这个IP地址的连接报文 设置防火墙，白名单或者黑名单 连接的断开 - 四次挥手\r#\r客户端发送FIN结束报文 - 第一次挥手 客户端主动断开连接，客户端进程调用close(fd)关闭套接字，操作系统发送FIN结束报文，并停止发送数据，主动关闭TCP连接 FIN结束报文，FIN=1，seq=u，u是前面已发送的最后一个字节的序号+1\n客户端进入FIN_WAIT_1(终止等待)状态，等待服务器发送确认报文\nFIN报文不携带数据，消耗一个序号\n服务器收到，回复确认报文 - 第二次挥手 服务器收到客户端的FIN结束报文，并立即发送确认报文 确认报文ack=u+1，seq=v，v等于服务器之前已发送的数据的最后一个字节的序号+1\n服务器进入CLOSE_WAIT(关闭等待)状态\n服务器通知上层应用程序，客户端不再向服务器发送数据，但服务器如果有数据发送，客户端仍要接受，服务器会继续发送未发完的数据给客户端\nTCP连接处于半关闭状态(half-close)\n客户端收到服务器确认报文后，客户端进入FIN_WAIT2(终止等待2)状态，等待服务器数据发送完，发送FIN结束报文\n服务器发送FIN结束报文 服务器数据发送完毕后，应用进程调用close(fd)通知TCP释放连接，向客户端发送FIN结束报文 结束报文FIN=1，seq=w，w是此前发送数据的最后一个字节序号\n同时需要回复确认号ack=u+1\n服务器进入LASK_ACK(最后确认)状态，等待客户端确认\n客户端收到，回复确认报文 - 第四次挥手 客户端收到服务器FIN结束报文，向服务器发送报告ACK确认报文 确认报文ACK=1，确认号ack=w+1，序号seq=u+1(第一次挥手的FIN报文消耗一个序号)\n客户端进入TIME_WAIT(时间等待状态)\nTCP连接此时仍未被释放，必须经过时间等待器TIME_WAIT timer设置的时间2MSL后，客户端才进入CLOSED状态\nMSL(Maximum Segment Lifetime，最长报文寿命)，是一个TCP报文存活的最长时间，RFC793建议为2分钟，可以根据实际情况设置更小的值\n即客户端进入TIME_WAIT状态后，要经过4分钟才进入CLOESD状态，才可以建立下一个连接 当客户端撤销相应的传输控制快TCB(socket调用前建立)，才算结束TCP连接\n先发起释放连接请求的，后结束TCP连接\n形象理解与问题\r#\r四次挥手的形象理解\r#\r客户端数据发送完毕，决定断开连接，发送结束报文告诉服务器，我最后发送的数据是u，我要断开了 服务器收到，回复收到了关于最后发送数据是u的断开请求，告知我目前最后发送数据是v，我还可能会继续发送数据 客户端收到服务器的确认，知道服务器知道自己要断开，同时知道服务器还会继续发送数据，自己仍须接收，直到收到服务器的结束FIN报文 服务器数据发送完毕，发送FIN结束报文，标示自己这边已经发送完毕数据，可以断开。我的这次断开针对最后收到数据是u的那个连接，我最后发送的数据序号是w 客户端收到服务器说他结束了，回复收到服务器的结束，知道对方发送的最后数据是w。客户端开始等待一段时间2MSL，没什么问题就释放TCP连接 为什么连接是三次握手，关闭是四次挥手？\r#\r建立连接也可以是四次握手，中间服务器发回的SYN和ACK可能被分成两个报文发送 关闭连接时中间服务器给客户端发送的确认报文和FIN结束报文可能合并，如果服务器已经没有数据要发送的话。但是如果还有数据要发送就得分开，发送完数据才发送FIN\nTCP通信是全双工的，发送FIN表示一端不再继续发送，但是还会继续接收。\n收到FIN报文，只是关闭一个方向的连接，TCP处于半关闭状态\n为什么客户端要等待2MSL才进入CLOSED状态？\r#\r保证客户端最后发送的ACK能到达服务器 保证可靠的终止TCP连接。因为如果报文丢失，服务器接收不到ACK报文，处于LAST_ACK状态的服务器会超时重传FIN报文，而客户端能在2MSL时间内收到重传的FIN报文。收到后客户端会重传确认，并重新计时。最后双方可以正常进入CLOSED状态 防止已经失效的连接请求报文出现在本次TCP连接 客户端发送完最后的ACK报文后经过2MSL，可以让本次TCP连接持续时间内产生的所有报文都从网络上消散。下一个新的TCP连接就不会出现旧的请求报文 TIME_WAIT状态何时出现？带来哪些问题？\r#\rTIME_WAIT是发起连接的一方收到对方的FIN结束报文，发出ACK确认报文后进入的状态 TIME_WAIT是为了让TCP报文得以自然消散，被动关闭的一方能够正常关闭连接\n服务器TIME_WAIT：如果短时间内大量关闭客户端连接，会出现大量TIME_WAIT状态，TCP连接没有释放，就会占据大量的tuple数据(包含目的和源IP、协议号、目的和源端口号)，严重消耗服务器资源 客户端TIME_WAIT：短时间大量TIME_WAIT无法释放端口，大量消耗客户端的端口号，只有65535个，消耗完毕就无法开启新的TCP连接 可靠性策略\r#\r校验和（单包数据无损）\r#\rTCP报文首部存在校验和字段，用于验证数据是否完整传输 发送端基于数据内容校验生成一个数值，接收端同样生成一个数值进行对比，相同的数据有效，反之无效则丢弃数据包\n序列号(数据包有序、去重)\r#\rTCP在操作系统中有自己的缓冲区，应用层调用的write、sendto等接口，是将自己定义的额缓冲区数据，拷贝到TCP的发送缓冲区 TCP面向字节流，TCP缓冲区中以字节为单位，将缓冲区划分为类似字符数组的形式，数组自带的下标作为TCP缓冲区字节的编号 TCP传输的每个字节都会按顺序编号 数据可以在接收到后有序拼接 由于网络延迟导致的重发数据重复接收等，可以用序列号去重\n确认应答\r#\rTCP协议规定，接收方接收数据，必须发送确认报文 序列号和确认号是TCP缓冲区的下标\n序列号：是本报文第一个字节的编号。TCP连接中传输的字节流的每个字节都会按顺序编号。序列号x：我给你的第一个字节是编号x的\n确认号：发送方给接收方发送数据，接收方收到数据就要给发送方发送确认报文。确认报文中的确认号表示接收方期望收到发送方下一个报文的第一个字节的编号。确认号y：我期望你下次给我发的第一个字节是编号y的\n接收方收到数据后，根据序列号给出确认号，让发送方知道接收方接受到哪些数据 应答报文ACK=1，此时确认号字段才有效\n确认应答可以提升通信效率 发送方完全可以一次性发送多个报文，每个报文是不同段的数据\n如果中间确认应答丢失，但是只要收到靠后确认号的应答，就可以确认前面的数据接收方已经收到 如果靠前序列号的报文丢失，接收方即使收到了后面序列号的数据，也只会给发送方返回丢失之前的序号的确认应答。前面的丢失报文由这个确认应答触发重传，而后面的发送报文没有返回确认报文，触发超时重传。 超时重传\r#\r数据在网络传输过程中可能丢包 发送方的发送报文和接收方的确认报文都可能丢失 都会导致发送方收不到接收方的确认报文 TCP规定，在报文发送后的一个时间间隔后，如果还没收到确认报文，发送方一律认为报文丢失，要重发报文\n超时时间的考虑\n最理想状态，保证确认应答一定能在这个时间内返回 设置太长影响重传效率，设置太短会频繁发送重复报文 不同网络环境要设置不同的超时时间 TCP动态计算超时时间\n各种操作系统中，超时以500ms为一个单位控制，每次设置超时时间都是500ms的整数倍 重发一次后仍得不到应答，等待2*500ms再重传 仍得不到应答，等待4*500ms再重传，指数递增 累积到一定重传次数，TCP认定对方主机异常，强制关闭连接 连接管理（通信能力检测）\r#\r就是三次握手四次挥手 数据传输前，验证双方的发送和接收能力，以及通信环境的正常\n流量控制（滑动窗口）\r#\r接收端处理数据速度有限，发送端发送太快打满接收缓冲区，会导致丢包，引起丢包重传等一系列反应 TCP根据接收端接受能力决定发送端发送速度（滑动窗口机制）\n拥塞控制\r#\r如果网络状态比较拥堵，不清楚网络状态，盲目根据接收方窗口大小发送数据，将导致网络更加拥堵，数据发送不出去 TCP引入慢启动机制，先发送少量数据，探测信道状态，了解拥堵情况，再决定按照多大的速度传输数据 设置拥塞窗口cwnd，大小为swnd 慢启动：\n一开始将cwnd设置为一个较小的值，通常是一个MSS 每经过一个传输轮次（即cwnd所允许发送的报文都连续发出去，且收到了对已发送的最后一个字节的确认），cwnd的大小就会加倍 通过指数级增长的方式，快速探测网络的可用带宽，但为了防止增长过快导致网络拥塞，还要引入慢开始门限ssthresh\n拥塞避免：\n当swnd超过ssthresh时，就会从慢开始算法切换到拥塞避免算法 在拥塞避免阶段，拥塞窗口不再加倍增长，而是每次收到一个确认报文，拥塞窗口就增加 1 个 MSS。也就是说，拥塞窗口以线性的方式缓慢增长 避免拥塞窗口增长过快，导致网络拥塞，让网络能够在一个相对稳定的状态下运行\n快恢复： 在每次超时重传(快重传)后，慢启动阈值会变成检测到网络拥塞时的窗口大小的一半，同时将拥塞窗口cwnd设置为1\nMSS：TCP协议报文能传输的最大数据段长度\n理论值：TCP报文最长65535字节，去掉20字节IP首部，最小20字节TCP首部，理论MSS=65495 字节\n实际值：主要由链路层的最大传输单元（MTU）决定。MTU 是指数据链路层能够承载的最大数据长度。例如，以太网的 MTU 通常是 1500 字节，在这种情况下，减去 20 字节的 IP 首部和 20 字节的 TCP 首部，MSS 的值为 1500 - 20 - 20 = 1460 字节\n协商机制：MSS 的值是在 TCP 连接建立时通过三次握手进行协商确定的。在客户端和服务器进行 TCP 连接建立的过程中，双方会在 SYN 报文中交换各自能够支持的 MSS 值，最终会选择一个双方都能接受的最小值作为本次连接的 MSS\n性能提升策略\r#\r滑动窗口\r#\r发送方一次发送多个报文，报文的数量由滑动窗口大小确定 TCP报文首部中，有一个16位大小的窗口值，该字段反映的是发送该报文的主机的接收缓冲区的剩余大小，也就是发送方反应自己的接受能力 三次握手时，就会通报对方自己的窗口大小，双方基于每次通信的报文中的窗口大小，来动态调整自己要发送给对方的报文数量，就是滑动窗口\n发送方根据对端发送的窗口大小，将自己的发送缓冲区分成三个部分 滑动窗口是可以发送未收到应答的部分\n窗口大小是指无需等待确认应答而可以继续发送数据的最大值 发送滑动窗口内的数据，不需要等待任何ACK，直接发送 收到一个ACK后，滑动窗口向后移动，继续发送后续的数据 操作系统内核维护滑动窗口，开辟发送缓冲区记录哪些数据没有应答，确认应答的数据从缓冲区删除（被后续数据覆盖） 窗口越大，网络吞吐率越高 相关问题\n滑动窗口只能向右，不能向左 因为左边数据已经发送且收到接收应答，不应该再发送 滑动窗口大小可以变化，可以为0 滑动窗口大小取决于对方的通告，可以辩变化。0表示对方暂时不能接收数据，可能是接收缓冲区满，于是发送方不再发送数据，但是会定期发送窗口探测报文，知晓接收方的窗口大小 滑动窗口能一直向右滑动不越界 因为发送缓冲区是环形队列，左边的部分会被新的数据覆盖 丢包如何重传 如果数据送到，ACK丢失，可以用后续的ACK进行确认 如果是数据没送到，则有快重传机制 快重传\r#\r数据包丢失情况下，发送方会一直收到前序报文序号+1的应答 如果连续三次收到前序报文序号+1的应答，发送端会立即重发丢失的数据包 即快重传机制\n延迟应答\r#\r接收方收到数据放入接收缓冲区，应用层会将缓冲区数据取走处理，释放接收缓冲区 如果接收方收到数据就立即返回ACK，返回的窗口会比较小，但是实际上一会会空出更大的窗口，接收方实际可以在一会后处理更多的数据 所以如果接收端等一会再应答，通报的窗口可以更大 窗口越大，网络吞吐量越大，传输效率越高 延迟应答：\n每隔N个包就应答一次 超过最大延迟时间就应答一次 不同操作系统不同，一半N=2，延迟时间取200ms 捎带应答\r#\r和确认应答搭配使用，在一方返回确认应答ACK报文时，可以在报文中携带数据，携带数据的确认应答就是捎带应答，提升数据传输效率\n拆包和粘包问题\r#\r包指的是应用层的数据包 拆包，即应用层的数据在TCP被拆成多个数据包分别传输和被接收 拆包传输，需要保证接收方能够根据拆包还原原本数据包 由TCP数据包的序列号连接和可靠性传输不丢包来保证\n粘包，两个应用层包的结尾和开头在一个TCP包内，即前后的多个应用层数据包粘连 粘包传输，需要接收方能够分离应用层的数据包，即明确边界 TCP的协议头没有数据长度字段，只有序列号便于分解TCP首部和载荷\n在传输层角度，TCP接收TCP报文，按序号将报文按顺序放在接收缓冲区，等待上层应用读取时，将载荷分离向上交付 在应用层角度，接收到TCP传输的载荷，载荷时一串连续字节数据。应用程序无法得知完整数据包的边界，多个包混杂粘连在一起，无法合理解析 所以应用层协议应该明确数据包的边界。比如HTTP header中有length，明确一个HTTP body部分的长度，取这个长度的数据作为一个response进行解析 明确包的边界是避免粘包问题的根本\n对于定长的包，每次按固定大小读取 对于变长的包，约定包总长度的字段，从而知道包的结束位置 对于变长的包，也可以约定包之间的分隔符 总览\r#\rTCP是字节流的传输层协议\nTCP的任务是保证数据的完整传输\nTCP通过三次握手检测双方发送和接收能力，以及信道传输能力\n通过校验和保证数据传输的无损\n通过序列号来保证数据包的顺序，让接收方能还原数据包\n通过确认应答、超时重传机制来保证不丢包\n通过滑动窗口机制(流量控制)来根据对方的接受能力调整发送速度\n通过拥塞控制来探测网络情况调整发送速度\n在确认应答机制中通过延迟应答，增大滑动窗口大小，提升数据吞吐\n在超时重传机制中通过快重传提升丢包重传速度\n在确认应答机制中通过捎带应答，多传输一些数据\n"},{"id":36,"href":"/codestack/docs/basic/net/transport/","title":"传输层","section":"计算机网络","content":"\r传输层 Transport Layer\r#\r"},{"id":37,"href":"/codestack/docs/basic/net/application/","title":"应用层","section":"计算机网络","content":"\r应用层 Application Layer\r#\r"},{"id":38,"href":"/codestack/docs/basic/net/","title":"计算机网络","section":"计算机基础","content":"\r计算机网络\r#\r"}]