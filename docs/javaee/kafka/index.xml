<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Kafka on CodeStack</title>
    <link>https://constructor-md.github.io/codestack/docs/javaee/kafka/</link>
    <description>Recent content in Kafka on CodeStack</description>
    <generator>Hugo</generator>
    <language>zh-CN</language>
    <atom:link href="https://constructor-md.github.io/codestack/docs/javaee/kafka/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>简介</title>
      <link>https://constructor-md.github.io/codestack/docs/javaee/kafka/intro/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://constructor-md.github.io/codestack/docs/javaee/kafka/intro/</guid>
      <description>&lt;h1 id=&#34;简介&#34;&gt;&#xD;&#xA;  简介&#xD;&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#%e7%ae%80%e4%bb%8b&#34;&gt;#&lt;/a&gt;&#xD;&#xA;&lt;/h1&gt;&#xD;&#xA;&lt;p&gt;Kafka是一种分布式流事件处理平台&lt;br&gt;&#xA;最初由LinkedIn开发，现在是Apache基金会的一部分&lt;br&gt;&#xA;核心功能包括：消息队列、流处理和数据集成&lt;br&gt;&#xA;具备高吞吐量、低延迟、可扩展和高容错性&lt;/p&gt;&#xA;&lt;h2 id=&#34;主要应用场景&#34;&gt;&#xD;&#xA;  主要应用场景&#xD;&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#%e4%b8%bb%e8%a6%81%e5%ba%94%e7%94%a8%e5%9c%ba%e6%99%af&#34;&gt;#&lt;/a&gt;&#xD;&#xA;&lt;/h2&gt;&#xD;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;消息队列&lt;br&gt;&#xA;用作高吞吐量的消息系统，将消息从一个系统传递到另一个系统&lt;/li&gt;&#xA;&lt;li&gt;日志收集&lt;br&gt;&#xA;集中收起日志数据，然后通过Kafka传递到是实时监控系统或存储系统&lt;/li&gt;&#xA;&lt;li&gt;流计算&lt;br&gt;&#xA;处理实时数据流，将数据传递给实时计算系统，如Apache Strom或 Apache Flink&lt;/li&gt;&#xA;&lt;li&gt;事件溯源&lt;br&gt;&#xA;记录时间发生的历史，以便稍后进行数据回溯或重新处理&lt;/li&gt;&#xA;&lt;li&gt;Metrics收集和监控&lt;br&gt;&#xA;收集来自不同服务的监控指标，统一存储和处理&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;p&gt;Kafka设计理念与传统消息队列（如RabbitMQ）有所不同。&lt;br&gt;&#xA;Kafka更侧重于处理大规模数据流、支持高吞吐量和持久化存储。通常用于处理日志、监控数据等大规模数据流&lt;br&gt;&#xA;传统消息队列更多侧重于短生命周期的消息传递和任务调度。通常用于任务队列、队列服务等场景&lt;/p&gt;&#xA;&lt;p&gt;Kafka能在大数据生态系统中占据一席之地，归功于其独特设计和多个技术特点&lt;/p&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;Kafka采用分区（Partition）和副本（Replica）的策略。每个主题（Topic）可以分成多个分区，每个分区可以有多个副本，即使某些节点出现故障，仍然可以保证数据的高可用和持久性。使得Kafka能够轻松应对大量数据的并发写入和读取&lt;/li&gt;&#xA;&lt;li&gt;Kafka的高吞吐量和低延迟主要得益于其高效的IO模型。Kafka将数据写入操作进行顺序追加，避免磁盘的随机读写，极大提高了写入性能。此外Kafka采用了零拷贝（Zero-Copy）的技术，可以大幅提升数据传输效率，从而降低延迟&lt;br&gt;&#xA;在流处理方面，Kafka有强大的流处理API&amp;ndash;Kafka Streams。这个API允许开发者使用简单的编程莫辛纳甘创建复杂的流处理应用，而不必依赖外部独立的流处理框架。&lt;br&gt;&#xA;另外，Kafka Connect是Kafka用来进行数据继承的工具。它提供了各种各样的连接器（Connectors），可以轻松的将数据从外部系统导入Kafka，或者将Kafka中的数据导出到外部系统&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;h2 id=&#34;基本架构组成&#34;&gt;&#xD;&#xA;  基本架构组成&#xD;&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#%e5%9f%ba%e6%9c%ac%e6%9e%b6%e6%9e%84%e7%bb%84%e6%88%90&#34;&gt;#&lt;/a&gt;&#xD;&#xA;&lt;/h2&gt;&#xD;&#xA;&lt;p&gt;Kafka基本架构主要包括：Producer、Consumer、Broker 和 Zookeeper&lt;/p&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;Producer&lt;br&gt;&#xA;消息生产者，将数据发布到Kafka特定Topic上。客户端可以指定消费者发送的主题数据的分区和副本策略&lt;/li&gt;&#xA;&lt;li&gt;Consumer&lt;br&gt;&#xA;消息消费者，从Kafka的Topic中读取数据。消费者可以属于某个消费者组（Consumer Group），消费者组内的消费者，每个只会消费一个主题的一个消息，不会重复消费，可以让多个消费者平衡复杂读取数据&lt;/li&gt;&#xA;&lt;li&gt;Broker&lt;br&gt;&#xA;消息代理，也就是Kafka集群的服务节点。负责消息的存储和管理，集群可以包含一个或多个Broker，负责接收、存储、发送数据&lt;/li&gt;&#xA;&lt;li&gt;Zookeeper（有废弃Zookeeper的版本）&lt;br&gt;&#xA;协调器，用于Kafka的愤怒不是协调和管理任务，比如存储Broker的元数据信息、分区列表、Leader等。Zookeeper来确保Kafka集群的高可用性和一致性&lt;/li&gt;&#xA;&lt;/ol&gt;</description>
    </item>
    <item>
      <title>消息的生产与消费流程</title>
      <link>https://constructor-md.github.io/codestack/docs/javaee/kafka/message-transfer/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://constructor-md.github.io/codestack/docs/javaee/kafka/message-transfer/</guid>
      <description>&lt;h1 id=&#34;消息的生产与消费流程&#34;&gt;&#xD;&#xA;  消息的生产与消费流程&#xD;&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#%e6%b6%88%e6%81%af%e7%9a%84%e7%94%9f%e4%ba%a7%e4%b8%8e%e6%b6%88%e8%b4%b9%e6%b5%81%e7%a8%8b&#34;&gt;#&lt;/a&gt;&#xD;&#xA;&lt;/h1&gt;&#xD;&#xA;&lt;h2 id=&#34;消息生产&#34;&gt;&#xD;&#xA;  消息生产&#xD;&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#%e6%b6%88%e6%81%af%e7%94%9f%e4%ba%a7&#34;&gt;#&lt;/a&gt;&#xD;&#xA;&lt;/h2&gt;&#xD;&#xA;&lt;p&gt;Producer生产消息&lt;br&gt;&#xA;可以指定消息的主题、Key、Value、时间戳、分区策略、可靠性参数&lt;br&gt;&#xA;此外客户端还需要配置序列化器、性能优化参数等&lt;/p&gt;&#xA;&lt;h3 id=&#34;分区策略&#34;&gt;&#xD;&#xA;  分区策略&#xD;&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#%e5%88%86%e5%8c%ba%e7%ad%96%e7%95%a5&#34;&gt;#&lt;/a&gt;&#xD;&#xA;&lt;/h3&gt;&#xD;&#xA;&lt;h4 id=&#34;默认分区&#34;&gt;&#xD;&#xA;  默认分区&#xD;&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#%e9%bb%98%e8%ae%a4%e5%88%86%e5%8c%ba&#34;&gt;#&lt;/a&gt;&#xD;&#xA;&lt;/h4&gt;&#xD;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Key != null：对Key进行Hash取模确定分区&lt;/li&gt;&#xA;&lt;li&gt;Key == null：轮询（RoundRobin）分配分区&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h4 id=&#34;自定义分区器&#34;&gt;&#xD;&#xA;  自定义分区器&#xD;&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#%e8%87%aa%e5%ae%9a%e4%b9%89%e5%88%86%e5%8c%ba%e5%99%a8&#34;&gt;#&lt;/a&gt;&#xD;&#xA;&lt;/h4&gt;&#xD;&#xA;&lt;p&gt;通过实现 Partitioner 接口自定义路由逻辑&lt;/p&gt;&#xA;&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;    /**&#xD;&#xA;     * 自定义分区器，确保同一用户的消息总是发送到同一分区&#xD;&#xA;     * 通过对用户ID进行哈希计算，确定分区号&#xD;&#xA;     */&#xD;&#xA;    private static class UserIdPartitioner implements org.apache.kafka.clients.producer.Partitioner {&#xD;&#xA;        @Override&#xD;&#xA;        public int partition(String topic, Object key, byte[] keyBytes, Object value, byte[] valueBytes, org.apache.kafka.common.Cluster cluster) {&#xD;&#xA;            // 获取主题的分区数&#xD;&#xA;            int partitionCount = cluster.partitionsForTopic(topic).size();&#xD;&#xA;            if (partitionCount &amp;lt;= 0) {&#xD;&#xA;                return 0;&#xD;&#xA;            }&#xD;&#xA;            &#xD;&#xA;            // 如果key为null，使用轮询方式分配分区&#xD;&#xA;            if (key == null) {&#xD;&#xA;                return Utils.toPositive(Utils.murmur2(valueBytes)) % partitionCount;&#xD;&#xA;            }&#xD;&#xA;            &#xD;&#xA;            // 对用户ID进行哈希，确保同一用户的消息总是发送到同一分区&#xD;&#xA;            return Utils.toPositive(Utils.murmur2(keyBytes)) % partitionCount;&#xD;&#xA;        }&#xD;&#xA;&#xD;&#xA;        @Override&#xD;&#xA;        public void close() {&#xD;&#xA;            // 无需关闭资源&#xD;&#xA;        }&#xD;&#xA;&#xD;&#xA;        @Override&#xD;&#xA;        public void configure(Map&amp;lt;String, ?&amp;gt; configs) {&#xD;&#xA;            // 无需配置&#xD;&#xA;        }&#xD;&#xA;    }&#xA;&lt;/code&gt;&lt;/pre&gt;&lt;h3 id=&#34;可靠性参数&#34;&gt;&#xD;&#xA;  可靠性参数&#xD;&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#%e5%8f%af%e9%9d%a0%e6%80%a7%e5%8f%82%e6%95%b0&#34;&gt;#&lt;/a&gt;&#xD;&#xA;&lt;/h3&gt;&#xD;&#xA;&lt;h4 id=&#34;acks&#34;&gt;&#xD;&#xA;  acks&#xD;&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#acks&#34;&gt;#&lt;/a&gt;&#xD;&#xA;&lt;/h4&gt;&#xD;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;0：无需确认（可能丢数据）。&lt;/li&gt;&#xA;&lt;li&gt;1：Leader 写入成功即确认（默认）。&lt;/li&gt;&#xA;&lt;li&gt;-1/all：ISR 所有副本同步成功才确认（最强保证）。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h4 id=&#34;retries&#34;&gt;&#xD;&#xA;  retries&#xD;&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#retries&#34;&gt;#&lt;/a&gt;&#xD;&#xA;&lt;/h4&gt;&#xD;&#xA;&lt;p&gt;发送失败时的重试次数。&lt;/p&gt;</description>
    </item>
  </channel>
</rss>
